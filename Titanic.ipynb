{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"id":"vsKh3-qCH_FA","executionInfo":{"status":"ok","timestamp":1661703428037,"user_tz":-270,"elapsed":2203,"user":{"displayName":"amirhossein rasouli","userId":"03756625815821128820"}}},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import tensorflow as tf"]},{"cell_type":"code","execution_count":5,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":285},"id":"oFaL3i5AH_FE","executionInfo":{"status":"ok","timestamp":1661703498728,"user_tz":-270,"elapsed":33,"user":{"displayName":"amirhossein rasouli","userId":"03756625815821128820"}},"outputId":"83ffbbb3-7f1e-4858-d2a9-ed26f60171da"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["   PassengerId  Survived  Pclass  \\\n","0            1         0       3   \n","1            2         1       1   \n","2            3         1       3   \n","3            4         1       1   \n","4            5         0       3   \n","\n","                                                Name     Sex   Age  SibSp  \\\n","0                            Braund, Mr. Owen Harris    male  22.0      1   \n","1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n","2                             Heikkinen, Miss. Laina  female  26.0      0   \n","3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n","4                           Allen, Mr. William Henry    male  35.0      0   \n","\n","   Parch            Ticket     Fare Cabin Embarked  \n","0      0         A/5 21171   7.2500   NaN        S  \n","1      0          PC 17599  71.2833   C85        C  \n","2      0  STON/O2. 3101282   7.9250   NaN        S  \n","3      0            113803  53.1000  C123        S  \n","4      0            373450   8.0500   NaN        S  "],"text/html":["\n","  <div id=\"df-16ec0c3f-3275-47ad-8215-2d5a12900090\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Ticket</th>\n","      <th>Fare</th>\n","      <th>Cabin</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>male</td>\n","      <td>22.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>A/5 21171</td>\n","      <td>7.2500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n","      <td>female</td>\n","      <td>38.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>PC 17599</td>\n","      <td>71.2833</td>\n","      <td>C85</td>\n","      <td>C</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>female</td>\n","      <td>26.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>STON/O2. 3101282</td>\n","      <td>7.9250</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>female</td>\n","      <td>35.0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>113803</td>\n","      <td>53.1000</td>\n","      <td>C123</td>\n","      <td>S</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>male</td>\n","      <td>35.0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>373450</td>\n","      <td>8.0500</td>\n","      <td>NaN</td>\n","      <td>S</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-16ec0c3f-3275-47ad-8215-2d5a12900090')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-16ec0c3f-3275-47ad-8215-2d5a12900090 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-16ec0c3f-3275-47ad-8215-2d5a12900090');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":5}],"source":["train_data = pd.read_csv('train.csv')\n","test_data = pd.read_csv('test.csv')\n","train_data.head()"]},{"cell_type":"code","execution_count":8,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"tSXhjovcH_FG","executionInfo":{"status":"ok","timestamp":1661703600933,"user_tz":-270,"elapsed":27,"user":{"displayName":"amirhossein rasouli","userId":"03756625815821128820"}},"outputId":"f5807c74-e6d8-4c7f-fc88-2ee4410d2bf6"},"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 891 entries, 0 to 890\n","Data columns (total 12 columns):\n"," #   Column       Non-Null Count  Dtype  \n","---  ------       --------------  -----  \n"," 0   PassengerId  891 non-null    int64  \n"," 1   Survived     891 non-null    int64  \n"," 2   Pclass       891 non-null    int64  \n"," 3   Name         891 non-null    object \n"," 4   Sex          891 non-null    object \n"," 5   Age          714 non-null    float64\n"," 6   SibSp        891 non-null    int64  \n"," 7   Parch        891 non-null    int64  \n"," 8   Ticket       891 non-null    object \n"," 9   Fare         891 non-null    float64\n"," 10  Cabin        204 non-null    object \n"," 11  Embarked     889 non-null    object \n","dtypes: float64(2), int64(5), object(5)\n","memory usage: 83.7+ KB\n"]}],"source":["combine = [train_data , test_data]\n","train_data.info()"]},{"cell_type":"code","source":["test_data.info()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"QhcAb3cMQNd3","executionInfo":{"status":"ok","timestamp":1661703613719,"user_tz":-270,"elapsed":34,"user":{"displayName":"amirhossein rasouli","userId":"03756625815821128820"}},"outputId":"ddbcbbef-a674-40d0-ce9d-9137218ed6ab"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["<class 'pandas.core.frame.DataFrame'>\n","RangeIndex: 418 entries, 0 to 417\n","Data columns (total 11 columns):\n"," #   Column       Non-Null Count  Dtype  \n","---  ------       --------------  -----  \n"," 0   PassengerId  418 non-null    int64  \n"," 1   Pclass       418 non-null    int64  \n"," 2   Name         418 non-null    object \n"," 3   Sex          418 non-null    object \n"," 4   Age          332 non-null    float64\n"," 5   SibSp        418 non-null    int64  \n"," 6   Parch        418 non-null    int64  \n"," 7   Ticket       418 non-null    object \n"," 8   Fare         417 non-null    float64\n"," 9   Cabin        91 non-null     object \n"," 10  Embarked     418 non-null    object \n","dtypes: float64(2), int64(4), object(5)\n","memory usage: 36.0+ KB\n"]}]},{"cell_type":"code","source":["train_data.drop(columns = [\"PassengerId\"] , inplace = True)\n","\n","for dataset in combine:\n","    dataset.drop(columns = [\"Ticket\" , \"Cabin\"] , inplace = True)"],"metadata":{"id":"FpfWmQgUQkDM","executionInfo":{"status":"ok","timestamp":1661703705606,"user_tz":-270,"elapsed":7,"user":{"displayName":"amirhossein rasouli","userId":"03756625815821128820"}}},"execution_count":10,"outputs":[]},{"cell_type":"code","source":["train_data.Embarked.fillna(train_data.Embarked.dropna().max(), inplace=True)\n","for dataset in combine:\n","    dataset['Embarked'] = dataset['Embarked'].dropna().map({'S':0,'C':1,'Q':2}).astype(int)"],"metadata":{"id":"cwLBlR9wQq9j","executionInfo":{"status":"ok","timestamp":1661703731557,"user_tz":-270,"elapsed":20,"user":{"displayName":"amirhossein rasouli","userId":"03756625815821128820"}}},"execution_count":11,"outputs":[]},{"cell_type":"code","source":["for dataset in combine:\n","    dataset['Sex'] = dataset['Sex'].map( {'female': 1, 'male': 0} ).astype(int)  "],"metadata":{"id":"7zl7pZW4Qt8e","executionInfo":{"status":"ok","timestamp":1661703744992,"user_tz":-270,"elapsed":462,"user":{"displayName":"amirhossein rasouli","userId":"03756625815821128820"}}},"execution_count":12,"outputs":[]},{"cell_type":"code","source":["guess_ages = np.zeros((2,3))\n","\n","for dataset in combine:\n","    for i in range(0, 2):\n","        for j in range(0, 3):\n","            guess_df = dataset[(dataset['Sex'] == i) & (dataset['Pclass'] == j+1)]['Age'].dropna()\n","            age_guess = guess_df.median()\n","            guess_ages[i,j] = int( age_guess/0.5 + 0.5 ) * 0.5\n","    for i in range(0, 2):\n","        for j in range(0, 3):\n","            dataset.loc[ (dataset.Age.isnull()) & (dataset.Sex == i) & (dataset.Pclass == j+1), 'Age'] = guess_ages[i,j]\n","    dataset['Age'] = dataset['Age'].astype(int)"],"metadata":{"id":"VEKfs0fxQucx","executionInfo":{"status":"ok","timestamp":1661703847770,"user_tz":-270,"elapsed":396,"user":{"displayName":"amirhossein rasouli","userId":"03756625815821128820"}}},"execution_count":13,"outputs":[]},{"cell_type":"code","source":["test_data.Fare.fillna(test_data.Fare.dropna().median() , inplace= True)"],"metadata":{"id":"9H8eQbmOQrvu","executionInfo":{"status":"ok","timestamp":1661703872932,"user_tz":-270,"elapsed":498,"user":{"displayName":"amirhossein rasouli","userId":"03756625815821128820"}}},"execution_count":14,"outputs":[]},{"cell_type":"code","source":["print(train_data.isnull().sum())\n","print(\"-\" * 50)\n","print(test_data.isnull().sum())"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"DXajL-3pRPdo","executionInfo":{"status":"ok","timestamp":1661703880830,"user_tz":-270,"elapsed":23,"user":{"displayName":"amirhossein rasouli","userId":"03756625815821128820"}},"outputId":"12305c5a-0c71-4a3f-8217-0f36d150cc65"},"execution_count":15,"outputs":[{"output_type":"stream","name":"stdout","text":["Survived    0\n","Pclass      0\n","Name        0\n","Sex         0\n","Age         0\n","SibSp       0\n","Parch       0\n","Fare        0\n","Embarked    0\n","dtype: int64\n","--------------------------------------------------\n","PassengerId    0\n","Pclass         0\n","Name           0\n","Sex            0\n","Age            0\n","SibSp          0\n","Parch          0\n","Fare           0\n","Embarked       0\n","dtype: int64\n"]}]},{"cell_type":"code","source":["train_data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"p8k025uYRR0k","executionInfo":{"status":"ok","timestamp":1661703892465,"user_tz":-270,"elapsed":23,"user":{"displayName":"amirhossein rasouli","userId":"03756625815821128820"}},"outputId":"4e83e1d8-6f5a-4ad9-9525-6e9ae8f0640e"},"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Survived  Pclass                                               Name  Sex  \\\n","0         0       3                            Braund, Mr. Owen Harris    0   \n","1         1       1  Cumings, Mrs. John Bradley (Florence Briggs Th...    1   \n","2         1       3                             Heikkinen, Miss. Laina    1   \n","3         1       1       Futrelle, Mrs. Jacques Heath (Lily May Peel)    1   \n","4         0       3                           Allen, Mr. William Henry    0   \n","\n","   Age  SibSp  Parch     Fare  Embarked  \n","0   22      1      0   7.2500         0  \n","1   38      1      0  71.2833         1  \n","2   26      0      0   7.9250         0  \n","3   35      1      0  53.1000         0  \n","4   35      0      0   8.0500         0  "],"text/html":["\n","  <div id=\"df-f5718b21-9520-4a13-9fae-5db4b0bcf22a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Name</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>SibSp</th>\n","      <th>Parch</th>\n","      <th>Fare</th>\n","      <th>Embarked</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Braund, Mr. Owen Harris</td>\n","      <td>0</td>\n","      <td>22</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>7.2500</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n","      <td>1</td>\n","      <td>38</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>71.2833</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>Heikkinen, Miss. Laina</td>\n","      <td>1</td>\n","      <td>26</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>7.9250</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n","      <td>1</td>\n","      <td>35</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>53.1000</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>Allen, Mr. William Henry</td>\n","      <td>0</td>\n","      <td>35</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>8.0500</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f5718b21-9520-4a13-9fae-5db4b0bcf22a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-f5718b21-9520-4a13-9fae-5db4b0bcf22a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-f5718b21-9520-4a13-9fae-5db4b0bcf22a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":16}]},{"cell_type":"code","source":["for dataset in combine:    \n","    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\n","    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\n","    dataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\n","    dataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\n","    dataset.loc[ dataset['Age'] > 64, 'Age']"],"metadata":{"id":"xBvy76o3RSkM","executionInfo":{"status":"ok","timestamp":1661704017760,"user_tz":-270,"elapsed":683,"user":{"displayName":"amirhossein rasouli","userId":"03756625815821128820"}}},"execution_count":17,"outputs":[]},{"cell_type":"code","source":["for dataset in combine:\n","    dataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\n","    dataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\n","    dataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\n","    dataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\n","    dataset['Fare'] = dataset['Fare'].astype(int)"],"metadata":{"id":"9JJw8hjKR5dY","executionInfo":{"status":"ok","timestamp":1661704067928,"user_tz":-270,"elapsed":501,"user":{"displayName":"amirhossein rasouli","userId":"03756625815821128820"}}},"execution_count":18,"outputs":[]},{"cell_type":"code","source":["for dataset in combine:\n","    dataset['FamilySize'] = dataset['SibSp'] + dataset['Parch'] + 1\n","\n","train_data.drop(['Parch', 'SibSp'], axis=1 , inplace = True)\n","test_data.drop(['Parch', 'SibSp'], axis=1 , inplace = True)    \n","\n","train_data[['FamilySize', 'Survived']].groupby(['FamilySize'], as_index=False).mean().sort_values(by='Survived', ascending=False)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":332},"id":"60SqmBYgR93k","executionInfo":{"status":"ok","timestamp":1661704199248,"user_tz":-270,"elapsed":1392,"user":{"displayName":"amirhossein rasouli","userId":"03756625815821128820"}},"outputId":"6d9c6a57-8770-496c-b6b2-1c1aa92fa32d"},"execution_count":19,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   FamilySize  Survived\n","3           4  0.724138\n","2           3  0.578431\n","1           2  0.552795\n","6           7  0.333333\n","0           1  0.303538\n","4           5  0.200000\n","5           6  0.136364\n","7           8  0.000000\n","8          11  0.000000"],"text/html":["\n","  <div id=\"df-62ba0d3f-74ef-41c5-b99b-06bcf4d91ecb\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>FamilySize</th>\n","      <th>Survived</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>3</th>\n","      <td>4</td>\n","      <td>0.724138</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>3</td>\n","      <td>0.578431</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>2</td>\n","      <td>0.552795</td>\n","    </tr>\n","    <tr>\n","      <th>6</th>\n","      <td>7</td>\n","      <td>0.333333</td>\n","    </tr>\n","    <tr>\n","      <th>0</th>\n","      <td>1</td>\n","      <td>0.303538</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>0.200000</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>6</td>\n","      <td>0.136364</td>\n","    </tr>\n","    <tr>\n","      <th>7</th>\n","      <td>8</td>\n","      <td>0.000000</td>\n","    </tr>\n","    <tr>\n","      <th>8</th>\n","      <td>11</td>\n","      <td>0.000000</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-62ba0d3f-74ef-41c5-b99b-06bcf4d91ecb')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-62ba0d3f-74ef-41c5-b99b-06bcf4d91ecb button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-62ba0d3f-74ef-41c5-b99b-06bcf4d91ecb');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":19}]},{"cell_type":"code","source":["for dataset in combine:\n","    dataset['Single'] = dataset['FamilySize'].map(lambda s: 1 if s == 1 else 0)\n","    dataset['SmallF'] = dataset['FamilySize'].map(lambda s: 1 if  s == 2  else 0)\n","    dataset['MedF'] = dataset['FamilySize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\n","    dataset['LargeF'] = dataset['FamilySize'].map(lambda s: 1 if s >= 5 else 0)\n","    \n","train_data.drop(columns = [\"FamilySize\"] , inplace = True)\n","test_data.drop(columns = [\"FamilySize\"] , inplace = True)"],"metadata":{"id":"o_JsbQgvSgz1","executionInfo":{"status":"ok","timestamp":1661704215264,"user_tz":-270,"elapsed":381,"user":{"displayName":"amirhossein rasouli","userId":"03756625815821128820"}}},"execution_count":20,"outputs":[]},{"cell_type":"code","source":["for dataset in combine:\n","    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n","\n","pd.crosstab(train_data['Title'], train_data['Sex'])"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":614},"id":"saFWSLMhShT5","executionInfo":{"status":"ok","timestamp":1661704248108,"user_tz":-270,"elapsed":607,"user":{"displayName":"amirhossein rasouli","userId":"03756625815821128820"}},"outputId":"01fd8f8a-0486-487b-f8fc-ab30c7776b80"},"execution_count":21,"outputs":[{"output_type":"execute_result","data":{"text/plain":["Sex         0    1\n","Title             \n","Capt        1    0\n","Col         2    0\n","Countess    0    1\n","Don         1    0\n","Dr          6    1\n","Jonkheer    1    0\n","Lady        0    1\n","Major       2    0\n","Master     40    0\n","Miss        0  182\n","Mlle        0    2\n","Mme         0    1\n","Mr        517    0\n","Mrs         0  125\n","Ms          0    1\n","Rev         6    0\n","Sir         1    0"],"text/html":["\n","  <div id=\"df-99331842-c8d3-4078-af13-afef8cb74f86\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th>Sex</th>\n","      <th>0</th>\n","      <th>1</th>\n","    </tr>\n","    <tr>\n","      <th>Title</th>\n","      <th></th>\n","      <th></th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>Capt</th>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Col</th>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Countess</th>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>Don</th>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Dr</th>\n","      <td>6</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>Jonkheer</th>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Lady</th>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>Major</th>\n","      <td>2</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Master</th>\n","      <td>40</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Miss</th>\n","      <td>0</td>\n","      <td>182</td>\n","    </tr>\n","    <tr>\n","      <th>Mlle</th>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>Mme</th>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>Mr</th>\n","      <td>517</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Mrs</th>\n","      <td>0</td>\n","      <td>125</td>\n","    </tr>\n","    <tr>\n","      <th>Ms</th>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>Rev</th>\n","      <td>6</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>Sir</th>\n","      <td>1</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-99331842-c8d3-4078-af13-afef8cb74f86')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-99331842-c8d3-4078-af13-afef8cb74f86 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-99331842-c8d3-4078-af13-afef8cb74f86');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":21}]},{"cell_type":"code","source":["for dataset in combine:\n","    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col',\\\n","    'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n","\n","    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n","    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n","    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n","    \n","train_data[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"ZOFsOOJuSpEs","executionInfo":{"status":"ok","timestamp":1661704256982,"user_tz":-270,"elapsed":7,"user":{"displayName":"amirhossein rasouli","userId":"03756625815821128820"}},"outputId":"27527471-82ec-46e0-a5e9-432e375090f0"},"execution_count":22,"outputs":[{"output_type":"execute_result","data":{"text/plain":["    Title  Survived\n","0  Master  0.575000\n","1    Miss  0.702703\n","2      Mr  0.156673\n","3     Mrs  0.793651\n","4    Rare  0.347826"],"text/html":["\n","  <div id=\"df-3f5c8ddf-d5af-409e-94c5-b40bd497d99a\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Title</th>\n","      <th>Survived</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Master</td>\n","      <td>0.575000</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Miss</td>\n","      <td>0.702703</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Mr</td>\n","      <td>0.156673</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>Mrs</td>\n","      <td>0.793651</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>Rare</td>\n","      <td>0.347826</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-3f5c8ddf-d5af-409e-94c5-b40bd497d99a')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-3f5c8ddf-d5af-409e-94c5-b40bd497d99a button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-3f5c8ddf-d5af-409e-94c5-b40bd497d99a');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":22}]},{"cell_type":"code","source":["title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n","for dataset in combine:\n","    dataset['Title'] = dataset['Title'].map(title_mapping)\n","    dataset['Title'] = dataset['Title'].fillna(0)"],"metadata":{"id":"jtnm1-97SrZm","executionInfo":{"status":"ok","timestamp":1661704293193,"user_tz":-270,"elapsed":440,"user":{"displayName":"amirhossein rasouli","userId":"03756625815821128820"}}},"execution_count":23,"outputs":[]},{"cell_type":"code","source":["train_data.drop(['Name'], axis=1 , inplace = True)\n","test_data.drop(['Name'], axis=1 , inplace = True)   "],"metadata":{"id":"4pzdEkqbSdFH","executionInfo":{"status":"ok","timestamp":1661704300037,"user_tz":-270,"elapsed":5,"user":{"displayName":"amirhossein rasouli","userId":"03756625815821128820"}}},"execution_count":24,"outputs":[]},{"cell_type":"code","source":["train_data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"rd4iBps7S15P","executionInfo":{"status":"ok","timestamp":1661704307295,"user_tz":-270,"elapsed":15,"user":{"displayName":"amirhossein rasouli","userId":"03756625815821128820"}},"outputId":"f7206a04-4492-4215-f54f-a9e95ae16e6d"},"execution_count":26,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   Survived  Pclass  Sex  Age  Fare  Embarked  Single  SmallF  MedF  LargeF  \\\n","0         0       3    0    1     0         0       0       1     0       0   \n","1         1       1    1    2     3         1       0       1     0       0   \n","2         1       3    1    1     1         0       1       0     0       0   \n","3         1       1    1    2     3         0       0       1     0       0   \n","4         0       3    0    2     1         0       1       0     0       0   \n","\n","   Title  \n","0      1  \n","1      3  \n","2      2  \n","3      3  \n","4      1  "],"text/html":["\n","  <div id=\"df-0740e0ca-b8dd-45c2-a949-114cb58f257f\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Survived</th>\n","      <th>Pclass</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>Fare</th>\n","      <th>Embarked</th>\n","      <th>Single</th>\n","      <th>SmallF</th>\n","      <th>MedF</th>\n","      <th>LargeF</th>\n","      <th>Title</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>1</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-0740e0ca-b8dd-45c2-a949-114cb58f257f')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-0740e0ca-b8dd-45c2-a949-114cb58f257f button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-0740e0ca-b8dd-45c2-a949-114cb58f257f');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":26}]},{"cell_type":"code","source":["test_data.head()"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":206},"id":"dBggPXrhS34G","executionInfo":{"status":"ok","timestamp":1661704321269,"user_tz":-270,"elapsed":496,"user":{"displayName":"amirhossein rasouli","userId":"03756625815821128820"}},"outputId":"778b708b-d7d2-42d0-9491-5ceb326f9e44"},"execution_count":27,"outputs":[{"output_type":"execute_result","data":{"text/plain":["   PassengerId  Pclass  Sex  Age  Fare  Embarked  Single  SmallF  MedF  \\\n","0          892       3    0    2     0         2       1       0     0   \n","1          893       3    1    2     0         0       0       1     0   \n","2          894       2    0    3     1         2       1       0     0   \n","3          895       3    0    1     1         0       1       0     0   \n","4          896       3    1    1     1         0       0       0     1   \n","\n","   LargeF  Title  \n","0       0      1  \n","1       0      3  \n","2       0      1  \n","3       0      1  \n","4       0      3  "],"text/html":["\n","  <div id=\"df-c1e130fa-adde-45a8-960e-a81d40fdc915\">\n","    <div class=\"colab-df-container\">\n","      <div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>PassengerId</th>\n","      <th>Pclass</th>\n","      <th>Sex</th>\n","      <th>Age</th>\n","      <th>Fare</th>\n","      <th>Embarked</th>\n","      <th>Single</th>\n","      <th>SmallF</th>\n","      <th>MedF</th>\n","      <th>LargeF</th>\n","      <th>Title</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>892</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>893</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>894</td>\n","      <td>2</td>\n","      <td>0</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>2</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>895</td>\n","      <td>3</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>896</td>\n","      <td>3</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>1</td>\n","      <td>0</td>\n","      <td>3</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>\n","      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c1e130fa-adde-45a8-960e-a81d40fdc915')\"\n","              title=\"Convert this dataframe to an interactive table.\"\n","              style=\"display:none;\">\n","        \n","  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n","       width=\"24px\">\n","    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n","    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n","  </svg>\n","      </button>\n","      \n","  <style>\n","    .colab-df-container {\n","      display:flex;\n","      flex-wrap:wrap;\n","      gap: 12px;\n","    }\n","\n","    .colab-df-convert {\n","      background-color: #E8F0FE;\n","      border: none;\n","      border-radius: 50%;\n","      cursor: pointer;\n","      display: none;\n","      fill: #1967D2;\n","      height: 32px;\n","      padding: 0 0 0 0;\n","      width: 32px;\n","    }\n","\n","    .colab-df-convert:hover {\n","      background-color: #E2EBFA;\n","      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n","      fill: #174EA6;\n","    }\n","\n","    [theme=dark] .colab-df-convert {\n","      background-color: #3B4455;\n","      fill: #D2E3FC;\n","    }\n","\n","    [theme=dark] .colab-df-convert:hover {\n","      background-color: #434B5C;\n","      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n","      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n","      fill: #FFFFFF;\n","    }\n","  </style>\n","\n","      <script>\n","        const buttonEl =\n","          document.querySelector('#df-c1e130fa-adde-45a8-960e-a81d40fdc915 button.colab-df-convert');\n","        buttonEl.style.display =\n","          google.colab.kernel.accessAllowed ? 'block' : 'none';\n","\n","        async function convertToInteractive(key) {\n","          const element = document.querySelector('#df-c1e130fa-adde-45a8-960e-a81d40fdc915');\n","          const dataTable =\n","            await google.colab.kernel.invokeFunction('convertToInteractive',\n","                                                     [key], {});\n","          if (!dataTable) return;\n","\n","          const docLinkHtml = 'Like what you see? Visit the ' +\n","            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n","            + ' to learn more about interactive tables.';\n","          element.innerHTML = '';\n","          dataTable['output_type'] = 'display_data';\n","          await google.colab.output.renderOutput(dataTable, element);\n","          const docLink = document.createElement('div');\n","          docLink.innerHTML = docLinkHtml;\n","          element.appendChild(docLink);\n","        }\n","      </script>\n","    </div>\n","  </div>\n","  "]},"metadata":{},"execution_count":27}]},{"cell_type":"code","source":["X = train_data.drop(labels = [\"Survived\"],axis = 1)\n","X_sub = test_data.drop('PassengerId', axis=1)\n","y = train_data[\"Survived\"]"],"metadata":{"id":"DkF9EmBXS7Nk","executionInfo":{"status":"ok","timestamp":1661710740683,"user_tz":-270,"elapsed":3,"user":{"displayName":"amirhossein rasouli","userId":"03756625815821128820"}}},"execution_count":99,"outputs":[]},{"cell_type":"code","source":["from sklearn.model_selection import train_test_split"],"metadata":{"id":"_PxLNpUhp0H6","executionInfo":{"status":"ok","timestamp":1661710373253,"user_tz":-270,"elapsed":366,"user":{"displayName":"amirhossein rasouli","userId":"03756625815821128820"}}},"execution_count":87,"outputs":[]},{"cell_type":"code","source":["X_train, X_test , y_train, y_test = train_test_split(X, y, random_state= 2468)"],"metadata":{"id":"1VJLuDvDToVh","executionInfo":{"status":"ok","timestamp":1661710480575,"user_tz":-270,"elapsed":1085,"user":{"displayName":"amirhossein rasouli","userId":"03756625815821128820"}}},"execution_count":89,"outputs":[]},{"cell_type":"code","execution_count":262,"metadata":{"id":"4eWEtPd7H_FP","executionInfo":{"status":"ok","timestamp":1661714034180,"user_tz":-270,"elapsed":933,"user":{"displayName":"amirhossein rasouli","userId":"03756625815821128820"}}},"outputs":[],"source":["model = tf.keras.models.Sequential([\n","    tf.keras.layers.Dense(10, activation='relu', input_shape=(10,)),\n","    tf.keras.layers.Dense(32, activation='relu'),\n","    tf.keras.layers.Dropout(0.2),\n","    tf.keras.layers.Dense(64, activation='relu'),\n","    tf.keras.layers.Dense(32, activation='relu'),\n","    tf.keras.layers.Dropout(0.1),\n","    tf.keras.layers.Dense(24, activation='relu'),\n","    tf.keras.layers.Dense(16, activation='relu'),\n","    tf.keras.layers.Dense(1, activation='sigmoid')\n","])"]},{"cell_type":"code","source":["reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_accuracy', factor=0.5,patience=3, min_lr=0.001, verbose=1)\n","model_check = tf.keras.callbacks.ModelCheckpoint(filepath='Logs/',monitor='val_accuracy',save_best_only=True, verbose=1)"],"metadata":{"id":"8wtKcQ3aLfzO","executionInfo":{"status":"ok","timestamp":1661710897484,"user_tz":-270,"elapsed":2,"user":{"displayName":"amirhossein rasouli","userId":"03756625815821128820"}}},"execution_count":105,"outputs":[]},{"cell_type":"code","execution_count":263,"metadata":{"id":"YNdI4BwZH_FQ","executionInfo":{"status":"ok","timestamp":1661714034180,"user_tz":-270,"elapsed":5,"user":{"displayName":"amirhossein rasouli","userId":"03756625815821128820"}}},"outputs":[],"source":["model.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(), metrics=['accuracy'])"]},{"cell_type":"code","execution_count":264,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"enmBj78AH_FQ","executionInfo":{"status":"ok","timestamp":1661714236193,"user_tz":-270,"elapsed":199765,"user":{"displayName":"amirhossein rasouli","userId":"03756625815821128820"}},"outputId":"955b6d53-bdbd-4c24-d2c9-2e66b085cdaf"},"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.6593 - accuracy: 0.6138\n","Epoch 1: val_accuracy did not improve from 0.86099\n","67/67 [==============================] - 1s 4ms/step - loss: 0.6593 - accuracy: 0.6138 - val_loss: 0.6109 - val_accuracy: 0.7758\n","Epoch 2/1000\n","39/67 [================>.............] - ETA: 0s - loss: 0.6086 - accuracy: 0.7051\n","Epoch 2: val_accuracy did not improve from 0.86099\n","67/67 [==============================] - 0s 2ms/step - loss: 0.5974 - accuracy: 0.7171 - val_loss: 0.5238 - val_accuracy: 0.7848\n","Epoch 3/1000\n","38/67 [================>.............] - ETA: 0s - loss: 0.5286 - accuracy: 0.7711\n","Epoch 3: val_accuracy did not improve from 0.86099\n","67/67 [==============================] - 0s 2ms/step - loss: 0.5507 - accuracy: 0.7710 - val_loss: 0.4771 - val_accuracy: 0.8251\n","Epoch 4/1000\n","40/67 [================>.............] - ETA: 0s - loss: 0.4738 - accuracy: 0.7950\n","Epoch 4: val_accuracy did not improve from 0.86099\n","67/67 [==============================] - 0s 2ms/step - loss: 0.5036 - accuracy: 0.7889 - val_loss: 0.4500 - val_accuracy: 0.8296\n","Epoch 5/1000\n","56/67 [========================>.....] - ETA: 0s - loss: 0.5532 - accuracy: 0.7679\n","Epoch 5: val_accuracy did not improve from 0.86099\n","67/67 [==============================] - 0s 2ms/step - loss: 0.5355 - accuracy: 0.7769 - val_loss: 0.4411 - val_accuracy: 0.8386\n","Epoch 6/1000\n","64/67 [===========================>..] - ETA: 0s - loss: 0.4905 - accuracy: 0.7859\n","Epoch 6: val_accuracy did not improve from 0.86099\n","67/67 [==============================] - 0s 2ms/step - loss: 0.4842 - accuracy: 0.7889 - val_loss: 0.4338 - val_accuracy: 0.8341\n","Epoch 7/1000\n","37/67 [===============>..............] - ETA: 0s - loss: 0.4874 - accuracy: 0.8135\n","Epoch 7: val_accuracy did not improve from 0.86099\n","67/67 [==============================] - 0s 2ms/step - loss: 0.4846 - accuracy: 0.7979 - val_loss: 0.4285 - val_accuracy: 0.8341\n","Epoch 8/1000\n","40/67 [================>.............] - ETA: 0s - loss: 0.4213 - accuracy: 0.8225\n","Epoch 8: val_accuracy did not improve from 0.86099\n","67/67 [==============================] - 0s 2ms/step - loss: 0.4629 - accuracy: 0.8114 - val_loss: 0.4282 - val_accuracy: 0.8430\n","Epoch 9/1000\n","39/67 [================>.............] - ETA: 0s - loss: 0.4472 - accuracy: 0.8000\n","Epoch 9: val_accuracy did not improve from 0.86099\n","67/67 [==============================] - 0s 2ms/step - loss: 0.4550 - accuracy: 0.8099 - val_loss: 0.4339 - val_accuracy: 0.8251\n","Epoch 10/1000\n","38/67 [================>.............] - ETA: 0s - loss: 0.4753 - accuracy: 0.8184\n","Epoch 10: val_accuracy did not improve from 0.86099\n","67/67 [==============================] - 0s 2ms/step - loss: 0.4512 - accuracy: 0.8189 - val_loss: 0.4502 - val_accuracy: 0.8341\n","Epoch 11/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.4267 - accuracy: 0.8204\n","Epoch 11: val_accuracy did not improve from 0.86099\n","67/67 [==============================] - 0s 2ms/step - loss: 0.4267 - accuracy: 0.8204 - val_loss: 0.4274 - val_accuracy: 0.8475\n","Epoch 12/1000\n","63/67 [===========================>..] - ETA: 0s - loss: 0.4374 - accuracy: 0.8238\n","Epoch 12: val_accuracy did not improve from 0.86099\n","67/67 [==============================] - 0s 2ms/step - loss: 0.4275 - accuracy: 0.8293 - val_loss: 0.4370 - val_accuracy: 0.8251\n","Epoch 13/1000\n","63/67 [===========================>..] - ETA: 0s - loss: 0.4229 - accuracy: 0.8286\n","Epoch 13: val_accuracy did not improve from 0.86099\n","67/67 [==============================] - 0s 2ms/step - loss: 0.4222 - accuracy: 0.8263 - val_loss: 0.4348 - val_accuracy: 0.8251\n","Epoch 14/1000\n","35/67 [==============>...............] - ETA: 0s - loss: 0.3655 - accuracy: 0.8514\n","Epoch 14: val_accuracy did not improve from 0.86099\n","67/67 [==============================] - 0s 2ms/step - loss: 0.4132 - accuracy: 0.8323 - val_loss: 0.4359 - val_accuracy: 0.8386\n","Epoch 15/1000\n","37/67 [===============>..............] - ETA: 0s - loss: 0.3891 - accuracy: 0.8459\n","Epoch 15: val_accuracy did not improve from 0.86099\n","67/67 [==============================] - 0s 3ms/step - loss: 0.4157 - accuracy: 0.8293 - val_loss: 0.4246 - val_accuracy: 0.8430\n","Epoch 16/1000\n","64/67 [===========================>..] - ETA: 0s - loss: 0.4163 - accuracy: 0.8266\n","Epoch 16: val_accuracy did not improve from 0.86099\n","67/67 [==============================] - 0s 2ms/step - loss: 0.4169 - accuracy: 0.8249 - val_loss: 0.4224 - val_accuracy: 0.8430\n","Epoch 17/1000\n","39/67 [================>.............] - ETA: 0s - loss: 0.3932 - accuracy: 0.8359\n","Epoch 17: val_accuracy did not improve from 0.86099\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3938 - accuracy: 0.8398 - val_loss: 0.4269 - val_accuracy: 0.8475\n","Epoch 18/1000\n","38/67 [================>.............] - ETA: 0s - loss: 0.4433 - accuracy: 0.8026\n","Epoch 18: val_accuracy did not improve from 0.86099\n","67/67 [==============================] - 0s 2ms/step - loss: 0.4146 - accuracy: 0.8174 - val_loss: 0.4382 - val_accuracy: 0.8430\n","Epoch 19/1000\n","36/67 [===============>..............] - ETA: 0s - loss: 0.4032 - accuracy: 0.8250\n","Epoch 19: val_accuracy did not improve from 0.86099\n","67/67 [==============================] - 0s 2ms/step - loss: 0.4271 - accuracy: 0.8204 - val_loss: 0.4294 - val_accuracy: 0.8520\n","Epoch 20/1000\n","38/67 [================>.............] - ETA: 0s - loss: 0.4178 - accuracy: 0.8184\n","Epoch 20: val_accuracy did not improve from 0.86099\n","67/67 [==============================] - 0s 2ms/step - loss: 0.4042 - accuracy: 0.8263 - val_loss: 0.4219 - val_accuracy: 0.8610\n","Epoch 21/1000\n","38/67 [================>.............] - ETA: 0s - loss: 0.4310 - accuracy: 0.8105\n","Epoch 21: val_accuracy did not improve from 0.86099\n","67/67 [==============================] - 0s 2ms/step - loss: 0.4035 - accuracy: 0.8308 - val_loss: 0.4335 - val_accuracy: 0.8475\n","Epoch 22/1000\n","39/67 [================>.............] - ETA: 0s - loss: 0.4376 - accuracy: 0.8308\n","Epoch 22: val_accuracy did not improve from 0.86099\n","67/67 [==============================] - 0s 2ms/step - loss: 0.4118 - accuracy: 0.8353 - val_loss: 0.4210 - val_accuracy: 0.8565\n","Epoch 23/1000\n","40/67 [================>.............] - ETA: 0s - loss: 0.3788 - accuracy: 0.8550\n","Epoch 23: val_accuracy did not improve from 0.86099\n","67/67 [==============================] - 0s 2ms/step - loss: 0.4014 - accuracy: 0.8338 - val_loss: 0.4281 - val_accuracy: 0.8430\n","Epoch 24/1000\n","37/67 [===============>..............] - ETA: 0s - loss: 0.4399 - accuracy: 0.8189\n","Epoch 24: val_accuracy did not improve from 0.86099\n","67/67 [==============================] - 0s 2ms/step - loss: 0.4141 - accuracy: 0.8249 - val_loss: 0.4285 - val_accuracy: 0.8475\n","Epoch 25/1000\n","40/67 [================>.............] - ETA: 0s - loss: 0.3898 - accuracy: 0.8425\n","Epoch 25: val_accuracy did not improve from 0.86099\n","67/67 [==============================] - 0s 2ms/step - loss: 0.4113 - accuracy: 0.8204 - val_loss: 0.4367 - val_accuracy: 0.8341\n","Epoch 26/1000\n","33/67 [=============>................] - ETA: 0s - loss: 0.3781 - accuracy: 0.8394\n","Epoch 26: val_accuracy did not improve from 0.86099\n","67/67 [==============================] - 0s 2ms/step - loss: 0.4168 - accuracy: 0.8278 - val_loss: 0.4348 - val_accuracy: 0.8386\n","Epoch 27/1000\n","41/67 [=================>............] - ETA: 0s - loss: 0.4022 - accuracy: 0.8293\n","Epoch 27: val_accuracy did not improve from 0.86099\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3862 - accuracy: 0.8413 - val_loss: 0.4280 - val_accuracy: 0.8565\n","Epoch 28/1000\n","33/67 [=============>................] - ETA: 0s - loss: 0.3915 - accuracy: 0.8182\n","Epoch 28: val_accuracy did not improve from 0.86099\n","67/67 [==============================] - 0s 2ms/step - loss: 0.4058 - accuracy: 0.8338 - val_loss: 0.4192 - val_accuracy: 0.8610\n","Epoch 29/1000\n","36/67 [===============>..............] - ETA: 0s - loss: 0.4023 - accuracy: 0.8250\n","Epoch 29: val_accuracy did not improve from 0.86099\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3958 - accuracy: 0.8308 - val_loss: 0.4161 - val_accuracy: 0.8565\n","Epoch 30/1000\n","40/67 [================>.............] - ETA: 0s - loss: 0.4096 - accuracy: 0.8250\n","Epoch 30: val_accuracy did not improve from 0.86099\n","67/67 [==============================] - 0s 2ms/step - loss: 0.4033 - accuracy: 0.8263 - val_loss: 0.4164 - val_accuracy: 0.8610\n","Epoch 31/1000\n","35/67 [==============>...............] - ETA: 0s - loss: 0.4031 - accuracy: 0.8371\n","Epoch 31: val_accuracy did not improve from 0.86099\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3948 - accuracy: 0.8293 - val_loss: 0.4281 - val_accuracy: 0.8520\n","Epoch 32/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.3875 - accuracy: 0.8439\n","Epoch 32: val_accuracy did not improve from 0.86099\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3870 - accuracy: 0.8428 - val_loss: 0.4203 - val_accuracy: 0.8565\n","Epoch 33/1000\n","59/67 [=========================>....] - ETA: 0s - loss: 0.4028 - accuracy: 0.8322\n","Epoch 33: val_accuracy did not improve from 0.86099\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3959 - accuracy: 0.8368 - val_loss: 0.4215 - val_accuracy: 0.8565\n","Epoch 34/1000\n","37/67 [===============>..............] - ETA: 0s - loss: 0.3944 - accuracy: 0.8649\n","Epoch 34: val_accuracy did not improve from 0.86099\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3991 - accuracy: 0.8413 - val_loss: 0.4358 - val_accuracy: 0.8296\n","Epoch 35/1000\n","40/67 [================>.............] - ETA: 0s - loss: 0.4242 - accuracy: 0.8175\n","Epoch 35: val_accuracy did not improve from 0.86099\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3987 - accuracy: 0.8338 - val_loss: 0.4311 - val_accuracy: 0.8475\n","Epoch 36/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.3977 - accuracy: 0.8278\n","Epoch 36: val_accuracy improved from 0.86099 to 0.86996, saving model to Logs/\n","67/67 [==============================] - 1s 22ms/step - loss: 0.3977 - accuracy: 0.8278 - val_loss: 0.4197 - val_accuracy: 0.8700\n","Epoch 37/1000\n","40/67 [================>.............] - ETA: 0s - loss: 0.3491 - accuracy: 0.8475\n","Epoch 37: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3857 - accuracy: 0.8308 - val_loss: 0.4190 - val_accuracy: 0.8520\n","Epoch 38/1000\n","65/67 [============================>.] - ETA: 0s - loss: 0.3996 - accuracy: 0.8262\n","Epoch 38: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3992 - accuracy: 0.8249 - val_loss: 0.4187 - val_accuracy: 0.8610\n","Epoch 39/1000\n","38/67 [================>.............] - ETA: 0s - loss: 0.3958 - accuracy: 0.8500\n","Epoch 39: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3901 - accuracy: 0.8383 - val_loss: 0.4170 - val_accuracy: 0.8655\n","Epoch 40/1000\n","41/67 [=================>............] - ETA: 0s - loss: 0.3675 - accuracy: 0.8463\n","Epoch 40: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3806 - accuracy: 0.8398 - val_loss: 0.4384 - val_accuracy: 0.8296\n","Epoch 41/1000\n","38/67 [================>.............] - ETA: 0s - loss: 0.3608 - accuracy: 0.8421\n","Epoch 41: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3747 - accuracy: 0.8383 - val_loss: 0.4216 - val_accuracy: 0.8430\n","Epoch 42/1000\n","40/67 [================>.............] - ETA: 0s - loss: 0.3932 - accuracy: 0.8375\n","Epoch 42: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3971 - accuracy: 0.8338 - val_loss: 0.4257 - val_accuracy: 0.8341\n","Epoch 43/1000\n","37/67 [===============>..............] - ETA: 0s - loss: 0.3746 - accuracy: 0.8432\n","Epoch 43: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3817 - accuracy: 0.8398 - val_loss: 0.4237 - val_accuracy: 0.8296\n","Epoch 44/1000\n","38/67 [================>.............] - ETA: 0s - loss: 0.3773 - accuracy: 0.8500\n","Epoch 44: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3967 - accuracy: 0.8368 - val_loss: 0.4433 - val_accuracy: 0.8161\n","Epoch 45/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.3903 - accuracy: 0.8308\n","Epoch 45: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3903 - accuracy: 0.8308 - val_loss: 0.4325 - val_accuracy: 0.8296\n","Epoch 46/1000\n","37/67 [===============>..............] - ETA: 0s - loss: 0.3539 - accuracy: 0.8459\n","Epoch 46: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3760 - accuracy: 0.8353 - val_loss: 0.4344 - val_accuracy: 0.8296\n","Epoch 47/1000\n","38/67 [================>.............] - ETA: 0s - loss: 0.3720 - accuracy: 0.8553\n","Epoch 47: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3771 - accuracy: 0.8443 - val_loss: 0.4178 - val_accuracy: 0.8520\n","Epoch 48/1000\n","40/67 [================>.............] - ETA: 0s - loss: 0.4049 - accuracy: 0.8200\n","Epoch 48: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3809 - accuracy: 0.8323 - val_loss: 0.4319 - val_accuracy: 0.8296\n","Epoch 49/1000\n","34/67 [==============>...............] - ETA: 0s - loss: 0.3596 - accuracy: 0.8588\n","Epoch 49: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3757 - accuracy: 0.8473 - val_loss: 0.4173 - val_accuracy: 0.8610\n","Epoch 50/1000\n","36/67 [===============>..............] - ETA: 0s - loss: 0.4011 - accuracy: 0.8250\n","Epoch 50: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3892 - accuracy: 0.8308 - val_loss: 0.4261 - val_accuracy: 0.8430\n","Epoch 51/1000\n","38/67 [================>.............] - ETA: 0s - loss: 0.3549 - accuracy: 0.8395\n","Epoch 51: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8338 - val_loss: 0.4239 - val_accuracy: 0.8430\n","Epoch 52/1000\n","40/67 [================>.............] - ETA: 0s - loss: 0.4030 - accuracy: 0.8350\n","Epoch 52: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3830 - accuracy: 0.8398 - val_loss: 0.4316 - val_accuracy: 0.8430\n","Epoch 53/1000\n","34/67 [==============>...............] - ETA: 0s - loss: 0.3736 - accuracy: 0.8441\n","Epoch 53: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3830 - accuracy: 0.8308 - val_loss: 0.4252 - val_accuracy: 0.8251\n","Epoch 54/1000\n","40/67 [================>.............] - ETA: 0s - loss: 0.3680 - accuracy: 0.8300\n","Epoch 54: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3769 - accuracy: 0.8219 - val_loss: 0.4301 - val_accuracy: 0.8296\n","Epoch 55/1000\n","38/67 [================>.............] - ETA: 0s - loss: 0.3803 - accuracy: 0.8447\n","Epoch 55: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3706 - accuracy: 0.8503 - val_loss: 0.4346 - val_accuracy: 0.8206\n","Epoch 56/1000\n","33/67 [=============>................] - ETA: 0s - loss: 0.3721 - accuracy: 0.8576\n","Epoch 56: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3762 - accuracy: 0.8488 - val_loss: 0.4207 - val_accuracy: 0.8565\n","Epoch 57/1000\n","39/67 [================>.............] - ETA: 0s - loss: 0.4030 - accuracy: 0.8359\n","Epoch 57: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3827 - accuracy: 0.8428 - val_loss: 0.4288 - val_accuracy: 0.8251\n","Epoch 58/1000\n","33/67 [=============>................] - ETA: 0s - loss: 0.3405 - accuracy: 0.8667\n","Epoch 58: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3853 - accuracy: 0.8413 - val_loss: 0.4218 - val_accuracy: 0.8386\n","Epoch 59/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.3684 - accuracy: 0.8409\n","Epoch 59: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8428 - val_loss: 0.4340 - val_accuracy: 0.8206\n","Epoch 60/1000\n","35/67 [==============>...............] - ETA: 0s - loss: 0.3763 - accuracy: 0.8286\n","Epoch 60: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3700 - accuracy: 0.8428 - val_loss: 0.4228 - val_accuracy: 0.8386\n","Epoch 61/1000\n","40/67 [================>.............] - ETA: 0s - loss: 0.3480 - accuracy: 0.8625\n","Epoch 61: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3735 - accuracy: 0.8428 - val_loss: 0.4270 - val_accuracy: 0.8341\n","Epoch 62/1000\n","33/67 [=============>................] - ETA: 0s - loss: 0.3967 - accuracy: 0.8333\n","Epoch 62: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3740 - accuracy: 0.8383 - val_loss: 0.4319 - val_accuracy: 0.8206\n","Epoch 63/1000\n","38/67 [================>.............] - ETA: 0s - loss: 0.3513 - accuracy: 0.8526\n","Epoch 63: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3642 - accuracy: 0.8473 - val_loss: 0.4233 - val_accuracy: 0.8341\n","Epoch 64/1000\n","38/67 [================>.............] - ETA: 0s - loss: 0.3960 - accuracy: 0.8421\n","Epoch 64: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3712 - accuracy: 0.8503 - val_loss: 0.4277 - val_accuracy: 0.8206\n","Epoch 65/1000\n","40/67 [================>.............] - ETA: 0s - loss: 0.3580 - accuracy: 0.8625\n","Epoch 65: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3718 - accuracy: 0.8548 - val_loss: 0.4281 - val_accuracy: 0.8206\n","Epoch 66/1000\n","34/67 [==============>...............] - ETA: 0s - loss: 0.3544 - accuracy: 0.8471\n","Epoch 66: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3687 - accuracy: 0.8488 - val_loss: 0.4303 - val_accuracy: 0.8341\n","Epoch 67/1000\n","38/67 [================>.............] - ETA: 0s - loss: 0.3697 - accuracy: 0.8500\n","Epoch 67: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3693 - accuracy: 0.8428 - val_loss: 0.4345 - val_accuracy: 0.8206\n","Epoch 68/1000\n","41/67 [=================>............] - ETA: 0s - loss: 0.3985 - accuracy: 0.8244\n","Epoch 68: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3752 - accuracy: 0.8383 - val_loss: 0.4316 - val_accuracy: 0.8206\n","Epoch 69/1000\n","39/67 [================>.............] - ETA: 0s - loss: 0.3384 - accuracy: 0.8667\n","Epoch 69: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3742 - accuracy: 0.8458 - val_loss: 0.4378 - val_accuracy: 0.8072\n","Epoch 70/1000\n","33/67 [=============>................] - ETA: 0s - loss: 0.3670 - accuracy: 0.8576\n","Epoch 70: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3716 - accuracy: 0.8593 - val_loss: 0.4263 - val_accuracy: 0.8206\n","Epoch 71/1000\n","38/67 [================>.............] - ETA: 0s - loss: 0.3927 - accuracy: 0.8211\n","Epoch 71: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3714 - accuracy: 0.8383 - val_loss: 0.4339 - val_accuracy: 0.8206\n","Epoch 72/1000\n","38/67 [================>.............] - ETA: 0s - loss: 0.3302 - accuracy: 0.8684\n","Epoch 72: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3580 - accuracy: 0.8593 - val_loss: 0.4318 - val_accuracy: 0.8161\n","Epoch 73/1000\n","32/67 [=============>................] - ETA: 0s - loss: 0.3282 - accuracy: 0.8844\n","Epoch 73: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3636 - accuracy: 0.8518 - val_loss: 0.4378 - val_accuracy: 0.8161\n","Epoch 74/1000\n","31/67 [============>.................] - ETA: 0s - loss: 0.3857 - accuracy: 0.8258\n","Epoch 74: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3687 - accuracy: 0.8353 - val_loss: 0.4398 - val_accuracy: 0.8206\n","Epoch 75/1000\n","39/67 [================>.............] - ETA: 0s - loss: 0.4066 - accuracy: 0.8179\n","Epoch 75: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3649 - accuracy: 0.8398 - val_loss: 0.4622 - val_accuracy: 0.8117\n","Epoch 76/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.3650 - accuracy: 0.8545\n","Epoch 76: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3621 - accuracy: 0.8563 - val_loss: 0.4359 - val_accuracy: 0.8117\n","Epoch 77/1000\n","35/67 [==============>...............] - ETA: 0s - loss: 0.3553 - accuracy: 0.8371\n","Epoch 77: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3595 - accuracy: 0.8458 - val_loss: 0.4355 - val_accuracy: 0.8117\n","Epoch 78/1000\n","39/67 [================>.............] - ETA: 0s - loss: 0.3696 - accuracy: 0.8436\n","Epoch 78: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3574 - accuracy: 0.8488 - val_loss: 0.4337 - val_accuracy: 0.8206\n","Epoch 79/1000\n","38/67 [================>.............] - ETA: 0s - loss: 0.3493 - accuracy: 0.8474\n","Epoch 79: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3550 - accuracy: 0.8533 - val_loss: 0.4389 - val_accuracy: 0.8206\n","Epoch 80/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.3502 - accuracy: 0.8548\n","Epoch 80: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3502 - accuracy: 0.8548 - val_loss: 0.4344 - val_accuracy: 0.8341\n","Epoch 81/1000\n","61/67 [==========================>...] - ETA: 0s - loss: 0.3679 - accuracy: 0.8475\n","Epoch 81: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3682 - accuracy: 0.8488 - val_loss: 0.4357 - val_accuracy: 0.8161\n","Epoch 82/1000\n","64/67 [===========================>..] - ETA: 0s - loss: 0.3566 - accuracy: 0.8594\n","Epoch 82: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3617 - accuracy: 0.8578 - val_loss: 0.4363 - val_accuracy: 0.8027\n","Epoch 83/1000\n","51/67 [=====================>........] - ETA: 0s - loss: 0.3718 - accuracy: 0.8412\n","Epoch 83: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3537 - accuracy: 0.8503 - val_loss: 0.4439 - val_accuracy: 0.8206\n","Epoch 84/1000\n","61/67 [==========================>...] - ETA: 0s - loss: 0.3576 - accuracy: 0.8557\n","Epoch 84: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3481 - accuracy: 0.8578 - val_loss: 0.4585 - val_accuracy: 0.8117\n","Epoch 85/1000\n","33/67 [=============>................] - ETA: 0s - loss: 0.3757 - accuracy: 0.8424\n","Epoch 85: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3602 - accuracy: 0.8563 - val_loss: 0.4478 - val_accuracy: 0.8027\n","Epoch 86/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.3681 - accuracy: 0.8561\n","Epoch 86: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3652 - accuracy: 0.8578 - val_loss: 0.4418 - val_accuracy: 0.8206\n","Epoch 87/1000\n","57/67 [========================>.....] - ETA: 0s - loss: 0.3391 - accuracy: 0.8702\n","Epoch 87: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3530 - accuracy: 0.8623 - val_loss: 0.4332 - val_accuracy: 0.8072\n","Epoch 88/1000\n","64/67 [===========================>..] - ETA: 0s - loss: 0.3600 - accuracy: 0.8531\n","Epoch 88: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3579 - accuracy: 0.8563 - val_loss: 0.4342 - val_accuracy: 0.8206\n","Epoch 89/1000\n","35/67 [==============>...............] - ETA: 0s - loss: 0.3287 - accuracy: 0.8486\n","Epoch 89: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3482 - accuracy: 0.8488 - val_loss: 0.4383 - val_accuracy: 0.8161\n","Epoch 90/1000\n","38/67 [================>.............] - ETA: 0s - loss: 0.3363 - accuracy: 0.8632\n","Epoch 90: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3497 - accuracy: 0.8623 - val_loss: 0.4328 - val_accuracy: 0.8251\n","Epoch 91/1000\n","61/67 [==========================>...] - ETA: 0s - loss: 0.3568 - accuracy: 0.8492\n","Epoch 91: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3536 - accuracy: 0.8503 - val_loss: 0.4271 - val_accuracy: 0.8386\n","Epoch 92/1000\n","56/67 [========================>.....] - ETA: 0s - loss: 0.3433 - accuracy: 0.8661\n","Epoch 92: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3548 - accuracy: 0.8533 - val_loss: 0.4393 - val_accuracy: 0.8161\n","Epoch 93/1000\n","54/67 [=======================>......] - ETA: 0s - loss: 0.3537 - accuracy: 0.8500\n","Epoch 93: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3567 - accuracy: 0.8488 - val_loss: 0.4266 - val_accuracy: 0.8296\n","Epoch 94/1000\n","62/67 [==========================>...] - ETA: 0s - loss: 0.3448 - accuracy: 0.8629\n","Epoch 94: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3466 - accuracy: 0.8608 - val_loss: 0.4423 - val_accuracy: 0.8027\n","Epoch 95/1000\n","62/67 [==========================>...] - ETA: 0s - loss: 0.3513 - accuracy: 0.8694\n","Epoch 95: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3468 - accuracy: 0.8698 - val_loss: 0.4355 - val_accuracy: 0.8206\n","Epoch 96/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.3466 - accuracy: 0.8606\n","Epoch 96: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3459 - accuracy: 0.8593 - val_loss: 0.4446 - val_accuracy: 0.8251\n","Epoch 97/1000\n","38/67 [================>.............] - ETA: 0s - loss: 0.3409 - accuracy: 0.8553\n","Epoch 97: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3515 - accuracy: 0.8578 - val_loss: 0.4498 - val_accuracy: 0.8161\n","Epoch 98/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.3594 - accuracy: 0.8578\n","Epoch 98: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3594 - accuracy: 0.8578 - val_loss: 0.4460 - val_accuracy: 0.8072\n","Epoch 99/1000\n","56/67 [========================>.....] - ETA: 0s - loss: 0.3285 - accuracy: 0.8732\n","Epoch 99: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3437 - accuracy: 0.8623 - val_loss: 0.4560 - val_accuracy: 0.8027\n","Epoch 100/1000\n","61/67 [==========================>...] - ETA: 0s - loss: 0.3482 - accuracy: 0.8705\n","Epoch 100: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3401 - accuracy: 0.8772 - val_loss: 0.4487 - val_accuracy: 0.8072\n","Epoch 101/1000\n","62/67 [==========================>...] - ETA: 0s - loss: 0.3610 - accuracy: 0.8629\n","Epoch 101: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3493 - accuracy: 0.8668 - val_loss: 0.4383 - val_accuracy: 0.8296\n","Epoch 102/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.3462 - accuracy: 0.8591\n","Epoch 102: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3437 - accuracy: 0.8608 - val_loss: 0.4493 - val_accuracy: 0.7982\n","Epoch 103/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.3511 - accuracy: 0.8485\n","Epoch 103: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3498 - accuracy: 0.8488 - val_loss: 0.4344 - val_accuracy: 0.8341\n","Epoch 104/1000\n","63/67 [===========================>..] - ETA: 0s - loss: 0.3519 - accuracy: 0.8587\n","Epoch 104: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3486 - accuracy: 0.8593 - val_loss: 0.4426 - val_accuracy: 0.8161\n","Epoch 105/1000\n","59/67 [=========================>....] - ETA: 0s - loss: 0.3295 - accuracy: 0.8695\n","Epoch 105: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3395 - accuracy: 0.8653 - val_loss: 0.4475 - val_accuracy: 0.8117\n","Epoch 106/1000\n","63/67 [===========================>..] - ETA: 0s - loss: 0.3491 - accuracy: 0.8524\n","Epoch 106: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3442 - accuracy: 0.8518 - val_loss: 0.4525 - val_accuracy: 0.8206\n","Epoch 107/1000\n","63/67 [===========================>..] - ETA: 0s - loss: 0.3440 - accuracy: 0.8635\n","Epoch 107: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3546 - accuracy: 0.8578 - val_loss: 0.4589 - val_accuracy: 0.8117\n","Epoch 108/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.3387 - accuracy: 0.8636\n","Epoch 108: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3417 - accuracy: 0.8608 - val_loss: 0.4502 - val_accuracy: 0.8206\n","Epoch 109/1000\n","33/67 [=============>................] - ETA: 0s - loss: 0.3425 - accuracy: 0.8515\n","Epoch 109: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3487 - accuracy: 0.8548 - val_loss: 0.4491 - val_accuracy: 0.8206\n","Epoch 110/1000\n","38/67 [================>.............] - ETA: 0s - loss: 0.3474 - accuracy: 0.8658\n","Epoch 110: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3461 - accuracy: 0.8593 - val_loss: 0.4492 - val_accuracy: 0.7892\n","Epoch 111/1000\n","36/67 [===============>..............] - ETA: 0s - loss: 0.3476 - accuracy: 0.8417\n","Epoch 111: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3433 - accuracy: 0.8503 - val_loss: 0.4435 - val_accuracy: 0.8072\n","Epoch 112/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.3683 - accuracy: 0.8561\n","Epoch 112: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3684 - accuracy: 0.8563 - val_loss: 0.4396 - val_accuracy: 0.8161\n","Epoch 113/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.3579 - accuracy: 0.8606\n","Epoch 113: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3631 - accuracy: 0.8563 - val_loss: 0.4370 - val_accuracy: 0.8161\n","Epoch 114/1000\n","34/67 [==============>...............] - ETA: 0s - loss: 0.3225 - accuracy: 0.8618\n","Epoch 114: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3534 - accuracy: 0.8533 - val_loss: 0.4367 - val_accuracy: 0.8117\n","Epoch 115/1000\n","32/67 [=============>................] - ETA: 0s - loss: 0.3542 - accuracy: 0.8500\n","Epoch 115: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3412 - accuracy: 0.8563 - val_loss: 0.4541 - val_accuracy: 0.7982\n","Epoch 116/1000\n","36/67 [===============>..............] - ETA: 0s - loss: 0.3377 - accuracy: 0.8639\n","Epoch 116: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3444 - accuracy: 0.8533 - val_loss: 0.4376 - val_accuracy: 0.8341\n","Epoch 117/1000\n","48/67 [====================>.........] - ETA: 0s - loss: 0.3658 - accuracy: 0.8500\n","Epoch 117: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3559 - accuracy: 0.8548 - val_loss: 0.4417 - val_accuracy: 0.8206\n","Epoch 118/1000\n","54/67 [=======================>......] - ETA: 0s - loss: 0.3463 - accuracy: 0.8574\n","Epoch 118: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3447 - accuracy: 0.8548 - val_loss: 0.4376 - val_accuracy: 0.8206\n","Epoch 119/1000\n","62/67 [==========================>...] - ETA: 0s - loss: 0.3352 - accuracy: 0.8597\n","Epoch 119: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3402 - accuracy: 0.8593 - val_loss: 0.4408 - val_accuracy: 0.8161\n","Epoch 120/1000\n","61/67 [==========================>...] - ETA: 0s - loss: 0.3374 - accuracy: 0.8525\n","Epoch 120: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3414 - accuracy: 0.8548 - val_loss: 0.4387 - val_accuracy: 0.8161\n","Epoch 121/1000\n","64/67 [===========================>..] - ETA: 0s - loss: 0.3521 - accuracy: 0.8547\n","Epoch 121: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3498 - accuracy: 0.8548 - val_loss: 0.4429 - val_accuracy: 0.8117\n","Epoch 122/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.3281 - accuracy: 0.8773\n","Epoch 122: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3275 - accuracy: 0.8772 - val_loss: 0.4592 - val_accuracy: 0.8117\n","Epoch 123/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.3473 - accuracy: 0.8515\n","Epoch 123: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3481 - accuracy: 0.8503 - val_loss: 0.4566 - val_accuracy: 0.8072\n","Epoch 124/1000\n","38/67 [================>.............] - ETA: 0s - loss: 0.3434 - accuracy: 0.8421\n","Epoch 124: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3433 - accuracy: 0.8518 - val_loss: 0.4480 - val_accuracy: 0.8072\n","Epoch 125/1000\n","36/67 [===============>..............] - ETA: 0s - loss: 0.3133 - accuracy: 0.8750\n","Epoch 125: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3359 - accuracy: 0.8668 - val_loss: 0.4627 - val_accuracy: 0.8072\n","Epoch 126/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.3370 - accuracy: 0.8608\n","Epoch 126: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3370 - accuracy: 0.8608 - val_loss: 0.4513 - val_accuracy: 0.7892\n","Epoch 127/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.3320 - accuracy: 0.8578\n","Epoch 127: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3320 - accuracy: 0.8578 - val_loss: 0.4528 - val_accuracy: 0.8117\n","Epoch 128/1000\n","59/67 [=========================>....] - ETA: 0s - loss: 0.3407 - accuracy: 0.8593\n","Epoch 128: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3383 - accuracy: 0.8578 - val_loss: 0.4474 - val_accuracy: 0.8072\n","Epoch 129/1000\n","64/67 [===========================>..] - ETA: 0s - loss: 0.3305 - accuracy: 0.8672\n","Epoch 129: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3266 - accuracy: 0.8668 - val_loss: 0.4668 - val_accuracy: 0.8072\n","Epoch 130/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.3405 - accuracy: 0.8697\n","Epoch 130: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3396 - accuracy: 0.8698 - val_loss: 0.4570 - val_accuracy: 0.8027\n","Epoch 131/1000\n","63/67 [===========================>..] - ETA: 0s - loss: 0.3562 - accuracy: 0.8460\n","Epoch 131: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3463 - accuracy: 0.8518 - val_loss: 0.4421 - val_accuracy: 0.8206\n","Epoch 132/1000\n","65/67 [============================>.] - ETA: 0s - loss: 0.3345 - accuracy: 0.8600\n","Epoch 132: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3318 - accuracy: 0.8623 - val_loss: 0.4640 - val_accuracy: 0.8027\n","Epoch 133/1000\n","65/67 [============================>.] - ETA: 0s - loss: 0.3363 - accuracy: 0.8538\n","Epoch 133: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3371 - accuracy: 0.8518 - val_loss: 0.4538 - val_accuracy: 0.8161\n","Epoch 134/1000\n","35/67 [==============>...............] - ETA: 0s - loss: 0.3561 - accuracy: 0.8486\n","Epoch 134: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3340 - accuracy: 0.8623 - val_loss: 0.4612 - val_accuracy: 0.8117\n","Epoch 135/1000\n","65/67 [============================>.] - ETA: 0s - loss: 0.3433 - accuracy: 0.8615\n","Epoch 135: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3424 - accuracy: 0.8623 - val_loss: 0.4616 - val_accuracy: 0.8117\n","Epoch 136/1000\n","55/67 [=======================>......] - ETA: 0s - loss: 0.3562 - accuracy: 0.8564\n","Epoch 136: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3399 - accuracy: 0.8623 - val_loss: 0.4521 - val_accuracy: 0.8117\n","Epoch 137/1000\n","58/67 [========================>.....] - ETA: 0s - loss: 0.3389 - accuracy: 0.8638\n","Epoch 137: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3361 - accuracy: 0.8638 - val_loss: 0.4498 - val_accuracy: 0.7982\n","Epoch 138/1000\n","36/67 [===============>..............] - ETA: 0s - loss: 0.3414 - accuracy: 0.8722\n","Epoch 138: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3433 - accuracy: 0.8638 - val_loss: 0.4424 - val_accuracy: 0.8206\n","Epoch 139/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.3412 - accuracy: 0.8697\n","Epoch 139: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3385 - accuracy: 0.8713 - val_loss: 0.4534 - val_accuracy: 0.8072\n","Epoch 140/1000\n","62/67 [==========================>...] - ETA: 0s - loss: 0.3320 - accuracy: 0.8613\n","Epoch 140: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3397 - accuracy: 0.8563 - val_loss: 0.4513 - val_accuracy: 0.8117\n","Epoch 141/1000\n","63/67 [===========================>..] - ETA: 0s - loss: 0.3380 - accuracy: 0.8556\n","Epoch 141: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3346 - accuracy: 0.8548 - val_loss: 0.4757 - val_accuracy: 0.8072\n","Epoch 142/1000\n","31/67 [============>.................] - ETA: 0s - loss: 0.3556 - accuracy: 0.8387\n","Epoch 142: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3381 - accuracy: 0.8638 - val_loss: 0.4564 - val_accuracy: 0.8161\n","Epoch 143/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.3342 - accuracy: 0.8668\n","Epoch 143: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3342 - accuracy: 0.8668 - val_loss: 0.4561 - val_accuracy: 0.8072\n","Epoch 144/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.3340 - accuracy: 0.8652\n","Epoch 144: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3332 - accuracy: 0.8653 - val_loss: 0.4699 - val_accuracy: 0.7892\n","Epoch 145/1000\n","61/67 [==========================>...] - ETA: 0s - loss: 0.3197 - accuracy: 0.8852\n","Epoch 145: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3206 - accuracy: 0.8832 - val_loss: 0.4649 - val_accuracy: 0.8027\n","Epoch 146/1000\n","57/67 [========================>.....] - ETA: 0s - loss: 0.3470 - accuracy: 0.8526\n","Epoch 146: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3329 - accuracy: 0.8593 - val_loss: 0.4709 - val_accuracy: 0.8117\n","Epoch 147/1000\n","62/67 [==========================>...] - ETA: 0s - loss: 0.3354 - accuracy: 0.8710\n","Epoch 147: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3335 - accuracy: 0.8728 - val_loss: 0.4694 - val_accuracy: 0.7982\n","Epoch 148/1000\n","58/67 [========================>.....] - ETA: 0s - loss: 0.3228 - accuracy: 0.8707\n","Epoch 148: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8623 - val_loss: 0.4478 - val_accuracy: 0.8251\n","Epoch 149/1000\n","58/67 [========================>.....] - ETA: 0s - loss: 0.3312 - accuracy: 0.8655\n","Epoch 149: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3379 - accuracy: 0.8623 - val_loss: 0.4537 - val_accuracy: 0.8161\n","Epoch 150/1000\n","58/67 [========================>.....] - ETA: 0s - loss: 0.3329 - accuracy: 0.8672\n","Epoch 150: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3338 - accuracy: 0.8608 - val_loss: 0.4558 - val_accuracy: 0.8251\n","Epoch 151/1000\n","60/67 [=========================>....] - ETA: 0s - loss: 0.3395 - accuracy: 0.8717\n","Epoch 151: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3417 - accuracy: 0.8683 - val_loss: 0.4585 - val_accuracy: 0.8072\n","Epoch 152/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.3168 - accuracy: 0.8742\n","Epoch 152: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3189 - accuracy: 0.8728 - val_loss: 0.4602 - val_accuracy: 0.7982\n","Epoch 153/1000\n","56/67 [========================>.....] - ETA: 0s - loss: 0.3070 - accuracy: 0.8732\n","Epoch 153: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3280 - accuracy: 0.8608 - val_loss: 0.4652 - val_accuracy: 0.7982\n","Epoch 154/1000\n","61/67 [==========================>...] - ETA: 0s - loss: 0.3295 - accuracy: 0.8721\n","Epoch 154: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3324 - accuracy: 0.8683 - val_loss: 0.4626 - val_accuracy: 0.7982\n","Epoch 155/1000\n","53/67 [======================>.......] - ETA: 0s - loss: 0.3498 - accuracy: 0.8566\n","Epoch 155: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3321 - accuracy: 0.8683 - val_loss: 0.4434 - val_accuracy: 0.8296\n","Epoch 156/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.3302 - accuracy: 0.8683\n","Epoch 156: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8683 - val_loss: 0.4591 - val_accuracy: 0.8072\n","Epoch 157/1000\n","59/67 [=========================>....] - ETA: 0s - loss: 0.3327 - accuracy: 0.8576\n","Epoch 157: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3270 - accuracy: 0.8608 - val_loss: 0.4644 - val_accuracy: 0.8117\n","Epoch 158/1000\n","65/67 [============================>.] - ETA: 0s - loss: 0.3227 - accuracy: 0.8615\n","Epoch 158: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3307 - accuracy: 0.8578 - val_loss: 0.4604 - val_accuracy: 0.8161\n","Epoch 159/1000\n","59/67 [=========================>....] - ETA: 0s - loss: 0.3132 - accuracy: 0.8695\n","Epoch 159: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3151 - accuracy: 0.8653 - val_loss: 0.4687 - val_accuracy: 0.8027\n","Epoch 160/1000\n","63/67 [===========================>..] - ETA: 0s - loss: 0.3247 - accuracy: 0.8603\n","Epoch 160: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3278 - accuracy: 0.8593 - val_loss: 0.4684 - val_accuracy: 0.8072\n","Epoch 161/1000\n","62/67 [==========================>...] - ETA: 0s - loss: 0.3341 - accuracy: 0.8629\n","Epoch 161: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3302 - accuracy: 0.8638 - val_loss: 0.4773 - val_accuracy: 0.8117\n","Epoch 162/1000\n","33/67 [=============>................] - ETA: 0s - loss: 0.3328 - accuracy: 0.8394\n","Epoch 162: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3304 - accuracy: 0.8563 - val_loss: 0.4724 - val_accuracy: 0.8117\n","Epoch 163/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.3256 - accuracy: 0.8593\n","Epoch 163: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3256 - accuracy: 0.8593 - val_loss: 0.4770 - val_accuracy: 0.8117\n","Epoch 164/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.3254 - accuracy: 0.8697\n","Epoch 164: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8713 - val_loss: 0.4826 - val_accuracy: 0.8161\n","Epoch 165/1000\n","35/67 [==============>...............] - ETA: 0s - loss: 0.3221 - accuracy: 0.8600\n","Epoch 165: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3436 - accuracy: 0.8473 - val_loss: 0.4488 - val_accuracy: 0.8117\n","Epoch 166/1000\n","37/67 [===============>..............] - ETA: 0s - loss: 0.3456 - accuracy: 0.8568\n","Epoch 166: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8698 - val_loss: 0.4864 - val_accuracy: 0.8027\n","Epoch 167/1000\n","34/67 [==============>...............] - ETA: 0s - loss: 0.3197 - accuracy: 0.8588\n","Epoch 167: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3230 - accuracy: 0.8653 - val_loss: 0.4846 - val_accuracy: 0.8027\n","Epoch 168/1000\n","59/67 [=========================>....] - ETA: 0s - loss: 0.3389 - accuracy: 0.8644\n","Epoch 168: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3280 - accuracy: 0.8713 - val_loss: 0.4688 - val_accuracy: 0.7982\n","Epoch 169/1000\n","65/67 [============================>.] - ETA: 0s - loss: 0.3141 - accuracy: 0.8754\n","Epoch 169: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3162 - accuracy: 0.8743 - val_loss: 0.4859 - val_accuracy: 0.7982\n","Epoch 170/1000\n","62/67 [==========================>...] - ETA: 0s - loss: 0.3240 - accuracy: 0.8677\n","Epoch 170: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3236 - accuracy: 0.8683 - val_loss: 0.4887 - val_accuracy: 0.8027\n","Epoch 171/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.3283 - accuracy: 0.8653\n","Epoch 171: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8653 - val_loss: 0.4704 - val_accuracy: 0.8072\n","Epoch 172/1000\n","62/67 [==========================>...] - ETA: 0s - loss: 0.3165 - accuracy: 0.8758\n","Epoch 172: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3209 - accuracy: 0.8713 - val_loss: 0.4733 - val_accuracy: 0.8072\n","Epoch 173/1000\n","34/67 [==============>...............] - ETA: 0s - loss: 0.3154 - accuracy: 0.8735\n","Epoch 173: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3273 - accuracy: 0.8653 - val_loss: 0.4684 - val_accuracy: 0.8161\n","Epoch 174/1000\n","54/67 [=======================>......] - ETA: 0s - loss: 0.3272 - accuracy: 0.8593\n","Epoch 174: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3235 - accuracy: 0.8608 - val_loss: 0.4772 - val_accuracy: 0.8072\n","Epoch 175/1000\n","59/67 [=========================>....] - ETA: 0s - loss: 0.3107 - accuracy: 0.8763\n","Epoch 175: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3165 - accuracy: 0.8728 - val_loss: 0.4738 - val_accuracy: 0.8251\n","Epoch 176/1000\n","53/67 [======================>.......] - ETA: 0s - loss: 0.3328 - accuracy: 0.8566\n","Epoch 176: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3277 - accuracy: 0.8623 - val_loss: 0.4788 - val_accuracy: 0.8072\n","Epoch 177/1000\n","62/67 [==========================>...] - ETA: 0s - loss: 0.3251 - accuracy: 0.8613\n","Epoch 177: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3262 - accuracy: 0.8608 - val_loss: 0.4779 - val_accuracy: 0.8027\n","Epoch 178/1000\n","57/67 [========================>.....] - ETA: 0s - loss: 0.3269 - accuracy: 0.8561\n","Epoch 178: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3284 - accuracy: 0.8533 - val_loss: 0.4927 - val_accuracy: 0.8072\n","Epoch 179/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.3186 - accuracy: 0.8773\n","Epoch 179: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3208 - accuracy: 0.8757 - val_loss: 0.4649 - val_accuracy: 0.8161\n","Epoch 180/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.3255 - accuracy: 0.8713\n","Epoch 180: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3255 - accuracy: 0.8713 - val_loss: 0.4795 - val_accuracy: 0.8206\n","Epoch 181/1000\n","62/67 [==========================>...] - ETA: 0s - loss: 0.3195 - accuracy: 0.8629\n","Epoch 181: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3171 - accuracy: 0.8638 - val_loss: 0.4746 - val_accuracy: 0.8161\n","Epoch 182/1000\n","59/67 [=========================>....] - ETA: 0s - loss: 0.3486 - accuracy: 0.8593\n","Epoch 182: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3483 - accuracy: 0.8608 - val_loss: 0.4538 - val_accuracy: 0.8027\n","Epoch 183/1000\n","58/67 [========================>.....] - ETA: 0s - loss: 0.3386 - accuracy: 0.8603\n","Epoch 183: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3306 - accuracy: 0.8668 - val_loss: 0.4664 - val_accuracy: 0.7982\n","Epoch 184/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.3198 - accuracy: 0.8636\n","Epoch 184: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3222 - accuracy: 0.8623 - val_loss: 0.4932 - val_accuracy: 0.7848\n","Epoch 185/1000\n","60/67 [=========================>....] - ETA: 0s - loss: 0.3207 - accuracy: 0.8683\n","Epoch 185: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3176 - accuracy: 0.8698 - val_loss: 0.5028 - val_accuracy: 0.7982\n","Epoch 186/1000\n","43/67 [==================>...........] - ETA: 0s - loss: 0.3237 - accuracy: 0.8674\n","Epoch 186: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3193 - accuracy: 0.8638 - val_loss: 0.4937 - val_accuracy: 0.7937\n","Epoch 187/1000\n","60/67 [=========================>....] - ETA: 0s - loss: 0.3171 - accuracy: 0.8683\n","Epoch 187: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3227 - accuracy: 0.8653 - val_loss: 0.4899 - val_accuracy: 0.8072\n","Epoch 188/1000\n","53/67 [======================>.......] - ETA: 0s - loss: 0.3236 - accuracy: 0.8660\n","Epoch 188: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3225 - accuracy: 0.8683 - val_loss: 0.5047 - val_accuracy: 0.8027\n","Epoch 189/1000\n","53/67 [======================>.......] - ETA: 0s - loss: 0.3240 - accuracy: 0.8642\n","Epoch 189: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3246 - accuracy: 0.8653 - val_loss: 0.5004 - val_accuracy: 0.8027\n","Epoch 190/1000\n","56/67 [========================>.....] - ETA: 0s - loss: 0.3226 - accuracy: 0.8607\n","Epoch 190: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3199 - accuracy: 0.8668 - val_loss: 0.4885 - val_accuracy: 0.8161\n","Epoch 191/1000\n","53/67 [======================>.......] - ETA: 0s - loss: 0.2954 - accuracy: 0.8811\n","Epoch 191: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3234 - accuracy: 0.8623 - val_loss: 0.4645 - val_accuracy: 0.8206\n","Epoch 192/1000\n","49/67 [====================>.........] - ETA: 0s - loss: 0.3118 - accuracy: 0.8694\n","Epoch 192: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3149 - accuracy: 0.8698 - val_loss: 0.4872 - val_accuracy: 0.8251\n","Epoch 193/1000\n","59/67 [=========================>....] - ETA: 0s - loss: 0.3140 - accuracy: 0.8814\n","Epoch 193: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3134 - accuracy: 0.8817 - val_loss: 0.4897 - val_accuracy: 0.8206\n","Epoch 194/1000\n","33/67 [=============>................] - ETA: 0s - loss: 0.3379 - accuracy: 0.8455\n","Epoch 194: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3225 - accuracy: 0.8533 - val_loss: 0.4818 - val_accuracy: 0.8251\n","Epoch 195/1000\n","64/67 [===========================>..] - ETA: 0s - loss: 0.3332 - accuracy: 0.8562\n","Epoch 195: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3296 - accuracy: 0.8578 - val_loss: 0.4879 - val_accuracy: 0.8206\n","Epoch 196/1000\n","55/67 [=======================>......] - ETA: 0s - loss: 0.3220 - accuracy: 0.8655\n","Epoch 196: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3272 - accuracy: 0.8653 - val_loss: 0.4835 - val_accuracy: 0.8161\n","Epoch 197/1000\n","60/67 [=========================>....] - ETA: 0s - loss: 0.3080 - accuracy: 0.8817\n","Epoch 197: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3182 - accuracy: 0.8728 - val_loss: 0.5033 - val_accuracy: 0.8072\n","Epoch 198/1000\n","53/67 [======================>.......] - ETA: 0s - loss: 0.3469 - accuracy: 0.8585\n","Epoch 198: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3190 - accuracy: 0.8698 - val_loss: 0.5101 - val_accuracy: 0.8072\n","Epoch 199/1000\n","65/67 [============================>.] - ETA: 0s - loss: 0.3276 - accuracy: 0.8662\n","Epoch 199: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3244 - accuracy: 0.8668 - val_loss: 0.4947 - val_accuracy: 0.8161\n","Epoch 200/1000\n","61/67 [==========================>...] - ETA: 0s - loss: 0.3178 - accuracy: 0.8738\n","Epoch 200: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3240 - accuracy: 0.8683 - val_loss: 0.4942 - val_accuracy: 0.8206\n","Epoch 201/1000\n","51/67 [=====================>........] - ETA: 0s - loss: 0.3051 - accuracy: 0.8824\n","Epoch 201: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3106 - accuracy: 0.8743 - val_loss: 0.5081 - val_accuracy: 0.8072\n","Epoch 202/1000\n","60/67 [=========================>....] - ETA: 0s - loss: 0.2989 - accuracy: 0.8767\n","Epoch 202: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3072 - accuracy: 0.8683 - val_loss: 0.4983 - val_accuracy: 0.8161\n","Epoch 203/1000\n","52/67 [======================>.......] - ETA: 0s - loss: 0.3115 - accuracy: 0.8769\n","Epoch 203: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3218 - accuracy: 0.8728 - val_loss: 0.4830 - val_accuracy: 0.8161\n","Epoch 204/1000\n","51/67 [=====================>........] - ETA: 0s - loss: 0.3022 - accuracy: 0.8725\n","Epoch 204: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3075 - accuracy: 0.8713 - val_loss: 0.5227 - val_accuracy: 0.8161\n","Epoch 205/1000\n","59/67 [=========================>....] - ETA: 0s - loss: 0.3254 - accuracy: 0.8593\n","Epoch 205: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3310 - accuracy: 0.8578 - val_loss: 0.4914 - val_accuracy: 0.8072\n","Epoch 206/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.3258 - accuracy: 0.8667\n","Epoch 206: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3240 - accuracy: 0.8668 - val_loss: 0.4981 - val_accuracy: 0.8072\n","Epoch 207/1000\n","58/67 [========================>.....] - ETA: 0s - loss: 0.2985 - accuracy: 0.8776\n","Epoch 207: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3105 - accuracy: 0.8743 - val_loss: 0.4999 - val_accuracy: 0.8161\n","Epoch 208/1000\n","59/67 [=========================>....] - ETA: 0s - loss: 0.3093 - accuracy: 0.8712\n","Epoch 208: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3078 - accuracy: 0.8713 - val_loss: 0.5064 - val_accuracy: 0.8072\n","Epoch 209/1000\n","49/67 [====================>.........] - ETA: 0s - loss: 0.3082 - accuracy: 0.8633\n","Epoch 209: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3180 - accuracy: 0.8638 - val_loss: 0.4959 - val_accuracy: 0.8206\n","Epoch 210/1000\n","56/67 [========================>.....] - ETA: 0s - loss: 0.3050 - accuracy: 0.8714\n","Epoch 210: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3029 - accuracy: 0.8728 - val_loss: 0.5266 - val_accuracy: 0.8251\n","Epoch 211/1000\n","58/67 [========================>.....] - ETA: 0s - loss: 0.3360 - accuracy: 0.8776\n","Epoch 211: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.8757 - val_loss: 0.4721 - val_accuracy: 0.8206\n","Epoch 212/1000\n","55/67 [=======================>......] - ETA: 0s - loss: 0.3333 - accuracy: 0.8636\n","Epoch 212: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3132 - accuracy: 0.8772 - val_loss: 0.4904 - val_accuracy: 0.8251\n","Epoch 213/1000\n","61/67 [==========================>...] - ETA: 0s - loss: 0.3098 - accuracy: 0.8705\n","Epoch 213: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3155 - accuracy: 0.8698 - val_loss: 0.5412 - val_accuracy: 0.8027\n","Epoch 214/1000\n","65/67 [============================>.] - ETA: 0s - loss: 0.3329 - accuracy: 0.8600\n","Epoch 214: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3348 - accuracy: 0.8593 - val_loss: 0.4813 - val_accuracy: 0.8117\n","Epoch 215/1000\n","50/67 [=====================>........] - ETA: 0s - loss: 0.3078 - accuracy: 0.8760\n","Epoch 215: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3190 - accuracy: 0.8743 - val_loss: 0.4949 - val_accuracy: 0.7982\n","Epoch 216/1000\n","54/67 [=======================>......] - ETA: 0s - loss: 0.3059 - accuracy: 0.8630\n","Epoch 216: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3175 - accuracy: 0.8593 - val_loss: 0.4929 - val_accuracy: 0.8072\n","Epoch 217/1000\n","53/67 [======================>.......] - ETA: 0s - loss: 0.2926 - accuracy: 0.8849\n","Epoch 217: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2996 - accuracy: 0.8787 - val_loss: 0.5060 - val_accuracy: 0.8072\n","Epoch 218/1000\n","61/67 [==========================>...] - ETA: 0s - loss: 0.3162 - accuracy: 0.8721\n","Epoch 218: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3168 - accuracy: 0.8728 - val_loss: 0.5028 - val_accuracy: 0.8072\n","Epoch 219/1000\n","58/67 [========================>.....] - ETA: 0s - loss: 0.3232 - accuracy: 0.8690\n","Epoch 219: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3214 - accuracy: 0.8668 - val_loss: 0.5022 - val_accuracy: 0.8072\n","Epoch 220/1000\n","50/67 [=====================>........] - ETA: 0s - loss: 0.2899 - accuracy: 0.8840\n","Epoch 220: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2921 - accuracy: 0.8817 - val_loss: 0.5393 - val_accuracy: 0.8072\n","Epoch 221/1000\n","56/67 [========================>.....] - ETA: 0s - loss: 0.2891 - accuracy: 0.8839\n","Epoch 221: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3038 - accuracy: 0.8772 - val_loss: 0.5306 - val_accuracy: 0.8072\n","Epoch 222/1000\n","60/67 [=========================>....] - ETA: 0s - loss: 0.3138 - accuracy: 0.8650\n","Epoch 222: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3059 - accuracy: 0.8668 - val_loss: 0.5487 - val_accuracy: 0.8072\n","Epoch 223/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.3177 - accuracy: 0.8623\n","Epoch 223: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3177 - accuracy: 0.8623 - val_loss: 0.5049 - val_accuracy: 0.8161\n","Epoch 224/1000\n","57/67 [========================>.....] - ETA: 0s - loss: 0.3233 - accuracy: 0.8702\n","Epoch 224: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3235 - accuracy: 0.8683 - val_loss: 0.5029 - val_accuracy: 0.8161\n","Epoch 225/1000\n","62/67 [==========================>...] - ETA: 0s - loss: 0.3021 - accuracy: 0.8758\n","Epoch 225: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3105 - accuracy: 0.8713 - val_loss: 0.5170 - val_accuracy: 0.8117\n","Epoch 226/1000\n","62/67 [==========================>...] - ETA: 0s - loss: 0.3050 - accuracy: 0.8726\n","Epoch 226: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8698 - val_loss: 0.5381 - val_accuracy: 0.8251\n","Epoch 227/1000\n","62/67 [==========================>...] - ETA: 0s - loss: 0.3169 - accuracy: 0.8645\n","Epoch 227: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3165 - accuracy: 0.8653 - val_loss: 0.5081 - val_accuracy: 0.8206\n","Epoch 228/1000\n","62/67 [==========================>...] - ETA: 0s - loss: 0.3054 - accuracy: 0.8774\n","Epoch 228: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3006 - accuracy: 0.8832 - val_loss: 0.5197 - val_accuracy: 0.8206\n","Epoch 229/1000\n","51/67 [=====================>........] - ETA: 0s - loss: 0.3285 - accuracy: 0.8667\n","Epoch 229: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3089 - accuracy: 0.8757 - val_loss: 0.5507 - val_accuracy: 0.8072\n","Epoch 230/1000\n","59/67 [=========================>....] - ETA: 0s - loss: 0.3050 - accuracy: 0.8763\n","Epoch 230: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2999 - accuracy: 0.8802 - val_loss: 0.5240 - val_accuracy: 0.8072\n","Epoch 231/1000\n","59/67 [=========================>....] - ETA: 0s - loss: 0.3117 - accuracy: 0.8746\n","Epoch 231: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3180 - accuracy: 0.8728 - val_loss: 0.5012 - val_accuracy: 0.8072\n","Epoch 232/1000\n","60/67 [=========================>....] - ETA: 0s - loss: 0.3013 - accuracy: 0.8750\n","Epoch 232: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3090 - accuracy: 0.8728 - val_loss: 0.4999 - val_accuracy: 0.8206\n","Epoch 233/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.3216 - accuracy: 0.8636\n","Epoch 233: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3203 - accuracy: 0.8638 - val_loss: 0.5119 - val_accuracy: 0.8251\n","Epoch 234/1000\n","57/67 [========================>.....] - ETA: 0s - loss: 0.2935 - accuracy: 0.8860\n","Epoch 234: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3110 - accuracy: 0.8772 - val_loss: 0.5037 - val_accuracy: 0.8206\n","Epoch 235/1000\n","57/67 [========================>.....] - ETA: 0s - loss: 0.3101 - accuracy: 0.8877\n","Epoch 235: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3159 - accuracy: 0.8802 - val_loss: 0.5487 - val_accuracy: 0.7937\n","Epoch 236/1000\n","61/67 [==========================>...] - ETA: 0s - loss: 0.3091 - accuracy: 0.8721\n","Epoch 236: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3027 - accuracy: 0.8743 - val_loss: 0.5309 - val_accuracy: 0.8072\n","Epoch 237/1000\n","54/67 [=======================>......] - ETA: 0s - loss: 0.2964 - accuracy: 0.8685\n","Epoch 237: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2936 - accuracy: 0.8698 - val_loss: 0.5483 - val_accuracy: 0.8117\n","Epoch 238/1000\n","58/67 [========================>.....] - ETA: 0s - loss: 0.2993 - accuracy: 0.8707\n","Epoch 238: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2981 - accuracy: 0.8728 - val_loss: 0.5416 - val_accuracy: 0.8072\n","Epoch 239/1000\n","63/67 [===========================>..] - ETA: 0s - loss: 0.3031 - accuracy: 0.8762\n","Epoch 239: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3093 - accuracy: 0.8743 - val_loss: 0.5388 - val_accuracy: 0.8161\n","Epoch 240/1000\n","62/67 [==========================>...] - ETA: 0s - loss: 0.3392 - accuracy: 0.8645\n","Epoch 240: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3283 - accuracy: 0.8713 - val_loss: 0.5203 - val_accuracy: 0.8161\n","Epoch 241/1000\n","56/67 [========================>.....] - ETA: 0s - loss: 0.3093 - accuracy: 0.8750\n","Epoch 241: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3104 - accuracy: 0.8698 - val_loss: 0.5195 - val_accuracy: 0.8206\n","Epoch 242/1000\n","53/67 [======================>.......] - ETA: 0s - loss: 0.3058 - accuracy: 0.8736\n","Epoch 242: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3109 - accuracy: 0.8698 - val_loss: 0.5430 - val_accuracy: 0.8161\n","Epoch 243/1000\n","61/67 [==========================>...] - ETA: 0s - loss: 0.3078 - accuracy: 0.8770\n","Epoch 243: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3133 - accuracy: 0.8757 - val_loss: 0.5252 - val_accuracy: 0.8072\n","Epoch 244/1000\n","48/67 [====================>.........] - ETA: 0s - loss: 0.2685 - accuracy: 0.8896\n","Epoch 244: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3039 - accuracy: 0.8757 - val_loss: 0.5290 - val_accuracy: 0.8072\n","Epoch 245/1000\n","65/67 [============================>.] - ETA: 0s - loss: 0.3096 - accuracy: 0.8754\n","Epoch 245: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3108 - accuracy: 0.8757 - val_loss: 0.5356 - val_accuracy: 0.8117\n","Epoch 246/1000\n","55/67 [=======================>......] - ETA: 0s - loss: 0.3107 - accuracy: 0.8764\n","Epoch 246: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3098 - accuracy: 0.8817 - val_loss: 0.5142 - val_accuracy: 0.8072\n","Epoch 247/1000\n","59/67 [=========================>....] - ETA: 0s - loss: 0.3133 - accuracy: 0.8763\n","Epoch 247: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3041 - accuracy: 0.8802 - val_loss: 0.5366 - val_accuracy: 0.8072\n","Epoch 248/1000\n","60/67 [=========================>....] - ETA: 0s - loss: 0.3070 - accuracy: 0.8733\n","Epoch 248: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3084 - accuracy: 0.8728 - val_loss: 0.5175 - val_accuracy: 0.8206\n","Epoch 249/1000\n","62/67 [==========================>...] - ETA: 0s - loss: 0.2960 - accuracy: 0.8774\n","Epoch 249: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2979 - accuracy: 0.8728 - val_loss: 0.5397 - val_accuracy: 0.8072\n","Epoch 250/1000\n","62/67 [==========================>...] - ETA: 0s - loss: 0.3023 - accuracy: 0.8790\n","Epoch 250: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3127 - accuracy: 0.8743 - val_loss: 0.5166 - val_accuracy: 0.8206\n","Epoch 251/1000\n","61/67 [==========================>...] - ETA: 0s - loss: 0.3115 - accuracy: 0.8574\n","Epoch 251: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8593 - val_loss: 0.5138 - val_accuracy: 0.8341\n","Epoch 252/1000\n","60/67 [=========================>....] - ETA: 0s - loss: 0.3002 - accuracy: 0.8800\n","Epoch 252: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3103 - accuracy: 0.8728 - val_loss: 0.5144 - val_accuracy: 0.8161\n","Epoch 253/1000\n","63/67 [===========================>..] - ETA: 0s - loss: 0.3108 - accuracy: 0.8825\n","Epoch 253: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3088 - accuracy: 0.8832 - val_loss: 0.5081 - val_accuracy: 0.8161\n","Epoch 254/1000\n","59/67 [=========================>....] - ETA: 0s - loss: 0.3053 - accuracy: 0.8763\n","Epoch 254: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2967 - accuracy: 0.8772 - val_loss: 0.5218 - val_accuracy: 0.8117\n","Epoch 255/1000\n","51/67 [=====================>........] - ETA: 0s - loss: 0.3046 - accuracy: 0.8725\n","Epoch 255: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3056 - accuracy: 0.8683 - val_loss: 0.5335 - val_accuracy: 0.8161\n","Epoch 256/1000\n","54/67 [=======================>......] - ETA: 0s - loss: 0.2980 - accuracy: 0.8778\n","Epoch 256: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3014 - accuracy: 0.8757 - val_loss: 0.5528 - val_accuracy: 0.8161\n","Epoch 257/1000\n","54/67 [=======================>......] - ETA: 0s - loss: 0.3166 - accuracy: 0.8667\n","Epoch 257: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2986 - accuracy: 0.8713 - val_loss: 0.5553 - val_accuracy: 0.8117\n","Epoch 258/1000\n","54/67 [=======================>......] - ETA: 0s - loss: 0.3150 - accuracy: 0.8630\n","Epoch 258: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2975 - accuracy: 0.8698 - val_loss: 0.5423 - val_accuracy: 0.8206\n","Epoch 259/1000\n","62/67 [==========================>...] - ETA: 0s - loss: 0.3122 - accuracy: 0.8694\n","Epoch 259: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3100 - accuracy: 0.8698 - val_loss: 0.5382 - val_accuracy: 0.8161\n","Epoch 260/1000\n","61/67 [==========================>...] - ETA: 0s - loss: 0.2964 - accuracy: 0.8820\n","Epoch 260: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3087 - accuracy: 0.8787 - val_loss: 0.5617 - val_accuracy: 0.8072\n","Epoch 261/1000\n","57/67 [========================>.....] - ETA: 0s - loss: 0.3135 - accuracy: 0.8667\n","Epoch 261: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3036 - accuracy: 0.8713 - val_loss: 0.5695 - val_accuracy: 0.8161\n","Epoch 262/1000\n","59/67 [=========================>....] - ETA: 0s - loss: 0.3127 - accuracy: 0.8627\n","Epoch 262: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3040 - accuracy: 0.8698 - val_loss: 0.5392 - val_accuracy: 0.8072\n","Epoch 263/1000\n","62/67 [==========================>...] - ETA: 0s - loss: 0.3090 - accuracy: 0.8710\n","Epoch 263: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3146 - accuracy: 0.8668 - val_loss: 0.5610 - val_accuracy: 0.7982\n","Epoch 264/1000\n","62/67 [==========================>...] - ETA: 0s - loss: 0.3191 - accuracy: 0.8677\n","Epoch 264: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3169 - accuracy: 0.8683 - val_loss: 0.5687 - val_accuracy: 0.8027\n","Epoch 265/1000\n","58/67 [========================>.....] - ETA: 0s - loss: 0.2947 - accuracy: 0.8862\n","Epoch 265: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3004 - accuracy: 0.8847 - val_loss: 0.5638 - val_accuracy: 0.8072\n","Epoch 266/1000\n","57/67 [========================>.....] - ETA: 0s - loss: 0.2931 - accuracy: 0.8877\n","Epoch 266: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2986 - accuracy: 0.8847 - val_loss: 0.5490 - val_accuracy: 0.8072\n","Epoch 267/1000\n","58/67 [========================>.....] - ETA: 0s - loss: 0.2976 - accuracy: 0.8776\n","Epoch 267: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2997 - accuracy: 0.8802 - val_loss: 0.5577 - val_accuracy: 0.8027\n","Epoch 268/1000\n","57/67 [========================>.....] - ETA: 0s - loss: 0.3020 - accuracy: 0.8789\n","Epoch 268: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2972 - accuracy: 0.8817 - val_loss: 0.5558 - val_accuracy: 0.8072\n","Epoch 269/1000\n","57/67 [========================>.....] - ETA: 0s - loss: 0.3109 - accuracy: 0.8684\n","Epoch 269: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3035 - accuracy: 0.8713 - val_loss: 0.5720 - val_accuracy: 0.8117\n","Epoch 270/1000\n","59/67 [=========================>....] - ETA: 0s - loss: 0.2960 - accuracy: 0.8763\n","Epoch 270: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3074 - accuracy: 0.8698 - val_loss: 0.5461 - val_accuracy: 0.8161\n","Epoch 271/1000\n","59/67 [=========================>....] - ETA: 0s - loss: 0.2967 - accuracy: 0.8729\n","Epoch 271: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3032 - accuracy: 0.8728 - val_loss: 0.5420 - val_accuracy: 0.8206\n","Epoch 272/1000\n","51/67 [=====================>........] - ETA: 0s - loss: 0.3074 - accuracy: 0.8706\n","Epoch 272: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3011 - accuracy: 0.8698 - val_loss: 0.5807 - val_accuracy: 0.8206\n","Epoch 273/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.2906 - accuracy: 0.8788\n","Epoch 273: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2891 - accuracy: 0.8787 - val_loss: 0.5774 - val_accuracy: 0.8161\n","Epoch 274/1000\n","56/67 [========================>.....] - ETA: 0s - loss: 0.2811 - accuracy: 0.8911\n","Epoch 274: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2927 - accuracy: 0.8877 - val_loss: 0.5847 - val_accuracy: 0.8251\n","Epoch 275/1000\n","60/67 [=========================>....] - ETA: 0s - loss: 0.2924 - accuracy: 0.8767\n","Epoch 275: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2900 - accuracy: 0.8802 - val_loss: 0.5710 - val_accuracy: 0.8161\n","Epoch 276/1000\n","50/67 [=====================>........] - ETA: 0s - loss: 0.3089 - accuracy: 0.8800\n","Epoch 276: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3194 - accuracy: 0.8713 - val_loss: 0.5242 - val_accuracy: 0.8296\n","Epoch 277/1000\n","57/67 [========================>.....] - ETA: 0s - loss: 0.3027 - accuracy: 0.8825\n","Epoch 277: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2987 - accuracy: 0.8832 - val_loss: 0.5236 - val_accuracy: 0.8251\n","Epoch 278/1000\n","62/67 [==========================>...] - ETA: 0s - loss: 0.2931 - accuracy: 0.8774\n","Epoch 278: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3010 - accuracy: 0.8728 - val_loss: 0.5235 - val_accuracy: 0.8161\n","Epoch 279/1000\n","60/67 [=========================>....] - ETA: 0s - loss: 0.3075 - accuracy: 0.8767\n","Epoch 279: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3096 - accuracy: 0.8772 - val_loss: 0.5389 - val_accuracy: 0.8251\n","Epoch 280/1000\n","64/67 [===========================>..] - ETA: 0s - loss: 0.2962 - accuracy: 0.8781\n","Epoch 280: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2950 - accuracy: 0.8772 - val_loss: 0.5244 - val_accuracy: 0.8161\n","Epoch 281/1000\n","60/67 [=========================>....] - ETA: 0s - loss: 0.2910 - accuracy: 0.8850\n","Epoch 281: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.3067 - accuracy: 0.8772 - val_loss: 0.5358 - val_accuracy: 0.8117\n","Epoch 282/1000\n","37/67 [===============>..............] - ETA: 0s - loss: 0.2898 - accuracy: 0.8838\n","Epoch 282: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.3020 - accuracy: 0.8832 - val_loss: 0.5587 - val_accuracy: 0.8072\n","Epoch 283/1000\n","60/67 [=========================>....] - ETA: 0s - loss: 0.2957 - accuracy: 0.8733\n","Epoch 283: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2868 - accuracy: 0.8772 - val_loss: 0.6100 - val_accuracy: 0.8072\n","Epoch 284/1000\n","55/67 [=======================>......] - ETA: 0s - loss: 0.2796 - accuracy: 0.8873\n","Epoch 284: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2941 - accuracy: 0.8862 - val_loss: 0.5822 - val_accuracy: 0.8117\n","Epoch 285/1000\n","63/67 [===========================>..] - ETA: 0s - loss: 0.2912 - accuracy: 0.8730\n","Epoch 285: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 5ms/step - loss: 0.2997 - accuracy: 0.8683 - val_loss: 0.5382 - val_accuracy: 0.8206\n","Epoch 286/1000\n","62/67 [==========================>...] - ETA: 0s - loss: 0.3096 - accuracy: 0.8823\n","Epoch 286: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3081 - accuracy: 0.8847 - val_loss: 0.5677 - val_accuracy: 0.8072\n","Epoch 287/1000\n","63/67 [===========================>..] - ETA: 0s - loss: 0.2978 - accuracy: 0.8730\n","Epoch 287: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2995 - accuracy: 0.8743 - val_loss: 0.5664 - val_accuracy: 0.8206\n","Epoch 288/1000\n","52/67 [======================>.......] - ETA: 0s - loss: 0.2959 - accuracy: 0.8846\n","Epoch 288: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2970 - accuracy: 0.8757 - val_loss: 0.5946 - val_accuracy: 0.8206\n","Epoch 289/1000\n","61/67 [==========================>...] - ETA: 0s - loss: 0.3088 - accuracy: 0.8754\n","Epoch 289: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 6ms/step - loss: 0.3012 - accuracy: 0.8787 - val_loss: 0.5990 - val_accuracy: 0.8206\n","Epoch 290/1000\n","65/67 [============================>.] - ETA: 0s - loss: 0.3168 - accuracy: 0.8677\n","Epoch 290: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3121 - accuracy: 0.8713 - val_loss: 0.5958 - val_accuracy: 0.8117\n","Epoch 291/1000\n","57/67 [========================>.....] - ETA: 0s - loss: 0.2925 - accuracy: 0.8772\n","Epoch 291: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2984 - accuracy: 0.8757 - val_loss: 0.5639 - val_accuracy: 0.8206\n","Epoch 292/1000\n","50/67 [=====================>........] - ETA: 0s - loss: 0.3127 - accuracy: 0.8700\n","Epoch 292: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2930 - accuracy: 0.8787 - val_loss: 0.5780 - val_accuracy: 0.8251\n","Epoch 293/1000\n","59/67 [=========================>....] - ETA: 0s - loss: 0.3094 - accuracy: 0.8729\n","Epoch 293: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3031 - accuracy: 0.8743 - val_loss: 0.5734 - val_accuracy: 0.8161\n","Epoch 294/1000\n","56/67 [========================>.....] - ETA: 0s - loss: 0.3135 - accuracy: 0.8643\n","Epoch 294: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2988 - accuracy: 0.8698 - val_loss: 0.5860 - val_accuracy: 0.8161\n","Epoch 295/1000\n","58/67 [========================>.....] - ETA: 0s - loss: 0.3024 - accuracy: 0.8759\n","Epoch 295: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2963 - accuracy: 0.8743 - val_loss: 0.5664 - val_accuracy: 0.8161\n","Epoch 296/1000\n","51/67 [=====================>........] - ETA: 0s - loss: 0.2727 - accuracy: 0.8804\n","Epoch 296: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2911 - accuracy: 0.8728 - val_loss: 0.5894 - val_accuracy: 0.8161\n","Epoch 297/1000\n","57/67 [========================>.....] - ETA: 0s - loss: 0.2732 - accuracy: 0.8860\n","Epoch 297: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2868 - accuracy: 0.8802 - val_loss: 0.5728 - val_accuracy: 0.8206\n","Epoch 298/1000\n","54/67 [=======================>......] - ETA: 0s - loss: 0.3056 - accuracy: 0.8741\n","Epoch 298: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3043 - accuracy: 0.8757 - val_loss: 0.5895 - val_accuracy: 0.8072\n","Epoch 299/1000\n","57/67 [========================>.....] - ETA: 0s - loss: 0.3009 - accuracy: 0.8754\n","Epoch 299: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2939 - accuracy: 0.8787 - val_loss: 0.5816 - val_accuracy: 0.8206\n","Epoch 300/1000\n","50/67 [=====================>........] - ETA: 0s - loss: 0.3054 - accuracy: 0.8700\n","Epoch 300: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2899 - accuracy: 0.8787 - val_loss: 0.5896 - val_accuracy: 0.8161\n","Epoch 301/1000\n","52/67 [======================>.......] - ETA: 0s - loss: 0.3185 - accuracy: 0.8577\n","Epoch 301: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3000 - accuracy: 0.8743 - val_loss: 0.6256 - val_accuracy: 0.8072\n","Epoch 302/1000\n","53/67 [======================>.......] - ETA: 0s - loss: 0.3138 - accuracy: 0.8679\n","Epoch 302: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3010 - accuracy: 0.8743 - val_loss: 0.5945 - val_accuracy: 0.8206\n","Epoch 303/1000\n","54/67 [=======================>......] - ETA: 0s - loss: 0.2867 - accuracy: 0.8852\n","Epoch 303: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3018 - accuracy: 0.8757 - val_loss: 0.5880 - val_accuracy: 0.7982\n","Epoch 304/1000\n","48/67 [====================>.........] - ETA: 0s - loss: 0.2975 - accuracy: 0.8729\n","Epoch 304: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2930 - accuracy: 0.8772 - val_loss: 0.6041 - val_accuracy: 0.8117\n","Epoch 305/1000\n","57/67 [========================>.....] - ETA: 0s - loss: 0.2975 - accuracy: 0.8772\n","Epoch 305: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3024 - accuracy: 0.8757 - val_loss: 0.5878 - val_accuracy: 0.8161\n","Epoch 306/1000\n","52/67 [======================>.......] - ETA: 0s - loss: 0.3026 - accuracy: 0.8731\n","Epoch 306: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2907 - accuracy: 0.8817 - val_loss: 0.6026 - val_accuracy: 0.7982\n","Epoch 307/1000\n","53/67 [======================>.......] - ETA: 0s - loss: 0.2880 - accuracy: 0.8755\n","Epoch 307: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2994 - accuracy: 0.8743 - val_loss: 0.5863 - val_accuracy: 0.8117\n","Epoch 308/1000\n","55/67 [=======================>......] - ETA: 0s - loss: 0.2714 - accuracy: 0.8800\n","Epoch 308: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2942 - accuracy: 0.8757 - val_loss: 0.5890 - val_accuracy: 0.8206\n","Epoch 309/1000\n","51/67 [=====================>........] - ETA: 0s - loss: 0.3138 - accuracy: 0.8686\n","Epoch 309: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2968 - accuracy: 0.8757 - val_loss: 0.6103 - val_accuracy: 0.8072\n","Epoch 310/1000\n","54/67 [=======================>......] - ETA: 0s - loss: 0.3047 - accuracy: 0.8722\n","Epoch 310: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3077 - accuracy: 0.8757 - val_loss: 0.5858 - val_accuracy: 0.8161\n","Epoch 311/1000\n","52/67 [======================>.......] - ETA: 0s - loss: 0.3102 - accuracy: 0.8673\n","Epoch 311: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2999 - accuracy: 0.8743 - val_loss: 0.5876 - val_accuracy: 0.8072\n","Epoch 312/1000\n","50/67 [=====================>........] - ETA: 0s - loss: 0.2922 - accuracy: 0.8820\n","Epoch 312: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3051 - accuracy: 0.8713 - val_loss: 0.5294 - val_accuracy: 0.8206\n","Epoch 313/1000\n","56/67 [========================>.....] - ETA: 0s - loss: 0.3023 - accuracy: 0.8696\n","Epoch 313: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3010 - accuracy: 0.8713 - val_loss: 0.5561 - val_accuracy: 0.8027\n","Epoch 314/1000\n","50/67 [=====================>........] - ETA: 0s - loss: 0.3040 - accuracy: 0.8700\n","Epoch 314: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3063 - accuracy: 0.8728 - val_loss: 0.5565 - val_accuracy: 0.7982\n","Epoch 315/1000\n","54/67 [=======================>......] - ETA: 0s - loss: 0.2732 - accuracy: 0.8870\n","Epoch 315: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2889 - accuracy: 0.8802 - val_loss: 0.6094 - val_accuracy: 0.7982\n","Epoch 316/1000\n","52/67 [======================>.......] - ETA: 0s - loss: 0.3038 - accuracy: 0.8712\n","Epoch 316: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2987 - accuracy: 0.8757 - val_loss: 0.6002 - val_accuracy: 0.8161\n","Epoch 317/1000\n","60/67 [=========================>....] - ETA: 0s - loss: 0.2802 - accuracy: 0.8883\n","Epoch 317: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2862 - accuracy: 0.8802 - val_loss: 0.6315 - val_accuracy: 0.8117\n","Epoch 318/1000\n","58/67 [========================>.....] - ETA: 0s - loss: 0.3081 - accuracy: 0.8621\n","Epoch 318: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3014 - accuracy: 0.8698 - val_loss: 0.6378 - val_accuracy: 0.7982\n","Epoch 319/1000\n","51/67 [=====================>........] - ETA: 0s - loss: 0.2828 - accuracy: 0.8745\n","Epoch 319: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2838 - accuracy: 0.8787 - val_loss: 0.6169 - val_accuracy: 0.8296\n","Epoch 320/1000\n","51/67 [=====================>........] - ETA: 0s - loss: 0.3001 - accuracy: 0.8765\n","Epoch 320: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3074 - accuracy: 0.8787 - val_loss: 0.6095 - val_accuracy: 0.8027\n","Epoch 321/1000\n","47/67 [====================>.........] - ETA: 0s - loss: 0.2918 - accuracy: 0.8766\n","Epoch 321: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2895 - accuracy: 0.8802 - val_loss: 0.5891 - val_accuracy: 0.8027\n","Epoch 322/1000\n","52/67 [======================>.......] - ETA: 0s - loss: 0.2874 - accuracy: 0.8885\n","Epoch 322: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2911 - accuracy: 0.8847 - val_loss: 0.5476 - val_accuracy: 0.8206\n","Epoch 323/1000\n","59/67 [=========================>....] - ETA: 0s - loss: 0.2950 - accuracy: 0.8847\n","Epoch 323: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2927 - accuracy: 0.8862 - val_loss: 0.5886 - val_accuracy: 0.8072\n","Epoch 324/1000\n","59/67 [=========================>....] - ETA: 0s - loss: 0.2852 - accuracy: 0.8847\n","Epoch 324: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2848 - accuracy: 0.8817 - val_loss: 0.5778 - val_accuracy: 0.8251\n","Epoch 325/1000\n","62/67 [==========================>...] - ETA: 0s - loss: 0.2809 - accuracy: 0.8839\n","Epoch 325: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2841 - accuracy: 0.8802 - val_loss: 0.6118 - val_accuracy: 0.8117\n","Epoch 326/1000\n","54/67 [=======================>......] - ETA: 0s - loss: 0.2770 - accuracy: 0.8778\n","Epoch 326: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2873 - accuracy: 0.8743 - val_loss: 0.5968 - val_accuracy: 0.8251\n","Epoch 327/1000\n","56/67 [========================>.....] - ETA: 0s - loss: 0.2872 - accuracy: 0.8696\n","Epoch 327: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2900 - accuracy: 0.8683 - val_loss: 0.6179 - val_accuracy: 0.8161\n","Epoch 328/1000\n","52/67 [======================>.......] - ETA: 0s - loss: 0.2998 - accuracy: 0.8654\n","Epoch 328: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3005 - accuracy: 0.8683 - val_loss: 0.6122 - val_accuracy: 0.8251\n","Epoch 329/1000\n","57/67 [========================>.....] - ETA: 0s - loss: 0.3065 - accuracy: 0.8807\n","Epoch 329: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3046 - accuracy: 0.8772 - val_loss: 0.6325 - val_accuracy: 0.8072\n","Epoch 330/1000\n","48/67 [====================>.........] - ETA: 0s - loss: 0.2788 - accuracy: 0.8750\n","Epoch 330: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2926 - accuracy: 0.8743 - val_loss: 0.6265 - val_accuracy: 0.7937\n","Epoch 331/1000\n","53/67 [======================>.......] - ETA: 0s - loss: 0.2864 - accuracy: 0.8868\n","Epoch 331: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2873 - accuracy: 0.8877 - val_loss: 0.6672 - val_accuracy: 0.8117\n","Epoch 332/1000\n","45/67 [===================>..........] - ETA: 0s - loss: 0.3039 - accuracy: 0.8711\n","Epoch 332: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2893 - accuracy: 0.8772 - val_loss: 0.6393 - val_accuracy: 0.8117\n","Epoch 333/1000\n","55/67 [=======================>......] - ETA: 0s - loss: 0.3017 - accuracy: 0.8782\n","Epoch 333: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3054 - accuracy: 0.8757 - val_loss: 0.6094 - val_accuracy: 0.8072\n","Epoch 334/1000\n","58/67 [========================>.....] - ETA: 0s - loss: 0.3375 - accuracy: 0.8862\n","Epoch 334: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3436 - accuracy: 0.8787 - val_loss: 0.5493 - val_accuracy: 0.8161\n","Epoch 335/1000\n","60/67 [=========================>....] - ETA: 0s - loss: 0.3036 - accuracy: 0.8750\n","Epoch 335: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3037 - accuracy: 0.8698 - val_loss: 0.5880 - val_accuracy: 0.8117\n","Epoch 336/1000\n","58/67 [========================>.....] - ETA: 0s - loss: 0.2837 - accuracy: 0.8741\n","Epoch 336: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2986 - accuracy: 0.8683 - val_loss: 0.6219 - val_accuracy: 0.7937\n","Epoch 337/1000\n","47/67 [====================>.........] - ETA: 0s - loss: 0.2969 - accuracy: 0.8723\n","Epoch 337: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2918 - accuracy: 0.8772 - val_loss: 0.6344 - val_accuracy: 0.8251\n","Epoch 338/1000\n","49/67 [====================>.........] - ETA: 0s - loss: 0.2979 - accuracy: 0.8837\n","Epoch 338: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2965 - accuracy: 0.8802 - val_loss: 0.6404 - val_accuracy: 0.8251\n","Epoch 339/1000\n","41/67 [=================>............] - ETA: 0s - loss: 0.3195 - accuracy: 0.8707\n","Epoch 339: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3145 - accuracy: 0.8757 - val_loss: 0.5662 - val_accuracy: 0.8251\n","Epoch 340/1000\n","51/67 [=====================>........] - ETA: 0s - loss: 0.3005 - accuracy: 0.8765\n","Epoch 340: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2988 - accuracy: 0.8787 - val_loss: 0.5920 - val_accuracy: 0.8117\n","Epoch 341/1000\n","54/67 [=======================>......] - ETA: 0s - loss: 0.3170 - accuracy: 0.8759\n","Epoch 341: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3115 - accuracy: 0.8757 - val_loss: 0.5803 - val_accuracy: 0.8072\n","Epoch 342/1000\n","60/67 [=========================>....] - ETA: 0s - loss: 0.2899 - accuracy: 0.8833\n","Epoch 342: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2917 - accuracy: 0.8847 - val_loss: 0.6142 - val_accuracy: 0.8072\n","Epoch 343/1000\n","47/67 [====================>.........] - ETA: 0s - loss: 0.2932 - accuracy: 0.8809\n","Epoch 343: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2908 - accuracy: 0.8802 - val_loss: 0.6263 - val_accuracy: 0.8161\n","Epoch 344/1000\n","52/67 [======================>.......] - ETA: 0s - loss: 0.2929 - accuracy: 0.8615\n","Epoch 344: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2892 - accuracy: 0.8668 - val_loss: 0.6055 - val_accuracy: 0.8117\n","Epoch 345/1000\n","54/67 [=======================>......] - ETA: 0s - loss: 0.2943 - accuracy: 0.8741\n","Epoch 345: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2785 - accuracy: 0.8847 - val_loss: 0.6417 - val_accuracy: 0.8027\n","Epoch 346/1000\n","52/67 [======================>.......] - ETA: 0s - loss: 0.2859 - accuracy: 0.8731\n","Epoch 346: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2905 - accuracy: 0.8728 - val_loss: 0.6004 - val_accuracy: 0.8117\n","Epoch 347/1000\n","53/67 [======================>.......] - ETA: 0s - loss: 0.2699 - accuracy: 0.8887\n","Epoch 347: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2884 - accuracy: 0.8802 - val_loss: 0.6036 - val_accuracy: 0.8206\n","Epoch 348/1000\n","54/67 [=======================>......] - ETA: 0s - loss: 0.2967 - accuracy: 0.8667\n","Epoch 348: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2990 - accuracy: 0.8683 - val_loss: 0.6058 - val_accuracy: 0.8206\n","Epoch 349/1000\n","60/67 [=========================>....] - ETA: 0s - loss: 0.2965 - accuracy: 0.8750\n","Epoch 349: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2963 - accuracy: 0.8772 - val_loss: 0.6130 - val_accuracy: 0.8296\n","Epoch 350/1000\n","53/67 [======================>.......] - ETA: 0s - loss: 0.2928 - accuracy: 0.8830\n","Epoch 350: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2981 - accuracy: 0.8832 - val_loss: 0.6205 - val_accuracy: 0.8161\n","Epoch 351/1000\n","52/67 [======================>.......] - ETA: 0s - loss: 0.2812 - accuracy: 0.8769\n","Epoch 351: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2763 - accuracy: 0.8802 - val_loss: 0.6441 - val_accuracy: 0.8072\n","Epoch 352/1000\n","45/67 [===================>..........] - ETA: 0s - loss: 0.2772 - accuracy: 0.8800\n","Epoch 352: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2814 - accuracy: 0.8802 - val_loss: 0.6450 - val_accuracy: 0.7982\n","Epoch 353/1000\n","59/67 [=========================>....] - ETA: 0s - loss: 0.2934 - accuracy: 0.8847\n","Epoch 353: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3041 - accuracy: 0.8802 - val_loss: 0.6234 - val_accuracy: 0.8206\n","Epoch 354/1000\n","55/67 [=======================>......] - ETA: 0s - loss: 0.3097 - accuracy: 0.8673\n","Epoch 354: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2961 - accuracy: 0.8743 - val_loss: 0.6214 - val_accuracy: 0.8251\n","Epoch 355/1000\n","56/67 [========================>.....] - ETA: 0s - loss: 0.2981 - accuracy: 0.8679\n","Epoch 355: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2831 - accuracy: 0.8787 - val_loss: 0.6111 - val_accuracy: 0.8161\n","Epoch 356/1000\n","55/67 [=======================>......] - ETA: 0s - loss: 0.2928 - accuracy: 0.8764\n","Epoch 356: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3006 - accuracy: 0.8772 - val_loss: 0.5625 - val_accuracy: 0.8206\n","Epoch 357/1000\n","55/67 [=======================>......] - ETA: 0s - loss: 0.3163 - accuracy: 0.8709\n","Epoch 357: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3022 - accuracy: 0.8772 - val_loss: 0.5826 - val_accuracy: 0.8072\n","Epoch 358/1000\n","63/67 [===========================>..] - ETA: 0s - loss: 0.2864 - accuracy: 0.8810\n","Epoch 358: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2906 - accuracy: 0.8787 - val_loss: 0.6046 - val_accuracy: 0.8161\n","Epoch 359/1000\n","61/67 [==========================>...] - ETA: 0s - loss: 0.2835 - accuracy: 0.8852\n","Epoch 359: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2913 - accuracy: 0.8817 - val_loss: 0.6472 - val_accuracy: 0.8117\n","Epoch 360/1000\n","59/67 [=========================>....] - ETA: 0s - loss: 0.2779 - accuracy: 0.8915\n","Epoch 360: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2851 - accuracy: 0.8832 - val_loss: 0.6456 - val_accuracy: 0.8117\n","Epoch 361/1000\n","53/67 [======================>.......] - ETA: 0s - loss: 0.2925 - accuracy: 0.8755\n","Epoch 361: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2838 - accuracy: 0.8802 - val_loss: 0.6515 - val_accuracy: 0.8072\n","Epoch 362/1000\n","55/67 [=======================>......] - ETA: 0s - loss: 0.2959 - accuracy: 0.8800\n","Epoch 362: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2786 - accuracy: 0.8877 - val_loss: 0.6785 - val_accuracy: 0.8251\n","Epoch 363/1000\n","62/67 [==========================>...] - ETA: 0s - loss: 0.2868 - accuracy: 0.8774\n","Epoch 363: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2950 - accuracy: 0.8743 - val_loss: 0.6322 - val_accuracy: 0.8206\n","Epoch 364/1000\n","53/67 [======================>.......] - ETA: 0s - loss: 0.3018 - accuracy: 0.8774\n","Epoch 364: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2928 - accuracy: 0.8772 - val_loss: 0.6172 - val_accuracy: 0.8161\n","Epoch 365/1000\n","52/67 [======================>.......] - ETA: 0s - loss: 0.2602 - accuracy: 0.8846\n","Epoch 365: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2969 - accuracy: 0.8772 - val_loss: 0.5785 - val_accuracy: 0.8117\n","Epoch 366/1000\n","47/67 [====================>.........] - ETA: 0s - loss: 0.3044 - accuracy: 0.8723\n","Epoch 366: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2933 - accuracy: 0.8757 - val_loss: 0.5821 - val_accuracy: 0.8027\n","Epoch 367/1000\n","57/67 [========================>.....] - ETA: 0s - loss: 0.3163 - accuracy: 0.8702\n","Epoch 367: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3043 - accuracy: 0.8728 - val_loss: 0.6184 - val_accuracy: 0.8072\n","Epoch 368/1000\n","44/67 [==================>...........] - ETA: 0s - loss: 0.2794 - accuracy: 0.8864\n","Epoch 368: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2860 - accuracy: 0.8832 - val_loss: 0.6324 - val_accuracy: 0.8251\n","Epoch 369/1000\n","54/67 [=======================>......] - ETA: 0s - loss: 0.2861 - accuracy: 0.8778\n","Epoch 369: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2890 - accuracy: 0.8817 - val_loss: 0.6586 - val_accuracy: 0.8117\n","Epoch 370/1000\n","56/67 [========================>.....] - ETA: 0s - loss: 0.2858 - accuracy: 0.8821\n","Epoch 370: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2912 - accuracy: 0.8743 - val_loss: 0.6307 - val_accuracy: 0.8161\n","Epoch 371/1000\n","54/67 [=======================>......] - ETA: 0s - loss: 0.2597 - accuracy: 0.8889\n","Epoch 371: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2827 - accuracy: 0.8802 - val_loss: 0.6356 - val_accuracy: 0.8072\n","Epoch 372/1000\n","58/67 [========================>.....] - ETA: 0s - loss: 0.2868 - accuracy: 0.8810\n","Epoch 372: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2892 - accuracy: 0.8787 - val_loss: 0.6385 - val_accuracy: 0.8072\n","Epoch 373/1000\n","53/67 [======================>.......] - ETA: 0s - loss: 0.3014 - accuracy: 0.8755\n","Epoch 373: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2874 - accuracy: 0.8847 - val_loss: 0.6230 - val_accuracy: 0.8386\n","Epoch 374/1000\n","61/67 [==========================>...] - ETA: 0s - loss: 0.2732 - accuracy: 0.8934\n","Epoch 374: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2860 - accuracy: 0.8877 - val_loss: 0.6628 - val_accuracy: 0.8161\n","Epoch 375/1000\n","60/67 [=========================>....] - ETA: 0s - loss: 0.2917 - accuracy: 0.8650\n","Epoch 375: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2946 - accuracy: 0.8683 - val_loss: 0.6207 - val_accuracy: 0.8251\n","Epoch 376/1000\n","51/67 [=====================>........] - ETA: 0s - loss: 0.2867 - accuracy: 0.8824\n","Epoch 376: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2927 - accuracy: 0.8802 - val_loss: 0.5894 - val_accuracy: 0.8251\n","Epoch 377/1000\n","51/67 [=====================>........] - ETA: 0s - loss: 0.2897 - accuracy: 0.8804\n","Epoch 377: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2882 - accuracy: 0.8817 - val_loss: 0.5882 - val_accuracy: 0.8251\n","Epoch 378/1000\n","57/67 [========================>.....] - ETA: 0s - loss: 0.2995 - accuracy: 0.8825\n","Epoch 378: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3105 - accuracy: 0.8757 - val_loss: 0.5525 - val_accuracy: 0.8161\n","Epoch 379/1000\n","41/67 [=================>............] - ETA: 0s - loss: 0.3133 - accuracy: 0.8683\n","Epoch 379: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2991 - accuracy: 0.8743 - val_loss: 0.5647 - val_accuracy: 0.8161\n","Epoch 380/1000\n","56/67 [========================>.....] - ETA: 0s - loss: 0.3075 - accuracy: 0.8661\n","Epoch 380: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3022 - accuracy: 0.8698 - val_loss: 0.5397 - val_accuracy: 0.8117\n","Epoch 381/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2990 - accuracy: 0.8696\n","Epoch 381: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3022 - accuracy: 0.8743 - val_loss: 0.5806 - val_accuracy: 0.8161\n","Epoch 382/1000\n","63/67 [===========================>..] - ETA: 0s - loss: 0.2955 - accuracy: 0.8762\n","Epoch 382: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2902 - accuracy: 0.8772 - val_loss: 0.6053 - val_accuracy: 0.8072\n","Epoch 383/1000\n","61/67 [==========================>...] - ETA: 0s - loss: 0.2796 - accuracy: 0.8836\n","Epoch 383: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2886 - accuracy: 0.8787 - val_loss: 0.6084 - val_accuracy: 0.8251\n","Epoch 384/1000\n","59/67 [=========================>....] - ETA: 0s - loss: 0.2939 - accuracy: 0.8780\n","Epoch 384: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2833 - accuracy: 0.8802 - val_loss: 0.5976 - val_accuracy: 0.8117\n","Epoch 385/1000\n","61/67 [==========================>...] - ETA: 0s - loss: 0.2923 - accuracy: 0.8820\n","Epoch 385: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2959 - accuracy: 0.8772 - val_loss: 0.5634 - val_accuracy: 0.8206\n","Epoch 386/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2731 - accuracy: 0.8935\n","Epoch 386: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2828 - accuracy: 0.8832 - val_loss: 0.6165 - val_accuracy: 0.8206\n","Epoch 387/1000\n","47/67 [====================>.........] - ETA: 0s - loss: 0.3057 - accuracy: 0.8660\n","Epoch 387: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3019 - accuracy: 0.8683 - val_loss: 0.6006 - val_accuracy: 0.8072\n","Epoch 388/1000\n","53/67 [======================>.......] - ETA: 0s - loss: 0.2588 - accuracy: 0.8925\n","Epoch 388: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2754 - accuracy: 0.8847 - val_loss: 0.6525 - val_accuracy: 0.8161\n","Epoch 389/1000\n","47/67 [====================>.........] - ETA: 0s - loss: 0.3057 - accuracy: 0.8617\n","Epoch 389: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2920 - accuracy: 0.8728 - val_loss: 0.6427 - val_accuracy: 0.8251\n","Epoch 390/1000\n","52/67 [======================>.......] - ETA: 0s - loss: 0.2673 - accuracy: 0.8865\n","Epoch 390: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2801 - accuracy: 0.8802 - val_loss: 0.6326 - val_accuracy: 0.8206\n","Epoch 391/1000\n","55/67 [=======================>......] - ETA: 0s - loss: 0.2783 - accuracy: 0.8836\n","Epoch 391: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2816 - accuracy: 0.8832 - val_loss: 0.6875 - val_accuracy: 0.8206\n","Epoch 392/1000\n","56/67 [========================>.....] - ETA: 0s - loss: 0.2918 - accuracy: 0.8768\n","Epoch 392: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2868 - accuracy: 0.8817 - val_loss: 0.6918 - val_accuracy: 0.8117\n","Epoch 393/1000\n","44/67 [==================>...........] - ETA: 0s - loss: 0.2771 - accuracy: 0.8841\n","Epoch 393: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2908 - accuracy: 0.8787 - val_loss: 0.6324 - val_accuracy: 0.8251\n","Epoch 394/1000\n","51/67 [=====================>........] - ETA: 0s - loss: 0.2809 - accuracy: 0.9000\n","Epoch 394: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2899 - accuracy: 0.8892 - val_loss: 0.6253 - val_accuracy: 0.8251\n","Epoch 395/1000\n","54/67 [=======================>......] - ETA: 0s - loss: 0.2867 - accuracy: 0.8833\n","Epoch 395: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2789 - accuracy: 0.8847 - val_loss: 0.6675 - val_accuracy: 0.8117\n","Epoch 396/1000\n","57/67 [========================>.....] - ETA: 0s - loss: 0.2952 - accuracy: 0.8737\n","Epoch 396: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2844 - accuracy: 0.8817 - val_loss: 0.6552 - val_accuracy: 0.8161\n","Epoch 397/1000\n","57/67 [========================>.....] - ETA: 0s - loss: 0.3024 - accuracy: 0.8702\n","Epoch 397: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2956 - accuracy: 0.8757 - val_loss: 0.6033 - val_accuracy: 0.8072\n","Epoch 398/1000\n","52/67 [======================>.......] - ETA: 0s - loss: 0.2870 - accuracy: 0.8712\n","Epoch 398: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2843 - accuracy: 0.8743 - val_loss: 0.6062 - val_accuracy: 0.8117\n","Epoch 399/1000\n","52/67 [======================>.......] - ETA: 0s - loss: 0.2860 - accuracy: 0.8808\n","Epoch 399: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2835 - accuracy: 0.8802 - val_loss: 0.5973 - val_accuracy: 0.8072\n","Epoch 400/1000\n","56/67 [========================>.....] - ETA: 0s - loss: 0.2788 - accuracy: 0.8875\n","Epoch 400: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2830 - accuracy: 0.8832 - val_loss: 0.6189 - val_accuracy: 0.8251\n","Epoch 401/1000\n","55/67 [=======================>......] - ETA: 0s - loss: 0.2883 - accuracy: 0.8909\n","Epoch 401: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2970 - accuracy: 0.8817 - val_loss: 0.5934 - val_accuracy: 0.8296\n","Epoch 402/1000\n","54/67 [=======================>......] - ETA: 0s - loss: 0.2835 - accuracy: 0.8852\n","Epoch 402: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2928 - accuracy: 0.8802 - val_loss: 0.6207 - val_accuracy: 0.8117\n","Epoch 403/1000\n","57/67 [========================>.....] - ETA: 0s - loss: 0.2709 - accuracy: 0.8877\n","Epoch 403: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2729 - accuracy: 0.8877 - val_loss: 0.6554 - val_accuracy: 0.7982\n","Epoch 404/1000\n","42/67 [=================>............] - ETA: 0s - loss: 0.2716 - accuracy: 0.8881\n","Epoch 404: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2821 - accuracy: 0.8877 - val_loss: 0.6387 - val_accuracy: 0.8072\n","Epoch 405/1000\n","48/67 [====================>.........] - ETA: 0s - loss: 0.3038 - accuracy: 0.8750\n","Epoch 405: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3087 - accuracy: 0.8713 - val_loss: 0.6302 - val_accuracy: 0.8072\n","Epoch 406/1000\n","51/67 [=====================>........] - ETA: 0s - loss: 0.2883 - accuracy: 0.8784\n","Epoch 406: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2835 - accuracy: 0.8847 - val_loss: 0.6476 - val_accuracy: 0.8072\n","Epoch 407/1000\n","54/67 [=======================>......] - ETA: 0s - loss: 0.3230 - accuracy: 0.8648\n","Epoch 407: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2965 - accuracy: 0.8802 - val_loss: 0.6221 - val_accuracy: 0.8251\n","Epoch 408/1000\n","55/67 [=======================>......] - ETA: 0s - loss: 0.2851 - accuracy: 0.8782\n","Epoch 408: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2785 - accuracy: 0.8802 - val_loss: 0.6801 - val_accuracy: 0.8117\n","Epoch 409/1000\n","56/67 [========================>.....] - ETA: 0s - loss: 0.2888 - accuracy: 0.8821\n","Epoch 409: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2860 - accuracy: 0.8832 - val_loss: 0.6128 - val_accuracy: 0.8341\n","Epoch 410/1000\n","49/67 [====================>.........] - ETA: 0s - loss: 0.2850 - accuracy: 0.8755\n","Epoch 410: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2927 - accuracy: 0.8728 - val_loss: 0.6601 - val_accuracy: 0.8161\n","Epoch 411/1000\n","51/67 [=====================>........] - ETA: 0s - loss: 0.2811 - accuracy: 0.8843\n","Epoch 411: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2912 - accuracy: 0.8757 - val_loss: 0.6497 - val_accuracy: 0.8206\n","Epoch 412/1000\n","57/67 [========================>.....] - ETA: 0s - loss: 0.2940 - accuracy: 0.8737\n","Epoch 412: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2878 - accuracy: 0.8772 - val_loss: 0.6735 - val_accuracy: 0.8206\n","Epoch 413/1000\n","52/67 [======================>.......] - ETA: 0s - loss: 0.2905 - accuracy: 0.8712\n","Epoch 413: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2894 - accuracy: 0.8757 - val_loss: 0.6094 - val_accuracy: 0.8206\n","Epoch 414/1000\n","56/67 [========================>.....] - ETA: 0s - loss: 0.2872 - accuracy: 0.8786\n","Epoch 414: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2783 - accuracy: 0.8817 - val_loss: 0.6533 - val_accuracy: 0.8296\n","Epoch 415/1000\n","55/67 [=======================>......] - ETA: 0s - loss: 0.2869 - accuracy: 0.8727\n","Epoch 415: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2850 - accuracy: 0.8772 - val_loss: 0.6516 - val_accuracy: 0.8296\n","Epoch 416/1000\n","51/67 [=====================>........] - ETA: 0s - loss: 0.3019 - accuracy: 0.8667\n","Epoch 416: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2876 - accuracy: 0.8772 - val_loss: 0.7037 - val_accuracy: 0.8117\n","Epoch 417/1000\n","59/67 [=========================>....] - ETA: 0s - loss: 0.2822 - accuracy: 0.8780\n","Epoch 417: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2861 - accuracy: 0.8772 - val_loss: 0.6830 - val_accuracy: 0.8206\n","Epoch 418/1000\n","54/67 [=======================>......] - ETA: 0s - loss: 0.2731 - accuracy: 0.8815\n","Epoch 418: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2871 - accuracy: 0.8787 - val_loss: 0.6454 - val_accuracy: 0.8206\n","Epoch 419/1000\n","49/67 [====================>.........] - ETA: 0s - loss: 0.2894 - accuracy: 0.8796\n","Epoch 419: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2936 - accuracy: 0.8743 - val_loss: 0.6415 - val_accuracy: 0.8251\n","Epoch 420/1000\n","49/67 [====================>.........] - ETA: 0s - loss: 0.2856 - accuracy: 0.8816\n","Epoch 420: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2845 - accuracy: 0.8817 - val_loss: 0.6750 - val_accuracy: 0.8117\n","Epoch 421/1000\n","52/67 [======================>.......] - ETA: 0s - loss: 0.2636 - accuracy: 0.8942\n","Epoch 421: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2720 - accuracy: 0.8892 - val_loss: 0.6563 - val_accuracy: 0.8161\n","Epoch 422/1000\n","48/67 [====================>.........] - ETA: 0s - loss: 0.2804 - accuracy: 0.8792\n","Epoch 422: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2906 - accuracy: 0.8772 - val_loss: 0.6596 - val_accuracy: 0.8161\n","Epoch 423/1000\n","51/67 [=====================>........] - ETA: 0s - loss: 0.2862 - accuracy: 0.8804\n","Epoch 423: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2815 - accuracy: 0.8787 - val_loss: 0.6787 - val_accuracy: 0.8161\n","Epoch 424/1000\n","59/67 [=========================>....] - ETA: 0s - loss: 0.2927 - accuracy: 0.8695\n","Epoch 424: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2851 - accuracy: 0.8757 - val_loss: 0.6296 - val_accuracy: 0.8296\n","Epoch 425/1000\n","55/67 [=======================>......] - ETA: 0s - loss: 0.2621 - accuracy: 0.8927\n","Epoch 425: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2787 - accuracy: 0.8877 - val_loss: 0.6567 - val_accuracy: 0.8027\n","Epoch 426/1000\n","52/67 [======================>.......] - ETA: 0s - loss: 0.2832 - accuracy: 0.8846\n","Epoch 426: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2817 - accuracy: 0.8862 - val_loss: 0.6250 - val_accuracy: 0.8161\n","Epoch 427/1000\n","63/67 [===========================>..] - ETA: 0s - loss: 0.2877 - accuracy: 0.8857\n","Epoch 427: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 5ms/step - loss: 0.2909 - accuracy: 0.8817 - val_loss: 0.7024 - val_accuracy: 0.7982\n","Epoch 428/1000\n","64/67 [===========================>..] - ETA: 0s - loss: 0.2719 - accuracy: 0.8797\n","Epoch 428: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2706 - accuracy: 0.8802 - val_loss: 0.7244 - val_accuracy: 0.8027\n","Epoch 429/1000\n","50/67 [=====================>........] - ETA: 0s - loss: 0.2655 - accuracy: 0.8900\n","Epoch 429: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2961 - accuracy: 0.8757 - val_loss: 0.6631 - val_accuracy: 0.8072\n","Epoch 430/1000\n","49/67 [====================>.........] - ETA: 0s - loss: 0.2752 - accuracy: 0.9000\n","Epoch 430: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3101 - accuracy: 0.8862 - val_loss: 0.6358 - val_accuracy: 0.8117\n","Epoch 431/1000\n","51/67 [=====================>........] - ETA: 0s - loss: 0.3038 - accuracy: 0.8745\n","Epoch 431: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2897 - accuracy: 0.8817 - val_loss: 0.6482 - val_accuracy: 0.7937\n","Epoch 432/1000\n","45/67 [===================>..........] - ETA: 0s - loss: 0.2897 - accuracy: 0.8822\n","Epoch 432: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2830 - accuracy: 0.8817 - val_loss: 0.6379 - val_accuracy: 0.8117\n","Epoch 433/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2947 - accuracy: 0.8717\n","Epoch 433: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2889 - accuracy: 0.8713 - val_loss: 0.6286 - val_accuracy: 0.8117\n","Epoch 434/1000\n","58/67 [========================>.....] - ETA: 0s - loss: 0.2867 - accuracy: 0.8741\n","Epoch 434: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2836 - accuracy: 0.8802 - val_loss: 0.6253 - val_accuracy: 0.7982\n","Epoch 435/1000\n","45/67 [===================>..........] - ETA: 0s - loss: 0.2982 - accuracy: 0.8711\n","Epoch 435: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2835 - accuracy: 0.8832 - val_loss: 0.6782 - val_accuracy: 0.8072\n","Epoch 436/1000\n","58/67 [========================>.....] - ETA: 0s - loss: 0.3579 - accuracy: 0.8810\n","Epoch 436: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.3428 - accuracy: 0.8817 - val_loss: 0.6086 - val_accuracy: 0.8072\n","Epoch 437/1000\n","52/67 [======================>.......] - ETA: 0s - loss: 0.2696 - accuracy: 0.8846\n","Epoch 437: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2690 - accuracy: 0.8877 - val_loss: 0.6387 - val_accuracy: 0.8072\n","Epoch 438/1000\n","44/67 [==================>...........] - ETA: 0s - loss: 0.2661 - accuracy: 0.8977\n","Epoch 438: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2885 - accuracy: 0.8877 - val_loss: 0.6255 - val_accuracy: 0.8161\n","Epoch 439/1000\n","47/67 [====================>.........] - ETA: 0s - loss: 0.2608 - accuracy: 0.8894\n","Epoch 439: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2795 - accuracy: 0.8832 - val_loss: 0.6166 - val_accuracy: 0.8251\n","Epoch 440/1000\n","56/67 [========================>.....] - ETA: 0s - loss: 0.2890 - accuracy: 0.8679\n","Epoch 440: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2721 - accuracy: 0.8802 - val_loss: 0.6665 - val_accuracy: 0.8206\n","Epoch 441/1000\n","48/67 [====================>.........] - ETA: 0s - loss: 0.2865 - accuracy: 0.9000\n","Epoch 441: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2931 - accuracy: 0.8877 - val_loss: 0.6626 - val_accuracy: 0.8251\n","Epoch 442/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2816 - accuracy: 0.8891\n","Epoch 442: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2791 - accuracy: 0.8877 - val_loss: 0.6636 - val_accuracy: 0.8251\n","Epoch 443/1000\n","45/67 [===================>..........] - ETA: 0s - loss: 0.2614 - accuracy: 0.8978\n","Epoch 443: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2745 - accuracy: 0.8862 - val_loss: 0.6629 - val_accuracy: 0.8206\n","Epoch 444/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.3009 - accuracy: 0.8891\n","Epoch 444: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2943 - accuracy: 0.8817 - val_loss: 0.6340 - val_accuracy: 0.8161\n","Epoch 445/1000\n","52/67 [======================>.......] - ETA: 0s - loss: 0.2895 - accuracy: 0.8692\n","Epoch 445: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2913 - accuracy: 0.8683 - val_loss: 0.6678 - val_accuracy: 0.8206\n","Epoch 446/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.3156 - accuracy: 0.8696\n","Epoch 446: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3082 - accuracy: 0.8757 - val_loss: 0.5629 - val_accuracy: 0.8027\n","Epoch 447/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2826 - accuracy: 0.8848\n","Epoch 447: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2917 - accuracy: 0.8772 - val_loss: 0.6096 - val_accuracy: 0.8117\n","Epoch 448/1000\n","50/67 [=====================>........] - ETA: 0s - loss: 0.3175 - accuracy: 0.8660\n","Epoch 448: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3055 - accuracy: 0.8713 - val_loss: 0.6369 - val_accuracy: 0.8117\n","Epoch 449/1000\n","42/67 [=================>............] - ETA: 0s - loss: 0.2995 - accuracy: 0.8762\n","Epoch 449: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2889 - accuracy: 0.8772 - val_loss: 0.6374 - val_accuracy: 0.8251\n","Epoch 450/1000\n","53/67 [======================>.......] - ETA: 0s - loss: 0.2768 - accuracy: 0.8792\n","Epoch 450: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2742 - accuracy: 0.8787 - val_loss: 0.6613 - val_accuracy: 0.7982\n","Epoch 451/1000\n","47/67 [====================>.........] - ETA: 0s - loss: 0.2503 - accuracy: 0.9043\n","Epoch 451: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2742 - accuracy: 0.8862 - val_loss: 0.7150 - val_accuracy: 0.7982\n","Epoch 452/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.2707 - accuracy: 0.8787\n","Epoch 452: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2707 - accuracy: 0.8787 - val_loss: 0.7075 - val_accuracy: 0.8117\n","Epoch 453/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2740 - accuracy: 0.8913\n","Epoch 453: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2696 - accuracy: 0.8937 - val_loss: 0.6800 - val_accuracy: 0.8117\n","Epoch 454/1000\n","40/67 [================>.............] - ETA: 0s - loss: 0.2931 - accuracy: 0.8775\n","Epoch 454: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2934 - accuracy: 0.8772 - val_loss: 0.6679 - val_accuracy: 0.8206\n","Epoch 455/1000\n","51/67 [=====================>........] - ETA: 0s - loss: 0.2647 - accuracy: 0.8941\n","Epoch 455: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2759 - accuracy: 0.8877 - val_loss: 0.6356 - val_accuracy: 0.8027\n","Epoch 456/1000\n","53/67 [======================>.......] - ETA: 0s - loss: 0.2702 - accuracy: 0.8830\n","Epoch 456: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2768 - accuracy: 0.8802 - val_loss: 0.6716 - val_accuracy: 0.8027\n","Epoch 457/1000\n","42/67 [=================>............] - ETA: 0s - loss: 0.3179 - accuracy: 0.8690\n","Epoch 457: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2747 - accuracy: 0.8862 - val_loss: 0.6341 - val_accuracy: 0.8117\n","Epoch 458/1000\n","52/67 [======================>.......] - ETA: 0s - loss: 0.2955 - accuracy: 0.8769\n","Epoch 458: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2823 - accuracy: 0.8832 - val_loss: 0.6303 - val_accuracy: 0.8117\n","Epoch 459/1000\n","52/67 [======================>.......] - ETA: 0s - loss: 0.2665 - accuracy: 0.8942\n","Epoch 459: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2852 - accuracy: 0.8817 - val_loss: 0.6292 - val_accuracy: 0.8161\n","Epoch 460/1000\n","56/67 [========================>.....] - ETA: 0s - loss: 0.2686 - accuracy: 0.8857\n","Epoch 460: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2750 - accuracy: 0.8832 - val_loss: 0.6270 - val_accuracy: 0.8117\n","Epoch 461/1000\n","49/67 [====================>.........] - ETA: 0s - loss: 0.3002 - accuracy: 0.8653\n","Epoch 461: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2832 - accuracy: 0.8787 - val_loss: 0.6464 - val_accuracy: 0.8117\n","Epoch 462/1000\n","45/67 [===================>..........] - ETA: 0s - loss: 0.2919 - accuracy: 0.8756\n","Epoch 462: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2791 - accuracy: 0.8772 - val_loss: 0.7024 - val_accuracy: 0.8206\n","Epoch 463/1000\n","48/67 [====================>.........] - ETA: 0s - loss: 0.2852 - accuracy: 0.8771\n","Epoch 463: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2812 - accuracy: 0.8817 - val_loss: 0.6893 - val_accuracy: 0.8251\n","Epoch 464/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2659 - accuracy: 0.8804\n","Epoch 464: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2807 - accuracy: 0.8728 - val_loss: 0.6972 - val_accuracy: 0.8072\n","Epoch 465/1000\n","44/67 [==================>...........] - ETA: 0s - loss: 0.2730 - accuracy: 0.8795\n","Epoch 465: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2827 - accuracy: 0.8757 - val_loss: 0.7251 - val_accuracy: 0.8161\n","Epoch 466/1000\n","54/67 [=======================>......] - ETA: 0s - loss: 0.2831 - accuracy: 0.8759\n","Epoch 466: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2780 - accuracy: 0.8832 - val_loss: 0.7059 - val_accuracy: 0.8161\n","Epoch 467/1000\n","52/67 [======================>.......] - ETA: 0s - loss: 0.2698 - accuracy: 0.8885\n","Epoch 467: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2756 - accuracy: 0.8832 - val_loss: 0.7075 - val_accuracy: 0.8206\n","Epoch 468/1000\n","45/67 [===================>..........] - ETA: 0s - loss: 0.2647 - accuracy: 0.8778\n","Epoch 468: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2725 - accuracy: 0.8772 - val_loss: 0.7380 - val_accuracy: 0.8117\n","Epoch 469/1000\n","47/67 [====================>.........] - ETA: 0s - loss: 0.2959 - accuracy: 0.8787\n","Epoch 469: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2898 - accuracy: 0.8772 - val_loss: 0.6678 - val_accuracy: 0.8072\n","Epoch 470/1000\n","63/67 [===========================>..] - ETA: 0s - loss: 0.2864 - accuracy: 0.8730\n","Epoch 470: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2854 - accuracy: 0.8743 - val_loss: 0.6980 - val_accuracy: 0.8072\n","Epoch 471/1000\n","48/67 [====================>.........] - ETA: 0s - loss: 0.2892 - accuracy: 0.8750\n","Epoch 471: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2863 - accuracy: 0.8757 - val_loss: 0.7050 - val_accuracy: 0.8161\n","Epoch 472/1000\n","40/67 [================>.............] - ETA: 0s - loss: 0.2789 - accuracy: 0.8750\n","Epoch 472: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2818 - accuracy: 0.8787 - val_loss: 0.7019 - val_accuracy: 0.8117\n","Epoch 473/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2744 - accuracy: 0.8978\n","Epoch 473: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2948 - accuracy: 0.8832 - val_loss: 0.6708 - val_accuracy: 0.7982\n","Epoch 474/1000\n","50/67 [=====================>........] - ETA: 0s - loss: 0.2830 - accuracy: 0.8780\n","Epoch 474: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2938 - accuracy: 0.8728 - val_loss: 0.6512 - val_accuracy: 0.8117\n","Epoch 475/1000\n","53/67 [======================>.......] - ETA: 0s - loss: 0.2734 - accuracy: 0.8830\n","Epoch 475: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2851 - accuracy: 0.8713 - val_loss: 0.6767 - val_accuracy: 0.8027\n","Epoch 476/1000\n","50/67 [=====================>........] - ETA: 0s - loss: 0.2918 - accuracy: 0.8680\n","Epoch 476: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2835 - accuracy: 0.8772 - val_loss: 0.6715 - val_accuracy: 0.8161\n","Epoch 477/1000\n","53/67 [======================>.......] - ETA: 0s - loss: 0.2878 - accuracy: 0.8717\n","Epoch 477: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2824 - accuracy: 0.8757 - val_loss: 0.6408 - val_accuracy: 0.8206\n","Epoch 478/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2823 - accuracy: 0.8761\n","Epoch 478: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2750 - accuracy: 0.8832 - val_loss: 0.6991 - val_accuracy: 0.8072\n","Epoch 479/1000\n","47/67 [====================>.........] - ETA: 0s - loss: 0.3229 - accuracy: 0.8638\n","Epoch 479: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2878 - accuracy: 0.8787 - val_loss: 0.6562 - val_accuracy: 0.8161\n","Epoch 480/1000\n","47/67 [====================>.........] - ETA: 0s - loss: 0.2645 - accuracy: 0.8809\n","Epoch 480: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2928 - accuracy: 0.8698 - val_loss: 0.6199 - val_accuracy: 0.8161\n","Epoch 481/1000\n","52/67 [======================>.......] - ETA: 0s - loss: 0.2640 - accuracy: 0.8865\n","Epoch 481: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2851 - accuracy: 0.8772 - val_loss: 0.6604 - val_accuracy: 0.8206\n","Epoch 482/1000\n","54/67 [=======================>......] - ETA: 0s - loss: 0.2989 - accuracy: 0.8667\n","Epoch 482: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2851 - accuracy: 0.8728 - val_loss: 0.6590 - val_accuracy: 0.8206\n","Epoch 483/1000\n","55/67 [=======================>......] - ETA: 0s - loss: 0.2673 - accuracy: 0.8945\n","Epoch 483: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2765 - accuracy: 0.8862 - val_loss: 0.6856 - val_accuracy: 0.8296\n","Epoch 484/1000\n","41/67 [=================>............] - ETA: 0s - loss: 0.2845 - accuracy: 0.8829\n","Epoch 484: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2857 - accuracy: 0.8847 - val_loss: 0.6896 - val_accuracy: 0.8206\n","Epoch 485/1000\n","50/67 [=====================>........] - ETA: 0s - loss: 0.2663 - accuracy: 0.8940\n","Epoch 485: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2825 - accuracy: 0.8847 - val_loss: 0.6542 - val_accuracy: 0.8251\n","Epoch 486/1000\n","47/67 [====================>.........] - ETA: 0s - loss: 0.2843 - accuracy: 0.8851\n","Epoch 486: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2842 - accuracy: 0.8772 - val_loss: 0.6353 - val_accuracy: 0.8206\n","Epoch 487/1000\n","50/67 [=====================>........] - ETA: 0s - loss: 0.2565 - accuracy: 0.8920\n","Epoch 487: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2817 - accuracy: 0.8862 - val_loss: 0.6505 - val_accuracy: 0.8027\n","Epoch 488/1000\n","49/67 [====================>.........] - ETA: 0s - loss: 0.2861 - accuracy: 0.8816\n","Epoch 488: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2956 - accuracy: 0.8802 - val_loss: 0.6351 - val_accuracy: 0.8027\n","Epoch 489/1000\n","45/67 [===================>..........] - ETA: 0s - loss: 0.2840 - accuracy: 0.8778\n","Epoch 489: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2850 - accuracy: 0.8757 - val_loss: 0.6307 - val_accuracy: 0.8072\n","Epoch 490/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2789 - accuracy: 0.8804\n","Epoch 490: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2774 - accuracy: 0.8862 - val_loss: 0.6707 - val_accuracy: 0.7982\n","Epoch 491/1000\n","65/67 [============================>.] - ETA: 0s - loss: 0.2903 - accuracy: 0.8738\n","Epoch 491: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2876 - accuracy: 0.8743 - val_loss: 0.6915 - val_accuracy: 0.8161\n","Epoch 492/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2891 - accuracy: 0.8804\n","Epoch 492: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2779 - accuracy: 0.8802 - val_loss: 0.6569 - val_accuracy: 0.8206\n","Epoch 493/1000\n","44/67 [==================>...........] - ETA: 0s - loss: 0.2573 - accuracy: 0.8864\n","Epoch 493: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2760 - accuracy: 0.8787 - val_loss: 0.7018 - val_accuracy: 0.8072\n","Epoch 494/1000\n","41/67 [=================>............] - ETA: 0s - loss: 0.2716 - accuracy: 0.8780\n","Epoch 494: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2706 - accuracy: 0.8787 - val_loss: 0.6909 - val_accuracy: 0.8027\n","Epoch 495/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2756 - accuracy: 0.8826\n","Epoch 495: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2741 - accuracy: 0.8832 - val_loss: 0.7184 - val_accuracy: 0.8251\n","Epoch 496/1000\n","64/67 [===========================>..] - ETA: 0s - loss: 0.2789 - accuracy: 0.8813\n","Epoch 496: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2785 - accuracy: 0.8817 - val_loss: 0.6671 - val_accuracy: 0.8117\n","Epoch 497/1000\n","55/67 [=======================>......] - ETA: 0s - loss: 0.2806 - accuracy: 0.8836\n","Epoch 497: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2731 - accuracy: 0.8847 - val_loss: 0.7173 - val_accuracy: 0.8206\n","Epoch 498/1000\n","51/67 [=====================>........] - ETA: 0s - loss: 0.2882 - accuracy: 0.8804\n","Epoch 498: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2793 - accuracy: 0.8817 - val_loss: 0.6790 - val_accuracy: 0.8251\n","Epoch 499/1000\n","45/67 [===================>..........] - ETA: 0s - loss: 0.2731 - accuracy: 0.8867\n","Epoch 499: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2818 - accuracy: 0.8802 - val_loss: 0.6698 - val_accuracy: 0.8161\n","Epoch 500/1000\n","47/67 [====================>.........] - ETA: 0s - loss: 0.3010 - accuracy: 0.8702\n","Epoch 500: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2908 - accuracy: 0.8787 - val_loss: 0.6079 - val_accuracy: 0.8296\n","Epoch 501/1000\n","38/67 [================>.............] - ETA: 0s - loss: 0.2703 - accuracy: 0.8947\n","Epoch 501: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2711 - accuracy: 0.8907 - val_loss: 0.6522 - val_accuracy: 0.8161\n","Epoch 502/1000\n","43/67 [==================>...........] - ETA: 0s - loss: 0.2960 - accuracy: 0.8721\n","Epoch 502: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2810 - accuracy: 0.8787 - val_loss: 0.6706 - val_accuracy: 0.8161\n","Epoch 503/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2959 - accuracy: 0.8870\n","Epoch 503: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2915 - accuracy: 0.8862 - val_loss: 0.6598 - val_accuracy: 0.8117\n","Epoch 504/1000\n","54/67 [=======================>......] - ETA: 0s - loss: 0.2715 - accuracy: 0.8833\n","Epoch 504: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2762 - accuracy: 0.8817 - val_loss: 0.6633 - val_accuracy: 0.8117\n","Epoch 505/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2506 - accuracy: 0.9000\n","Epoch 505: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2680 - accuracy: 0.8922 - val_loss: 0.6641 - val_accuracy: 0.8206\n","Epoch 506/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.2832 - accuracy: 0.8712\n","Epoch 506: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2804 - accuracy: 0.8728 - val_loss: 0.6819 - val_accuracy: 0.8206\n","Epoch 507/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.2666 - accuracy: 0.8833\n","Epoch 507: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2646 - accuracy: 0.8847 - val_loss: 0.6856 - val_accuracy: 0.8161\n","Epoch 508/1000\n","43/67 [==================>...........] - ETA: 0s - loss: 0.3004 - accuracy: 0.8767\n","Epoch 508: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2801 - accuracy: 0.8892 - val_loss: 0.7215 - val_accuracy: 0.8161\n","Epoch 509/1000\n","50/67 [=====================>........] - ETA: 0s - loss: 0.2875 - accuracy: 0.8760\n","Epoch 509: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2851 - accuracy: 0.8802 - val_loss: 0.7090 - val_accuracy: 0.8161\n","Epoch 510/1000\n","55/67 [=======================>......] - ETA: 0s - loss: 0.2710 - accuracy: 0.8855\n","Epoch 510: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2767 - accuracy: 0.8832 - val_loss: 0.7130 - val_accuracy: 0.8206\n","Epoch 511/1000\n","51/67 [=====================>........] - ETA: 0s - loss: 0.2983 - accuracy: 0.8725\n","Epoch 511: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2868 - accuracy: 0.8787 - val_loss: 0.7178 - val_accuracy: 0.7982\n","Epoch 512/1000\n","50/67 [=====================>........] - ETA: 0s - loss: 0.2917 - accuracy: 0.8840\n","Epoch 512: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2916 - accuracy: 0.8892 - val_loss: 0.6867 - val_accuracy: 0.8072\n","Epoch 513/1000\n","48/67 [====================>.........] - ETA: 0s - loss: 0.2667 - accuracy: 0.8896\n","Epoch 513: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2821 - accuracy: 0.8802 - val_loss: 0.7458 - val_accuracy: 0.8027\n","Epoch 514/1000\n","45/67 [===================>..........] - ETA: 0s - loss: 0.2824 - accuracy: 0.8689\n","Epoch 514: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2757 - accuracy: 0.8772 - val_loss: 0.7329 - val_accuracy: 0.8161\n","Epoch 515/1000\n","63/67 [===========================>..] - ETA: 0s - loss: 0.2818 - accuracy: 0.8825\n","Epoch 515: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2818 - accuracy: 0.8802 - val_loss: 0.7232 - val_accuracy: 0.8161\n","Epoch 516/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.2771 - accuracy: 0.8773\n","Epoch 516: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2742 - accuracy: 0.8787 - val_loss: 0.7254 - val_accuracy: 0.8072\n","Epoch 517/1000\n","47/67 [====================>.........] - ETA: 0s - loss: 0.2754 - accuracy: 0.8809\n","Epoch 517: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2691 - accuracy: 0.8892 - val_loss: 0.7459 - val_accuracy: 0.8027\n","Epoch 518/1000\n","54/67 [=======================>......] - ETA: 0s - loss: 0.3078 - accuracy: 0.8759\n","Epoch 518: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3029 - accuracy: 0.8772 - val_loss: 0.7027 - val_accuracy: 0.8027\n","Epoch 519/1000\n","56/67 [========================>.....] - ETA: 0s - loss: 0.2659 - accuracy: 0.8839\n","Epoch 519: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2723 - accuracy: 0.8802 - val_loss: 0.6657 - val_accuracy: 0.8027\n","Epoch 520/1000\n","52/67 [======================>.......] - ETA: 0s - loss: 0.2849 - accuracy: 0.8731\n","Epoch 520: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2757 - accuracy: 0.8832 - val_loss: 0.6854 - val_accuracy: 0.8206\n","Epoch 521/1000\n","47/67 [====================>.........] - ETA: 0s - loss: 0.2561 - accuracy: 0.8957\n","Epoch 521: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2772 - accuracy: 0.8802 - val_loss: 0.6909 - val_accuracy: 0.8161\n","Epoch 522/1000\n","49/67 [====================>.........] - ETA: 0s - loss: 0.2732 - accuracy: 0.8776\n","Epoch 522: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2700 - accuracy: 0.8743 - val_loss: 0.6999 - val_accuracy: 0.8072\n","Epoch 523/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2824 - accuracy: 0.8804\n","Epoch 523: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2841 - accuracy: 0.8787 - val_loss: 0.6947 - val_accuracy: 0.8251\n","Epoch 524/1000\n","49/67 [====================>.........] - ETA: 0s - loss: 0.2849 - accuracy: 0.8837\n","Epoch 524: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2803 - accuracy: 0.8772 - val_loss: 0.6312 - val_accuracy: 0.7982\n","Epoch 525/1000\n","49/67 [====================>.........] - ETA: 0s - loss: 0.2845 - accuracy: 0.8776\n","Epoch 525: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2854 - accuracy: 0.8743 - val_loss: 0.6301 - val_accuracy: 0.8161\n","Epoch 526/1000\n","53/67 [======================>.......] - ETA: 0s - loss: 0.2686 - accuracy: 0.8906\n","Epoch 526: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2749 - accuracy: 0.8862 - val_loss: 0.6615 - val_accuracy: 0.8027\n","Epoch 527/1000\n","45/67 [===================>..........] - ETA: 0s - loss: 0.3027 - accuracy: 0.8578\n","Epoch 527: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2826 - accuracy: 0.8728 - val_loss: 0.7025 - val_accuracy: 0.8072\n","Epoch 528/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.2796 - accuracy: 0.8862\n","Epoch 528: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2796 - accuracy: 0.8862 - val_loss: 0.7029 - val_accuracy: 0.8072\n","Epoch 529/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.3099 - accuracy: 0.8757\n","Epoch 529: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3099 - accuracy: 0.8757 - val_loss: 0.6031 - val_accuracy: 0.8161\n","Epoch 530/1000\n","42/67 [=================>............] - ETA: 0s - loss: 0.2813 - accuracy: 0.8857\n","Epoch 530: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2820 - accuracy: 0.8802 - val_loss: 0.6756 - val_accuracy: 0.8161\n","Epoch 531/1000\n","49/67 [====================>.........] - ETA: 0s - loss: 0.2794 - accuracy: 0.8837\n","Epoch 531: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2762 - accuracy: 0.8877 - val_loss: 0.6867 - val_accuracy: 0.8251\n","Epoch 532/1000\n","57/67 [========================>.....] - ETA: 0s - loss: 0.2686 - accuracy: 0.8912\n","Epoch 532: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2741 - accuracy: 0.8847 - val_loss: 0.7049 - val_accuracy: 0.8117\n","Epoch 533/1000\n","47/67 [====================>.........] - ETA: 0s - loss: 0.2764 - accuracy: 0.8723\n","Epoch 533: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2716 - accuracy: 0.8728 - val_loss: 0.7162 - val_accuracy: 0.8072\n","Epoch 534/1000\n","65/67 [============================>.] - ETA: 0s - loss: 0.2712 - accuracy: 0.8862\n","Epoch 534: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2758 - accuracy: 0.8832 - val_loss: 0.6683 - val_accuracy: 0.8161\n","Epoch 535/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.2622 - accuracy: 0.8894\n","Epoch 535: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2692 - accuracy: 0.8862 - val_loss: 0.7047 - val_accuracy: 0.8027\n","Epoch 536/1000\n","55/67 [=======================>......] - ETA: 0s - loss: 0.2746 - accuracy: 0.8800\n","Epoch 536: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2858 - accuracy: 0.8817 - val_loss: 0.6609 - val_accuracy: 0.8072\n","Epoch 537/1000\n","48/67 [====================>.........] - ETA: 0s - loss: 0.2826 - accuracy: 0.8854\n","Epoch 537: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2768 - accuracy: 0.8847 - val_loss: 0.6615 - val_accuracy: 0.8072\n","Epoch 538/1000\n","58/67 [========================>.....] - ETA: 0s - loss: 0.2683 - accuracy: 0.8862\n","Epoch 538: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2683 - accuracy: 0.8877 - val_loss: 0.7104 - val_accuracy: 0.8027\n","Epoch 539/1000\n","45/67 [===================>..........] - ETA: 0s - loss: 0.2714 - accuracy: 0.8800\n","Epoch 539: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2731 - accuracy: 0.8817 - val_loss: 0.7160 - val_accuracy: 0.8161\n","Epoch 540/1000\n","41/67 [=================>............] - ETA: 0s - loss: 0.2683 - accuracy: 0.8951\n","Epoch 540: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2671 - accuracy: 0.8877 - val_loss: 0.7554 - val_accuracy: 0.8072\n","Epoch 541/1000\n","58/67 [========================>.....] - ETA: 0s - loss: 0.2833 - accuracy: 0.8810\n","Epoch 541: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2821 - accuracy: 0.8802 - val_loss: 0.6570 - val_accuracy: 0.8161\n","Epoch 542/1000\n","53/67 [======================>.......] - ETA: 0s - loss: 0.2751 - accuracy: 0.8811\n","Epoch 542: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2815 - accuracy: 0.8817 - val_loss: 0.6853 - val_accuracy: 0.8072\n","Epoch 543/1000\n","63/67 [===========================>..] - ETA: 0s - loss: 0.2828 - accuracy: 0.8825\n","Epoch 543: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2769 - accuracy: 0.8847 - val_loss: 0.6968 - val_accuracy: 0.8072\n","Epoch 544/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2587 - accuracy: 0.8957\n","Epoch 544: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2734 - accuracy: 0.8877 - val_loss: 0.6508 - val_accuracy: 0.8072\n","Epoch 545/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2738 - accuracy: 0.8826\n","Epoch 545: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2870 - accuracy: 0.8802 - val_loss: 0.7254 - val_accuracy: 0.8072\n","Epoch 546/1000\n","55/67 [=======================>......] - ETA: 0s - loss: 0.2821 - accuracy: 0.8909\n","Epoch 546: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2767 - accuracy: 0.8907 - val_loss: 0.7060 - val_accuracy: 0.8161\n","Epoch 547/1000\n","54/67 [=======================>......] - ETA: 0s - loss: 0.2828 - accuracy: 0.8741\n","Epoch 547: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2753 - accuracy: 0.8802 - val_loss: 0.7118 - val_accuracy: 0.8206\n","Epoch 548/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2865 - accuracy: 0.8848\n","Epoch 548: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2787 - accuracy: 0.8847 - val_loss: 0.7096 - val_accuracy: 0.8161\n","Epoch 549/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.2855 - accuracy: 0.8817\n","Epoch 549: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2855 - accuracy: 0.8817 - val_loss: 0.6829 - val_accuracy: 0.8072\n","Epoch 550/1000\n","49/67 [====================>.........] - ETA: 0s - loss: 0.2572 - accuracy: 0.8918\n","Epoch 550: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2841 - accuracy: 0.8817 - val_loss: 0.7323 - val_accuracy: 0.8072\n","Epoch 551/1000\n","58/67 [========================>.....] - ETA: 0s - loss: 0.2864 - accuracy: 0.8724\n","Epoch 551: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2775 - accuracy: 0.8787 - val_loss: 0.7007 - val_accuracy: 0.8072\n","Epoch 552/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.2741 - accuracy: 0.8862\n","Epoch 552: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2741 - accuracy: 0.8862 - val_loss: 0.7130 - val_accuracy: 0.7982\n","Epoch 553/1000\n","63/67 [===========================>..] - ETA: 0s - loss: 0.2754 - accuracy: 0.8905\n","Epoch 553: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2776 - accuracy: 0.8892 - val_loss: 0.7123 - val_accuracy: 0.8072\n","Epoch 554/1000\n","65/67 [============================>.] - ETA: 0s - loss: 0.2659 - accuracy: 0.8892\n","Epoch 554: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2661 - accuracy: 0.8892 - val_loss: 0.7177 - val_accuracy: 0.8027\n","Epoch 555/1000\n","48/67 [====================>.........] - ETA: 0s - loss: 0.2550 - accuracy: 0.8875\n","Epoch 555: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2848 - accuracy: 0.8713 - val_loss: 0.7016 - val_accuracy: 0.8072\n","Epoch 556/1000\n","45/67 [===================>..........] - ETA: 0s - loss: 0.2986 - accuracy: 0.8689\n","Epoch 556: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2826 - accuracy: 0.8743 - val_loss: 0.7314 - val_accuracy: 0.8072\n","Epoch 557/1000\n","48/67 [====================>.........] - ETA: 0s - loss: 0.2772 - accuracy: 0.8813\n","Epoch 557: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2772 - accuracy: 0.8847 - val_loss: 0.7237 - val_accuracy: 0.8027\n","Epoch 558/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.2768 - accuracy: 0.8787\n","Epoch 558: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2768 - accuracy: 0.8787 - val_loss: 0.6714 - val_accuracy: 0.8161\n","Epoch 559/1000\n","53/67 [======================>.......] - ETA: 0s - loss: 0.2705 - accuracy: 0.8830\n","Epoch 559: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2759 - accuracy: 0.8787 - val_loss: 0.6521 - val_accuracy: 0.8117\n","Epoch 560/1000\n","50/67 [=====================>........] - ETA: 0s - loss: 0.2663 - accuracy: 0.8860\n","Epoch 560: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2800 - accuracy: 0.8772 - val_loss: 0.7190 - val_accuracy: 0.8117\n","Epoch 561/1000\n","50/67 [=====================>........] - ETA: 0s - loss: 0.2724 - accuracy: 0.8860\n","Epoch 561: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2754 - accuracy: 0.8862 - val_loss: 0.7427 - val_accuracy: 0.8072\n","Epoch 562/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2710 - accuracy: 0.8826\n","Epoch 562: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2681 - accuracy: 0.8787 - val_loss: 0.7779 - val_accuracy: 0.8206\n","Epoch 563/1000\n","42/67 [=================>............] - ETA: 0s - loss: 0.2533 - accuracy: 0.8952\n","Epoch 563: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2768 - accuracy: 0.8862 - val_loss: 0.7581 - val_accuracy: 0.8296\n","Epoch 564/1000\n","48/67 [====================>.........] - ETA: 0s - loss: 0.2449 - accuracy: 0.8979\n","Epoch 564: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2698 - accuracy: 0.8847 - val_loss: 0.8051 - val_accuracy: 0.8117\n","Epoch 565/1000\n","64/67 [===========================>..] - ETA: 0s - loss: 0.2807 - accuracy: 0.8750\n","Epoch 565: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2803 - accuracy: 0.8743 - val_loss: 0.8284 - val_accuracy: 0.8117\n","Epoch 566/1000\n","42/67 [=================>............] - ETA: 0s - loss: 0.2980 - accuracy: 0.8881\n","Epoch 566: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2892 - accuracy: 0.8862 - val_loss: 0.7865 - val_accuracy: 0.8117\n","Epoch 567/1000\n","44/67 [==================>...........] - ETA: 0s - loss: 0.2674 - accuracy: 0.8932\n","Epoch 567: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2791 - accuracy: 0.8847 - val_loss: 0.7514 - val_accuracy: 0.8206\n","Epoch 568/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.2751 - accuracy: 0.8894\n","Epoch 568: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2756 - accuracy: 0.8892 - val_loss: 0.7093 - val_accuracy: 0.8251\n","Epoch 569/1000\n","52/67 [======================>.......] - ETA: 0s - loss: 0.2613 - accuracy: 0.8942\n","Epoch 569: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2633 - accuracy: 0.8847 - val_loss: 0.6940 - val_accuracy: 0.8161\n","Epoch 570/1000\n","64/67 [===========================>..] - ETA: 0s - loss: 0.2806 - accuracy: 0.8766\n","Epoch 570: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2875 - accuracy: 0.8728 - val_loss: 0.6864 - val_accuracy: 0.8072\n","Epoch 571/1000\n","52/67 [======================>.......] - ETA: 0s - loss: 0.2705 - accuracy: 0.8827\n","Epoch 571: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2771 - accuracy: 0.8802 - val_loss: 0.7157 - val_accuracy: 0.8117\n","Epoch 572/1000\n","47/67 [====================>.........] - ETA: 0s - loss: 0.2582 - accuracy: 0.8957\n","Epoch 572: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2855 - accuracy: 0.8817 - val_loss: 0.7122 - val_accuracy: 0.8117\n","Epoch 573/1000\n","44/67 [==================>...........] - ETA: 0s - loss: 0.2657 - accuracy: 0.8932\n","Epoch 573: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2743 - accuracy: 0.8877 - val_loss: 0.7596 - val_accuracy: 0.7937\n","Epoch 574/1000\n","48/67 [====================>.........] - ETA: 0s - loss: 0.2907 - accuracy: 0.8875\n","Epoch 574: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2776 - accuracy: 0.8907 - val_loss: 0.7578 - val_accuracy: 0.8072\n","Epoch 575/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.2684 - accuracy: 0.8848\n","Epoch 575: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2715 - accuracy: 0.8847 - val_loss: 0.7434 - val_accuracy: 0.8072\n","Epoch 576/1000\n","44/67 [==================>...........] - ETA: 0s - loss: 0.2946 - accuracy: 0.8705\n","Epoch 576: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2790 - accuracy: 0.8832 - val_loss: 0.7092 - val_accuracy: 0.8027\n","Epoch 577/1000\n","48/67 [====================>.........] - ETA: 0s - loss: 0.2710 - accuracy: 0.8896\n","Epoch 577: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2808 - accuracy: 0.8802 - val_loss: 0.7308 - val_accuracy: 0.8161\n","Epoch 578/1000\n","47/67 [====================>.........] - ETA: 0s - loss: 0.2621 - accuracy: 0.8936\n","Epoch 578: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2802 - accuracy: 0.8832 - val_loss: 0.7159 - val_accuracy: 0.8161\n","Epoch 579/1000\n","44/67 [==================>...........] - ETA: 0s - loss: 0.2541 - accuracy: 0.9023\n","Epoch 579: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2809 - accuracy: 0.8832 - val_loss: 0.6681 - val_accuracy: 0.8251\n","Epoch 580/1000\n","48/67 [====================>.........] - ETA: 0s - loss: 0.2632 - accuracy: 0.8979\n","Epoch 580: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2710 - accuracy: 0.8907 - val_loss: 0.7652 - val_accuracy: 0.8117\n","Epoch 581/1000\n","51/67 [=====================>........] - ETA: 0s - loss: 0.2779 - accuracy: 0.8824\n","Epoch 581: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2722 - accuracy: 0.8817 - val_loss: 0.7868 - val_accuracy: 0.8072\n","Epoch 582/1000\n","48/67 [====================>.........] - ETA: 0s - loss: 0.3109 - accuracy: 0.8625\n","Epoch 582: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2840 - accuracy: 0.8772 - val_loss: 0.7009 - val_accuracy: 0.8117\n","Epoch 583/1000\n","50/67 [=====================>........] - ETA: 0s - loss: 0.2842 - accuracy: 0.8820\n","Epoch 583: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2745 - accuracy: 0.8847 - val_loss: 0.7461 - val_accuracy: 0.8161\n","Epoch 584/1000\n","52/67 [======================>.......] - ETA: 0s - loss: 0.2907 - accuracy: 0.8827\n","Epoch 584: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2859 - accuracy: 0.8787 - val_loss: 0.6910 - val_accuracy: 0.8117\n","Epoch 585/1000\n","52/67 [======================>.......] - ETA: 0s - loss: 0.2638 - accuracy: 0.8865\n","Epoch 585: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2749 - accuracy: 0.8802 - val_loss: 0.7180 - val_accuracy: 0.8117\n","Epoch 586/1000\n","47/67 [====================>.........] - ETA: 0s - loss: 0.2702 - accuracy: 0.8979\n","Epoch 586: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2766 - accuracy: 0.8877 - val_loss: 0.7376 - val_accuracy: 0.8117\n","Epoch 587/1000\n","49/67 [====================>.........] - ETA: 0s - loss: 0.2578 - accuracy: 0.8959\n","Epoch 587: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2709 - accuracy: 0.8877 - val_loss: 0.7703 - val_accuracy: 0.8161\n","Epoch 588/1000\n","49/67 [====================>.........] - ETA: 0s - loss: 0.2759 - accuracy: 0.8735\n","Epoch 588: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2701 - accuracy: 0.8802 - val_loss: 0.7535 - val_accuracy: 0.8117\n","Epoch 589/1000\n","50/67 [=====================>........] - ETA: 0s - loss: 0.2729 - accuracy: 0.8740\n","Epoch 589: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2775 - accuracy: 0.8772 - val_loss: 0.6930 - val_accuracy: 0.8117\n","Epoch 590/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2670 - accuracy: 0.8826\n","Epoch 590: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2659 - accuracy: 0.8802 - val_loss: 0.7368 - val_accuracy: 0.8251\n","Epoch 591/1000\n","49/67 [====================>.........] - ETA: 0s - loss: 0.2669 - accuracy: 0.8878\n","Epoch 591: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2769 - accuracy: 0.8802 - val_loss: 0.7366 - val_accuracy: 0.8117\n","Epoch 592/1000\n","45/67 [===================>..........] - ETA: 0s - loss: 0.2568 - accuracy: 0.8978\n","Epoch 592: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2675 - accuracy: 0.8907 - val_loss: 0.7419 - val_accuracy: 0.8117\n","Epoch 593/1000\n","48/67 [====================>.........] - ETA: 0s - loss: 0.2923 - accuracy: 0.8729\n","Epoch 593: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2733 - accuracy: 0.8877 - val_loss: 0.7574 - val_accuracy: 0.8117\n","Epoch 594/1000\n","52/67 [======================>.......] - ETA: 0s - loss: 0.2830 - accuracy: 0.8731\n","Epoch 594: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2951 - accuracy: 0.8772 - val_loss: 0.6983 - val_accuracy: 0.7982\n","Epoch 595/1000\n","50/67 [=====================>........] - ETA: 0s - loss: 0.2783 - accuracy: 0.8820\n","Epoch 595: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2753 - accuracy: 0.8817 - val_loss: 0.7874 - val_accuracy: 0.8161\n","Epoch 596/1000\n","45/67 [===================>..........] - ETA: 0s - loss: 0.2909 - accuracy: 0.8800\n","Epoch 596: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2749 - accuracy: 0.8862 - val_loss: 0.7648 - val_accuracy: 0.8206\n","Epoch 597/1000\n","53/67 [======================>.......] - ETA: 0s - loss: 0.2753 - accuracy: 0.8868\n","Epoch 597: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2696 - accuracy: 0.8892 - val_loss: 0.7422 - val_accuracy: 0.8161\n","Epoch 598/1000\n","50/67 [=====================>........] - ETA: 0s - loss: 0.2892 - accuracy: 0.8740\n","Epoch 598: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2814 - accuracy: 0.8832 - val_loss: 0.7234 - val_accuracy: 0.8161\n","Epoch 599/1000\n","47/67 [====================>.........] - ETA: 0s - loss: 0.2817 - accuracy: 0.8766\n","Epoch 599: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2809 - accuracy: 0.8787 - val_loss: 0.7247 - val_accuracy: 0.8072\n","Epoch 600/1000\n","48/67 [====================>.........] - ETA: 0s - loss: 0.2680 - accuracy: 0.8896\n","Epoch 600: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2733 - accuracy: 0.8847 - val_loss: 0.7603 - val_accuracy: 0.8072\n","Epoch 601/1000\n","60/67 [=========================>....] - ETA: 0s - loss: 0.2702 - accuracy: 0.8833\n","Epoch 601: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2757 - accuracy: 0.8817 - val_loss: 0.7117 - val_accuracy: 0.8072\n","Epoch 602/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.2790 - accuracy: 0.8879\n","Epoch 602: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2785 - accuracy: 0.8862 - val_loss: 0.7357 - val_accuracy: 0.8117\n","Epoch 603/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2543 - accuracy: 0.9022\n","Epoch 603: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2711 - accuracy: 0.8877 - val_loss: 0.7485 - val_accuracy: 0.8027\n","Epoch 604/1000\n","47/67 [====================>.........] - ETA: 0s - loss: 0.2629 - accuracy: 0.8957\n","Epoch 604: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2727 - accuracy: 0.8937 - val_loss: 0.7545 - val_accuracy: 0.8161\n","Epoch 605/1000\n","64/67 [===========================>..] - ETA: 0s - loss: 0.2814 - accuracy: 0.8875\n","Epoch 605: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2766 - accuracy: 0.8907 - val_loss: 0.6946 - val_accuracy: 0.8206\n","Epoch 606/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2625 - accuracy: 0.8913\n","Epoch 606: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2782 - accuracy: 0.8847 - val_loss: 0.7264 - val_accuracy: 0.8206\n","Epoch 607/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2585 - accuracy: 0.8978\n","Epoch 607: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2675 - accuracy: 0.8907 - val_loss: 0.7629 - val_accuracy: 0.8161\n","Epoch 608/1000\n","43/67 [==================>...........] - ETA: 0s - loss: 0.2458 - accuracy: 0.8953\n","Epoch 608: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2962 - accuracy: 0.8743 - val_loss: 0.6405 - val_accuracy: 0.7937\n","Epoch 609/1000\n","53/67 [======================>.......] - ETA: 0s - loss: 0.2847 - accuracy: 0.8830\n","Epoch 609: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2788 - accuracy: 0.8802 - val_loss: 0.7152 - val_accuracy: 0.8027\n","Epoch 610/1000\n","47/67 [====================>.........] - ETA: 0s - loss: 0.2512 - accuracy: 0.8979\n","Epoch 610: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2798 - accuracy: 0.8877 - val_loss: 0.6888 - val_accuracy: 0.8072\n","Epoch 611/1000\n","48/67 [====================>.........] - ETA: 0s - loss: 0.2495 - accuracy: 0.8833\n","Epoch 611: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2689 - accuracy: 0.8787 - val_loss: 0.7088 - val_accuracy: 0.8027\n","Epoch 612/1000\n","49/67 [====================>.........] - ETA: 0s - loss: 0.2688 - accuracy: 0.8816\n","Epoch 612: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2695 - accuracy: 0.8877 - val_loss: 0.7308 - val_accuracy: 0.8027\n","Epoch 613/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2809 - accuracy: 0.8761\n","Epoch 613: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2811 - accuracy: 0.8817 - val_loss: 0.7111 - val_accuracy: 0.7982\n","Epoch 614/1000\n","50/67 [=====================>........] - ETA: 0s - loss: 0.2724 - accuracy: 0.8880\n","Epoch 614: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2700 - accuracy: 0.8907 - val_loss: 0.7319 - val_accuracy: 0.7982\n","Epoch 615/1000\n","50/67 [=====================>........] - ETA: 0s - loss: 0.2781 - accuracy: 0.8820\n","Epoch 615: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2714 - accuracy: 0.8862 - val_loss: 0.7437 - val_accuracy: 0.8027\n","Epoch 616/1000\n","51/67 [=====================>........] - ETA: 0s - loss: 0.2557 - accuracy: 0.8980\n","Epoch 616: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2652 - accuracy: 0.8937 - val_loss: 0.7654 - val_accuracy: 0.8161\n","Epoch 617/1000\n","65/67 [============================>.] - ETA: 0s - loss: 0.2717 - accuracy: 0.8877\n","Epoch 617: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2715 - accuracy: 0.8877 - val_loss: 0.6851 - val_accuracy: 0.8206\n","Epoch 618/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2916 - accuracy: 0.8957\n","Epoch 618: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2802 - accuracy: 0.8937 - val_loss: 0.6878 - val_accuracy: 0.8161\n","Epoch 619/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2614 - accuracy: 0.8935\n","Epoch 619: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2758 - accuracy: 0.8847 - val_loss: 0.7162 - val_accuracy: 0.8072\n","Epoch 620/1000\n","45/67 [===================>..........] - ETA: 0s - loss: 0.2586 - accuracy: 0.8978\n","Epoch 620: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2773 - accuracy: 0.8832 - val_loss: 0.7133 - val_accuracy: 0.8027\n","Epoch 621/1000\n","64/67 [===========================>..] - ETA: 0s - loss: 0.2857 - accuracy: 0.8797\n","Epoch 621: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2822 - accuracy: 0.8817 - val_loss: 0.6717 - val_accuracy: 0.7982\n","Epoch 622/1000\n","62/67 [==========================>...] - ETA: 0s - loss: 0.2744 - accuracy: 0.8823\n","Epoch 622: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2780 - accuracy: 0.8787 - val_loss: 0.7005 - val_accuracy: 0.8072\n","Epoch 623/1000\n","41/67 [=================>............] - ETA: 0s - loss: 0.2489 - accuracy: 0.9024\n","Epoch 623: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2718 - accuracy: 0.8847 - val_loss: 0.7007 - val_accuracy: 0.8072\n","Epoch 624/1000\n","48/67 [====================>.........] - ETA: 0s - loss: 0.2561 - accuracy: 0.8938\n","Epoch 624: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2841 - accuracy: 0.8802 - val_loss: 0.6234 - val_accuracy: 0.8072\n","Epoch 625/1000\n","64/67 [===========================>..] - ETA: 0s - loss: 0.2662 - accuracy: 0.8875\n","Epoch 625: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2739 - accuracy: 0.8862 - val_loss: 0.7063 - val_accuracy: 0.8027\n","Epoch 626/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.2825 - accuracy: 0.8817\n","Epoch 626: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2825 - accuracy: 0.8817 - val_loss: 0.6433 - val_accuracy: 0.7982\n","Epoch 627/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.2644 - accuracy: 0.8937\n","Epoch 627: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2644 - accuracy: 0.8937 - val_loss: 0.7130 - val_accuracy: 0.8161\n","Epoch 628/1000\n","54/67 [=======================>......] - ETA: 0s - loss: 0.2763 - accuracy: 0.8778\n","Epoch 628: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2728 - accuracy: 0.8802 - val_loss: 0.7396 - val_accuracy: 0.7982\n","Epoch 629/1000\n","42/67 [=================>............] - ETA: 0s - loss: 0.2889 - accuracy: 0.8738\n","Epoch 629: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2814 - accuracy: 0.8787 - val_loss: 0.6849 - val_accuracy: 0.8117\n","Epoch 630/1000\n","56/67 [========================>.....] - ETA: 0s - loss: 0.2801 - accuracy: 0.8893\n","Epoch 630: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2802 - accuracy: 0.8877 - val_loss: 0.6363 - val_accuracy: 0.8027\n","Epoch 631/1000\n","63/67 [===========================>..] - ETA: 0s - loss: 0.2747 - accuracy: 0.8778\n","Epoch 631: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2708 - accuracy: 0.8802 - val_loss: 0.7087 - val_accuracy: 0.8072\n","Epoch 632/1000\n","59/67 [=========================>....] - ETA: 0s - loss: 0.2604 - accuracy: 0.8966\n","Epoch 632: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2764 - accuracy: 0.8892 - val_loss: 0.6991 - val_accuracy: 0.7982\n","Epoch 633/1000\n","40/67 [================>.............] - ETA: 0s - loss: 0.2780 - accuracy: 0.8875\n","Epoch 633: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2821 - accuracy: 0.8817 - val_loss: 0.6728 - val_accuracy: 0.8027\n","Epoch 634/1000\n","60/67 [=========================>....] - ETA: 0s - loss: 0.2600 - accuracy: 0.8917\n","Epoch 634: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2657 - accuracy: 0.8892 - val_loss: 0.7319 - val_accuracy: 0.8206\n","Epoch 635/1000\n","62/67 [==========================>...] - ETA: 0s - loss: 0.2790 - accuracy: 0.8823\n","Epoch 635: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2815 - accuracy: 0.8832 - val_loss: 0.7027 - val_accuracy: 0.8027\n","Epoch 636/1000\n","44/67 [==================>...........] - ETA: 0s - loss: 0.2726 - accuracy: 0.8932\n","Epoch 636: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2759 - accuracy: 0.8832 - val_loss: 0.7257 - val_accuracy: 0.8027\n","Epoch 637/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.2734 - accuracy: 0.8787\n","Epoch 637: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2734 - accuracy: 0.8787 - val_loss: 0.7630 - val_accuracy: 0.8027\n","Epoch 638/1000\n","48/67 [====================>.........] - ETA: 0s - loss: 0.2605 - accuracy: 0.8917\n","Epoch 638: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2731 - accuracy: 0.8862 - val_loss: 0.7627 - val_accuracy: 0.7982\n","Epoch 639/1000\n","54/67 [=======================>......] - ETA: 0s - loss: 0.2771 - accuracy: 0.8815\n","Epoch 639: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2787 - accuracy: 0.8787 - val_loss: 0.7490 - val_accuracy: 0.7937\n","Epoch 640/1000\n","48/67 [====================>.........] - ETA: 0s - loss: 0.2716 - accuracy: 0.8875\n","Epoch 640: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2731 - accuracy: 0.8862 - val_loss: 0.7747 - val_accuracy: 0.7982\n","Epoch 641/1000\n","51/67 [=====================>........] - ETA: 0s - loss: 0.2819 - accuracy: 0.8784\n","Epoch 641: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2819 - accuracy: 0.8787 - val_loss: 0.7602 - val_accuracy: 0.8027\n","Epoch 642/1000\n","40/67 [================>.............] - ETA: 0s - loss: 0.2716 - accuracy: 0.8925\n","Epoch 642: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2816 - accuracy: 0.8892 - val_loss: 0.7598 - val_accuracy: 0.8027\n","Epoch 643/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.2774 - accuracy: 0.8787\n","Epoch 643: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2774 - accuracy: 0.8787 - val_loss: 0.7381 - val_accuracy: 0.8117\n","Epoch 644/1000\n","50/67 [=====================>........] - ETA: 0s - loss: 0.2785 - accuracy: 0.8920\n","Epoch 644: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2743 - accuracy: 0.8892 - val_loss: 0.7936 - val_accuracy: 0.7937\n","Epoch 645/1000\n","42/67 [=================>............] - ETA: 0s - loss: 0.2839 - accuracy: 0.8786\n","Epoch 645: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2764 - accuracy: 0.8787 - val_loss: 0.7912 - val_accuracy: 0.8206\n","Epoch 646/1000\n","54/67 [=======================>......] - ETA: 0s - loss: 0.2658 - accuracy: 0.8889\n","Epoch 646: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2657 - accuracy: 0.8922 - val_loss: 0.8006 - val_accuracy: 0.8072\n","Epoch 647/1000\n","64/67 [===========================>..] - ETA: 0s - loss: 0.2782 - accuracy: 0.8766\n","Epoch 647: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2741 - accuracy: 0.8787 - val_loss: 0.7673 - val_accuracy: 0.8072\n","Epoch 648/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2624 - accuracy: 0.8891\n","Epoch 648: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2812 - accuracy: 0.8892 - val_loss: 0.7611 - val_accuracy: 0.8161\n","Epoch 649/1000\n","45/67 [===================>..........] - ETA: 0s - loss: 0.2892 - accuracy: 0.8733\n","Epoch 649: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2757 - accuracy: 0.8817 - val_loss: 0.7679 - val_accuracy: 0.7982\n","Epoch 650/1000\n","58/67 [========================>.....] - ETA: 0s - loss: 0.2752 - accuracy: 0.8879\n","Epoch 650: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2797 - accuracy: 0.8847 - val_loss: 0.7141 - val_accuracy: 0.8206\n","Epoch 651/1000\n","47/67 [====================>.........] - ETA: 0s - loss: 0.2616 - accuracy: 0.8915\n","Epoch 651: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2689 - accuracy: 0.8907 - val_loss: 0.6831 - val_accuracy: 0.8161\n","Epoch 652/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.2775 - accuracy: 0.8892\n","Epoch 652: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2775 - accuracy: 0.8892 - val_loss: 0.7539 - val_accuracy: 0.8072\n","Epoch 653/1000\n","48/67 [====================>.........] - ETA: 0s - loss: 0.2572 - accuracy: 0.8958\n","Epoch 653: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2609 - accuracy: 0.8922 - val_loss: 0.7326 - val_accuracy: 0.8027\n","Epoch 654/1000\n","44/67 [==================>...........] - ETA: 0s - loss: 0.2566 - accuracy: 0.8932\n","Epoch 654: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2788 - accuracy: 0.8847 - val_loss: 0.7010 - val_accuracy: 0.8072\n","Epoch 655/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.3369 - accuracy: 0.8864\n","Epoch 655: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3374 - accuracy: 0.8862 - val_loss: 0.6700 - val_accuracy: 0.8206\n","Epoch 656/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2859 - accuracy: 0.8848\n","Epoch 656: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2799 - accuracy: 0.8907 - val_loss: 0.7076 - val_accuracy: 0.8296\n","Epoch 657/1000\n","47/67 [====================>.........] - ETA: 0s - loss: 0.2653 - accuracy: 0.8894\n","Epoch 657: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2686 - accuracy: 0.8862 - val_loss: 0.7880 - val_accuracy: 0.7982\n","Epoch 658/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.2627 - accuracy: 0.8862\n","Epoch 658: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2627 - accuracy: 0.8862 - val_loss: 0.7455 - val_accuracy: 0.7982\n","Epoch 659/1000\n","64/67 [===========================>..] - ETA: 0s - loss: 0.2863 - accuracy: 0.8766\n","Epoch 659: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2806 - accuracy: 0.8802 - val_loss: 0.7902 - val_accuracy: 0.8117\n","Epoch 660/1000\n","45/67 [===================>..........] - ETA: 0s - loss: 0.2342 - accuracy: 0.9022\n","Epoch 660: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2682 - accuracy: 0.8862 - val_loss: 0.7646 - val_accuracy: 0.7982\n","Epoch 661/1000\n","50/67 [=====================>........] - ETA: 0s - loss: 0.2659 - accuracy: 0.8920\n","Epoch 661: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2703 - accuracy: 0.8907 - val_loss: 0.7598 - val_accuracy: 0.8072\n","Epoch 662/1000\n","50/67 [=====================>........] - ETA: 0s - loss: 0.2801 - accuracy: 0.8900\n","Epoch 662: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2649 - accuracy: 0.8937 - val_loss: 0.7858 - val_accuracy: 0.8072\n","Epoch 663/1000\n","52/67 [======================>.......] - ETA: 0s - loss: 0.2663 - accuracy: 0.8846\n","Epoch 663: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2680 - accuracy: 0.8892 - val_loss: 0.7662 - val_accuracy: 0.8117\n","Epoch 664/1000\n","48/67 [====================>.........] - ETA: 0s - loss: 0.2614 - accuracy: 0.8917\n","Epoch 664: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2787 - accuracy: 0.8847 - val_loss: 0.7780 - val_accuracy: 0.7982\n","Epoch 665/1000\n","48/67 [====================>.........] - ETA: 0s - loss: 0.2677 - accuracy: 0.8854\n","Epoch 665: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2595 - accuracy: 0.8922 - val_loss: 0.8504 - val_accuracy: 0.7982\n","Epoch 666/1000\n","59/67 [=========================>....] - ETA: 0s - loss: 0.2756 - accuracy: 0.8847\n","Epoch 666: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2692 - accuracy: 0.8892 - val_loss: 0.8159 - val_accuracy: 0.8072\n","Epoch 667/1000\n","42/67 [=================>............] - ETA: 0s - loss: 0.2759 - accuracy: 0.8833\n","Epoch 667: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2724 - accuracy: 0.8892 - val_loss: 0.7715 - val_accuracy: 0.8072\n","Epoch 668/1000\n","41/67 [=================>............] - ETA: 0s - loss: 0.2716 - accuracy: 0.8878\n","Epoch 668: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2819 - accuracy: 0.8847 - val_loss: 0.7433 - val_accuracy: 0.7982\n","Epoch 669/1000\n","43/67 [==================>...........] - ETA: 0s - loss: 0.2885 - accuracy: 0.8884\n","Epoch 669: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2830 - accuracy: 0.8847 - val_loss: 0.6080 - val_accuracy: 0.8161\n","Epoch 670/1000\n","54/67 [=======================>......] - ETA: 0s - loss: 0.3168 - accuracy: 0.8574\n","Epoch 670: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3047 - accuracy: 0.8653 - val_loss: 0.6581 - val_accuracy: 0.7982\n","Epoch 671/1000\n","44/67 [==================>...........] - ETA: 0s - loss: 0.2523 - accuracy: 0.9000\n","Epoch 671: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2808 - accuracy: 0.8862 - val_loss: 0.6842 - val_accuracy: 0.7937\n","Epoch 672/1000\n","53/67 [======================>.......] - ETA: 0s - loss: 0.2868 - accuracy: 0.8811\n","Epoch 672: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2778 - accuracy: 0.8847 - val_loss: 0.6976 - val_accuracy: 0.7892\n","Epoch 673/1000\n","53/67 [======================>.......] - ETA: 0s - loss: 0.2699 - accuracy: 0.8868\n","Epoch 673: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2897 - accuracy: 0.8787 - val_loss: 0.7023 - val_accuracy: 0.7982\n","Epoch 674/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.2622 - accuracy: 0.8985\n","Epoch 674: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2620 - accuracy: 0.8982 - val_loss: 0.7119 - val_accuracy: 0.8027\n","Epoch 675/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2822 - accuracy: 0.8804\n","Epoch 675: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2721 - accuracy: 0.8877 - val_loss: 0.7030 - val_accuracy: 0.8027\n","Epoch 676/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.2743 - accuracy: 0.8833\n","Epoch 676: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2734 - accuracy: 0.8832 - val_loss: 0.7086 - val_accuracy: 0.8072\n","Epoch 677/1000\n","43/67 [==================>...........] - ETA: 0s - loss: 0.2476 - accuracy: 0.8977\n","Epoch 677: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2673 - accuracy: 0.8892 - val_loss: 0.7462 - val_accuracy: 0.7982\n","Epoch 678/1000\n","49/67 [====================>.........] - ETA: 0s - loss: 0.2694 - accuracy: 0.8837\n","Epoch 678: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2718 - accuracy: 0.8862 - val_loss: 0.7440 - val_accuracy: 0.8027\n","Epoch 679/1000\n","43/67 [==================>...........] - ETA: 0s - loss: 0.2647 - accuracy: 0.9000\n","Epoch 679: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2578 - accuracy: 0.8922 - val_loss: 0.7677 - val_accuracy: 0.8072\n","Epoch 680/1000\n","45/67 [===================>..........] - ETA: 0s - loss: 0.2612 - accuracy: 0.8867\n","Epoch 680: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2674 - accuracy: 0.8832 - val_loss: 0.8013 - val_accuracy: 0.8027\n","Epoch 681/1000\n","42/67 [=================>............] - ETA: 0s - loss: 0.2569 - accuracy: 0.8929\n","Epoch 681: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2648 - accuracy: 0.8967 - val_loss: 0.8018 - val_accuracy: 0.8027\n","Epoch 682/1000\n","50/67 [=====================>........] - ETA: 0s - loss: 0.2663 - accuracy: 0.8820\n","Epoch 682: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2704 - accuracy: 0.8862 - val_loss: 0.8110 - val_accuracy: 0.7982\n","Epoch 683/1000\n","43/67 [==================>...........] - ETA: 0s - loss: 0.2776 - accuracy: 0.8791\n","Epoch 683: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2897 - accuracy: 0.8757 - val_loss: 0.7704 - val_accuracy: 0.8117\n","Epoch 684/1000\n","37/67 [===============>..............] - ETA: 0s - loss: 0.2752 - accuracy: 0.8838\n","Epoch 684: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2669 - accuracy: 0.8907 - val_loss: 0.7772 - val_accuracy: 0.8027\n","Epoch 685/1000\n","50/67 [=====================>........] - ETA: 0s - loss: 0.2559 - accuracy: 0.8960\n","Epoch 685: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2634 - accuracy: 0.8922 - val_loss: 0.7952 - val_accuracy: 0.8072\n","Epoch 686/1000\n","49/67 [====================>.........] - ETA: 0s - loss: 0.2560 - accuracy: 0.9000\n","Epoch 686: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2668 - accuracy: 0.8907 - val_loss: 0.7972 - val_accuracy: 0.7982\n","Epoch 687/1000\n","59/67 [=========================>....] - ETA: 0s - loss: 0.2628 - accuracy: 0.8949\n","Epoch 687: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2708 - accuracy: 0.8892 - val_loss: 0.7971 - val_accuracy: 0.8027\n","Epoch 688/1000\n","53/67 [======================>.......] - ETA: 0s - loss: 0.2946 - accuracy: 0.8755\n","Epoch 688: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2892 - accuracy: 0.8787 - val_loss: 0.7431 - val_accuracy: 0.8161\n","Epoch 689/1000\n","49/67 [====================>.........] - ETA: 0s - loss: 0.2629 - accuracy: 0.8980\n","Epoch 689: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2793 - accuracy: 0.8847 - val_loss: 0.7241 - val_accuracy: 0.8072\n","Epoch 690/1000\n","48/67 [====================>.........] - ETA: 0s - loss: 0.2935 - accuracy: 0.8771\n","Epoch 690: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2855 - accuracy: 0.8787 - val_loss: 0.7278 - val_accuracy: 0.8161\n","Epoch 691/1000\n","48/67 [====================>.........] - ETA: 0s - loss: 0.2661 - accuracy: 0.8896\n","Epoch 691: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2741 - accuracy: 0.8832 - val_loss: 0.7861 - val_accuracy: 0.8072\n","Epoch 692/1000\n","42/67 [=================>............] - ETA: 0s - loss: 0.3059 - accuracy: 0.8714\n","Epoch 692: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2805 - accuracy: 0.8802 - val_loss: 0.7522 - val_accuracy: 0.8027\n","Epoch 693/1000\n","48/67 [====================>.........] - ETA: 0s - loss: 0.3017 - accuracy: 0.8750\n","Epoch 693: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2854 - accuracy: 0.8847 - val_loss: 0.7422 - val_accuracy: 0.8117\n","Epoch 694/1000\n","43/67 [==================>...........] - ETA: 0s - loss: 0.2673 - accuracy: 0.8884\n","Epoch 694: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2759 - accuracy: 0.8922 - val_loss: 0.7230 - val_accuracy: 0.8027\n","Epoch 695/1000\n","49/67 [====================>.........] - ETA: 0s - loss: 0.2798 - accuracy: 0.8857\n","Epoch 695: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2711 - accuracy: 0.8862 - val_loss: 0.7392 - val_accuracy: 0.8072\n","Epoch 696/1000\n","50/67 [=====================>........] - ETA: 0s - loss: 0.2797 - accuracy: 0.8840\n","Epoch 696: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2811 - accuracy: 0.8847 - val_loss: 0.7194 - val_accuracy: 0.8072\n","Epoch 697/1000\n","48/67 [====================>.........] - ETA: 0s - loss: 0.2622 - accuracy: 0.8854\n","Epoch 697: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2615 - accuracy: 0.8862 - val_loss: 0.7597 - val_accuracy: 0.8072\n","Epoch 698/1000\n","50/67 [=====================>........] - ETA: 0s - loss: 0.2792 - accuracy: 0.8780\n","Epoch 698: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2648 - accuracy: 0.8877 - val_loss: 0.7401 - val_accuracy: 0.7982\n","Epoch 699/1000\n","47/67 [====================>.........] - ETA: 0s - loss: 0.2824 - accuracy: 0.8894\n","Epoch 699: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2691 - accuracy: 0.8982 - val_loss: 0.7048 - val_accuracy: 0.8161\n","Epoch 700/1000\n","47/67 [====================>.........] - ETA: 0s - loss: 0.2551 - accuracy: 0.9000\n","Epoch 700: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2631 - accuracy: 0.8937 - val_loss: 0.7495 - val_accuracy: 0.8027\n","Epoch 701/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2613 - accuracy: 0.8957\n","Epoch 701: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2692 - accuracy: 0.8907 - val_loss: 0.7179 - val_accuracy: 0.7982\n","Epoch 702/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.2784 - accuracy: 0.8848\n","Epoch 702: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2764 - accuracy: 0.8862 - val_loss: 0.6982 - val_accuracy: 0.8161\n","Epoch 703/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.2772 - accuracy: 0.8817\n","Epoch 703: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2772 - accuracy: 0.8817 - val_loss: 0.7460 - val_accuracy: 0.8027\n","Epoch 704/1000\n","49/67 [====================>.........] - ETA: 0s - loss: 0.2818 - accuracy: 0.8939\n","Epoch 704: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2757 - accuracy: 0.8907 - val_loss: 0.7361 - val_accuracy: 0.7982\n","Epoch 705/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.2670 - accuracy: 0.8877\n","Epoch 705: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2670 - accuracy: 0.8877 - val_loss: 0.7772 - val_accuracy: 0.7982\n","Epoch 706/1000\n","51/67 [=====================>........] - ETA: 0s - loss: 0.2928 - accuracy: 0.8784\n","Epoch 706: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2717 - accuracy: 0.8877 - val_loss: 0.7443 - val_accuracy: 0.8072\n","Epoch 707/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2376 - accuracy: 0.9087\n","Epoch 707: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2593 - accuracy: 0.8937 - val_loss: 0.7552 - val_accuracy: 0.8072\n","Epoch 708/1000\n","45/67 [===================>..........] - ETA: 0s - loss: 0.2728 - accuracy: 0.8800\n","Epoch 708: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2659 - accuracy: 0.8877 - val_loss: 0.7723 - val_accuracy: 0.7937\n","Epoch 709/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2461 - accuracy: 0.9000\n","Epoch 709: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2607 - accuracy: 0.8922 - val_loss: 0.7711 - val_accuracy: 0.8161\n","Epoch 710/1000\n","43/67 [==================>...........] - ETA: 0s - loss: 0.2820 - accuracy: 0.8814\n","Epoch 710: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2654 - accuracy: 0.8862 - val_loss: 0.8407 - val_accuracy: 0.7937\n","Epoch 711/1000\n","48/67 [====================>.........] - ETA: 0s - loss: 0.3013 - accuracy: 0.8729\n","Epoch 711: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2856 - accuracy: 0.8847 - val_loss: 0.7778 - val_accuracy: 0.7982\n","Epoch 712/1000\n","45/67 [===================>..........] - ETA: 0s - loss: 0.2771 - accuracy: 0.8689\n","Epoch 712: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2661 - accuracy: 0.8817 - val_loss: 0.7476 - val_accuracy: 0.8206\n","Epoch 713/1000\n","49/67 [====================>.........] - ETA: 0s - loss: 0.2600 - accuracy: 0.9020\n","Epoch 713: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2779 - accuracy: 0.8847 - val_loss: 0.7263 - val_accuracy: 0.7937\n","Epoch 714/1000\n","52/67 [======================>.......] - ETA: 0s - loss: 0.2700 - accuracy: 0.8865\n","Epoch 714: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2772 - accuracy: 0.8847 - val_loss: 0.7593 - val_accuracy: 0.8027\n","Epoch 715/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.2608 - accuracy: 0.8922\n","Epoch 715: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2608 - accuracy: 0.8922 - val_loss: 0.7876 - val_accuracy: 0.8027\n","Epoch 716/1000\n","48/67 [====================>.........] - ETA: 0s - loss: 0.2707 - accuracy: 0.8875\n","Epoch 716: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2728 - accuracy: 0.8877 - val_loss: 0.7765 - val_accuracy: 0.8027\n","Epoch 717/1000\n","65/67 [============================>.] - ETA: 0s - loss: 0.2602 - accuracy: 0.8892\n","Epoch 717: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2627 - accuracy: 0.8877 - val_loss: 0.8065 - val_accuracy: 0.8072\n","Epoch 718/1000\n","65/67 [============================>.] - ETA: 0s - loss: 0.2796 - accuracy: 0.8877\n","Epoch 718: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2844 - accuracy: 0.8847 - val_loss: 0.6920 - val_accuracy: 0.8027\n","Epoch 719/1000\n","57/67 [========================>.....] - ETA: 0s - loss: 0.2988 - accuracy: 0.8702\n","Epoch 719: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2959 - accuracy: 0.8743 - val_loss: 0.7020 - val_accuracy: 0.8117\n","Epoch 720/1000\n","43/67 [==================>...........] - ETA: 0s - loss: 0.2861 - accuracy: 0.8791\n","Epoch 720: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2732 - accuracy: 0.8892 - val_loss: 0.7553 - val_accuracy: 0.8072\n","Epoch 721/1000\n","55/67 [=======================>......] - ETA: 0s - loss: 0.2604 - accuracy: 0.8927\n","Epoch 721: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2711 - accuracy: 0.8817 - val_loss: 0.6820 - val_accuracy: 0.8161\n","Epoch 722/1000\n","51/67 [=====================>........] - ETA: 0s - loss: 0.2518 - accuracy: 0.8980\n","Epoch 722: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2751 - accuracy: 0.8847 - val_loss: 0.7372 - val_accuracy: 0.8027\n","Epoch 723/1000\n","63/67 [===========================>..] - ETA: 0s - loss: 0.2732 - accuracy: 0.8810\n","Epoch 723: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2796 - accuracy: 0.8743 - val_loss: 0.7355 - val_accuracy: 0.8161\n","Epoch 724/1000\n","65/67 [============================>.] - ETA: 0s - loss: 0.2800 - accuracy: 0.8769\n","Epoch 724: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2773 - accuracy: 0.8787 - val_loss: 0.7390 - val_accuracy: 0.8027\n","Epoch 725/1000\n","48/67 [====================>.........] - ETA: 0s - loss: 0.2658 - accuracy: 0.8917\n","Epoch 725: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2701 - accuracy: 0.8892 - val_loss: 0.7481 - val_accuracy: 0.8117\n","Epoch 726/1000\n","47/67 [====================>.........] - ETA: 0s - loss: 0.2709 - accuracy: 0.8830\n","Epoch 726: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2620 - accuracy: 0.8862 - val_loss: 0.7266 - val_accuracy: 0.8161\n","Epoch 727/1000\n","53/67 [======================>.......] - ETA: 0s - loss: 0.2847 - accuracy: 0.8774\n","Epoch 727: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2672 - accuracy: 0.8832 - val_loss: 0.7610 - val_accuracy: 0.8072\n","Epoch 728/1000\n","49/67 [====================>.........] - ETA: 0s - loss: 0.2636 - accuracy: 0.9020\n","Epoch 728: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2647 - accuracy: 0.8937 - val_loss: 0.7463 - val_accuracy: 0.8161\n","Epoch 729/1000\n","61/67 [==========================>...] - ETA: 0s - loss: 0.2527 - accuracy: 0.8869\n","Epoch 729: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2594 - accuracy: 0.8862 - val_loss: 0.8186 - val_accuracy: 0.8161\n","Epoch 730/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.2707 - accuracy: 0.8773\n","Epoch 730: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2697 - accuracy: 0.8787 - val_loss: 0.7555 - val_accuracy: 0.8117\n","Epoch 731/1000\n","52/67 [======================>.......] - ETA: 0s - loss: 0.2758 - accuracy: 0.8885\n","Epoch 731: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2840 - accuracy: 0.8847 - val_loss: 0.7042 - val_accuracy: 0.8027\n","Epoch 732/1000\n","47/67 [====================>.........] - ETA: 0s - loss: 0.2754 - accuracy: 0.8830\n","Epoch 732: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2626 - accuracy: 0.8907 - val_loss: 0.7158 - val_accuracy: 0.8296\n","Epoch 733/1000\n","47/67 [====================>.........] - ETA: 0s - loss: 0.2893 - accuracy: 0.8809\n","Epoch 733: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2797 - accuracy: 0.8772 - val_loss: 0.6479 - val_accuracy: 0.8206\n","Epoch 734/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2834 - accuracy: 0.8848\n","Epoch 734: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2870 - accuracy: 0.8817 - val_loss: 0.6267 - val_accuracy: 0.8117\n","Epoch 735/1000\n","57/67 [========================>.....] - ETA: 0s - loss: 0.3102 - accuracy: 0.8737\n","Epoch 735: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 2ms/step - loss: 0.2998 - accuracy: 0.8787 - val_loss: 0.6536 - val_accuracy: 0.8027\n","Epoch 736/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2653 - accuracy: 0.8957\n","Epoch 736: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2886 - accuracy: 0.8817 - val_loss: 0.6635 - val_accuracy: 0.8206\n","Epoch 737/1000\n","65/67 [============================>.] - ETA: 0s - loss: 0.2813 - accuracy: 0.8846\n","Epoch 737: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2787 - accuracy: 0.8847 - val_loss: 0.6731 - val_accuracy: 0.8117\n","Epoch 738/1000\n","64/67 [===========================>..] - ETA: 0s - loss: 0.2655 - accuracy: 0.8922\n","Epoch 738: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2708 - accuracy: 0.8877 - val_loss: 0.7188 - val_accuracy: 0.8117\n","Epoch 739/1000\n","61/67 [==========================>...] - ETA: 0s - loss: 0.2786 - accuracy: 0.8885\n","Epoch 739: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2725 - accuracy: 0.8907 - val_loss: 0.6925 - val_accuracy: 0.7982\n","Epoch 740/1000\n","44/67 [==================>...........] - ETA: 0s - loss: 0.2609 - accuracy: 0.8909\n","Epoch 740: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2588 - accuracy: 0.8952 - val_loss: 0.7326 - val_accuracy: 0.8161\n","Epoch 741/1000\n","65/67 [============================>.] - ETA: 0s - loss: 0.2655 - accuracy: 0.8892\n","Epoch 741: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2618 - accuracy: 0.8922 - val_loss: 0.7341 - val_accuracy: 0.8161\n","Epoch 742/1000\n","65/67 [============================>.] - ETA: 0s - loss: 0.2799 - accuracy: 0.8846\n","Epoch 742: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2808 - accuracy: 0.8847 - val_loss: 0.7229 - val_accuracy: 0.8072\n","Epoch 743/1000\n","47/67 [====================>.........] - ETA: 0s - loss: 0.2570 - accuracy: 0.8936\n","Epoch 743: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2622 - accuracy: 0.8892 - val_loss: 0.7352 - val_accuracy: 0.8117\n","Epoch 744/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2606 - accuracy: 0.8978\n","Epoch 744: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2717 - accuracy: 0.8862 - val_loss: 0.7483 - val_accuracy: 0.8027\n","Epoch 745/1000\n","65/67 [============================>.] - ETA: 0s - loss: 0.2619 - accuracy: 0.8877\n","Epoch 745: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2625 - accuracy: 0.8862 - val_loss: 0.7714 - val_accuracy: 0.8027\n","Epoch 746/1000\n","49/67 [====================>.........] - ETA: 0s - loss: 0.2618 - accuracy: 0.9041\n","Epoch 746: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2674 - accuracy: 0.8937 - val_loss: 0.7189 - val_accuracy: 0.8251\n","Epoch 747/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.2728 - accuracy: 0.8817\n","Epoch 747: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2728 - accuracy: 0.8817 - val_loss: 0.6875 - val_accuracy: 0.8161\n","Epoch 748/1000\n","60/67 [=========================>....] - ETA: 0s - loss: 0.2732 - accuracy: 0.8983\n","Epoch 748: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2838 - accuracy: 0.8862 - val_loss: 0.6972 - val_accuracy: 0.8072\n","Epoch 749/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.2902 - accuracy: 0.8788\n","Epoch 749: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2885 - accuracy: 0.8802 - val_loss: 0.6816 - val_accuracy: 0.8251\n","Epoch 750/1000\n","51/67 [=====================>........] - ETA: 0s - loss: 0.2897 - accuracy: 0.8706\n","Epoch 750: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2792 - accuracy: 0.8787 - val_loss: 0.6749 - val_accuracy: 0.8206\n","Epoch 751/1000\n","45/67 [===================>..........] - ETA: 0s - loss: 0.2819 - accuracy: 0.8844\n","Epoch 751: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2729 - accuracy: 0.8847 - val_loss: 0.7320 - val_accuracy: 0.8072\n","Epoch 752/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2533 - accuracy: 0.9000\n","Epoch 752: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2694 - accuracy: 0.8892 - val_loss: 0.7542 - val_accuracy: 0.8027\n","Epoch 753/1000\n","62/67 [==========================>...] - ETA: 0s - loss: 0.2936 - accuracy: 0.8758\n","Epoch 753: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2861 - accuracy: 0.8787 - val_loss: 0.7124 - val_accuracy: 0.8206\n","Epoch 754/1000\n","55/67 [=======================>......] - ETA: 0s - loss: 0.2877 - accuracy: 0.8800\n","Epoch 754: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2746 - accuracy: 0.8877 - val_loss: 0.7267 - val_accuracy: 0.8027\n","Epoch 755/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2683 - accuracy: 0.8804\n","Epoch 755: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2674 - accuracy: 0.8877 - val_loss: 0.7960 - val_accuracy: 0.8072\n","Epoch 756/1000\n","44/67 [==================>...........] - ETA: 0s - loss: 0.2362 - accuracy: 0.9091\n","Epoch 756: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2659 - accuracy: 0.8907 - val_loss: 0.7391 - val_accuracy: 0.8117\n","Epoch 757/1000\n","47/67 [====================>.........] - ETA: 0s - loss: 0.2684 - accuracy: 0.8957\n","Epoch 757: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2615 - accuracy: 0.8952 - val_loss: 0.7701 - val_accuracy: 0.8206\n","Epoch 758/1000\n","45/67 [===================>..........] - ETA: 0s - loss: 0.2526 - accuracy: 0.8978\n","Epoch 758: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2642 - accuracy: 0.8907 - val_loss: 0.7535 - val_accuracy: 0.8206\n","Epoch 759/1000\n","61/67 [==========================>...] - ETA: 0s - loss: 0.2609 - accuracy: 0.8984\n","Epoch 759: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2669 - accuracy: 0.8937 - val_loss: 0.7318 - val_accuracy: 0.8161\n","Epoch 760/1000\n","44/67 [==================>...........] - ETA: 0s - loss: 0.2385 - accuracy: 0.9023\n","Epoch 760: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2620 - accuracy: 0.8877 - val_loss: 0.7932 - val_accuracy: 0.8117\n","Epoch 761/1000\n","65/67 [============================>.] - ETA: 0s - loss: 0.2608 - accuracy: 0.8877\n","Epoch 761: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2674 - accuracy: 0.8847 - val_loss: 0.7170 - val_accuracy: 0.8251\n","Epoch 762/1000\n","45/67 [===================>..........] - ETA: 0s - loss: 0.2625 - accuracy: 0.8956\n","Epoch 762: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2681 - accuracy: 0.8862 - val_loss: 0.7795 - val_accuracy: 0.8206\n","Epoch 763/1000\n","64/67 [===========================>..] - ETA: 0s - loss: 0.2671 - accuracy: 0.8891\n","Epoch 763: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2706 - accuracy: 0.8877 - val_loss: 0.7897 - val_accuracy: 0.7982\n","Epoch 764/1000\n","55/67 [=======================>......] - ETA: 0s - loss: 0.2564 - accuracy: 0.8945\n","Epoch 764: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2682 - accuracy: 0.8862 - val_loss: 0.7900 - val_accuracy: 0.8117\n","Epoch 765/1000\n","51/67 [=====================>........] - ETA: 0s - loss: 0.2652 - accuracy: 0.8941\n","Epoch 765: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2745 - accuracy: 0.8877 - val_loss: 0.7614 - val_accuracy: 0.8072\n","Epoch 766/1000\n","49/67 [====================>.........] - ETA: 0s - loss: 0.2940 - accuracy: 0.8776\n","Epoch 766: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2744 - accuracy: 0.8847 - val_loss: 0.7784 - val_accuracy: 0.8027\n","Epoch 767/1000\n","64/67 [===========================>..] - ETA: 0s - loss: 0.2740 - accuracy: 0.8875\n","Epoch 767: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2795 - accuracy: 0.8832 - val_loss: 0.7583 - val_accuracy: 0.8027\n","Epoch 768/1000\n","45/67 [===================>..........] - ETA: 0s - loss: 0.2622 - accuracy: 0.9000\n","Epoch 768: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2698 - accuracy: 0.8892 - val_loss: 0.7728 - val_accuracy: 0.8072\n","Epoch 769/1000\n","49/67 [====================>.........] - ETA: 0s - loss: 0.2563 - accuracy: 0.8918\n","Epoch 769: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2627 - accuracy: 0.8892 - val_loss: 0.7761 - val_accuracy: 0.8027\n","Epoch 770/1000\n","47/67 [====================>.........] - ETA: 0s - loss: 0.2835 - accuracy: 0.8766\n","Epoch 770: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2667 - accuracy: 0.8877 - val_loss: 0.7553 - val_accuracy: 0.8161\n","Epoch 771/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.2689 - accuracy: 0.8922\n","Epoch 771: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2689 - accuracy: 0.8922 - val_loss: 0.7888 - val_accuracy: 0.8117\n","Epoch 772/1000\n","60/67 [=========================>....] - ETA: 0s - loss: 0.2679 - accuracy: 0.8850\n","Epoch 772: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2710 - accuracy: 0.8847 - val_loss: 0.7909 - val_accuracy: 0.8117\n","Epoch 773/1000\n","65/67 [============================>.] - ETA: 0s - loss: 0.2672 - accuracy: 0.8892\n","Epoch 773: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2703 - accuracy: 0.8862 - val_loss: 0.7876 - val_accuracy: 0.8027\n","Epoch 774/1000\n","50/67 [=====================>........] - ETA: 0s - loss: 0.2778 - accuracy: 0.8780\n","Epoch 774: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2688 - accuracy: 0.8847 - val_loss: 0.8094 - val_accuracy: 0.7937\n","Epoch 775/1000\n","62/67 [==========================>...] - ETA: 0s - loss: 0.2689 - accuracy: 0.8887\n","Epoch 775: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2676 - accuracy: 0.8892 - val_loss: 0.8016 - val_accuracy: 0.7982\n","Epoch 776/1000\n","51/67 [=====================>........] - ETA: 0s - loss: 0.2521 - accuracy: 0.8922\n","Epoch 776: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2604 - accuracy: 0.8877 - val_loss: 0.8096 - val_accuracy: 0.8072\n","Epoch 777/1000\n","49/67 [====================>.........] - ETA: 0s - loss: 0.2676 - accuracy: 0.8918\n","Epoch 777: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2591 - accuracy: 0.8907 - val_loss: 0.8609 - val_accuracy: 0.8117\n","Epoch 778/1000\n","48/67 [====================>.........] - ETA: 0s - loss: 0.2589 - accuracy: 0.8979\n","Epoch 778: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2627 - accuracy: 0.8922 - val_loss: 0.8376 - val_accuracy: 0.8251\n","Epoch 779/1000\n","41/67 [=================>............] - ETA: 0s - loss: 0.2683 - accuracy: 0.8902\n","Epoch 779: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2810 - accuracy: 0.8787 - val_loss: 0.7479 - val_accuracy: 0.8251\n","Epoch 780/1000\n","42/67 [=================>............] - ETA: 0s - loss: 0.2705 - accuracy: 0.8857\n","Epoch 780: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2715 - accuracy: 0.8862 - val_loss: 0.7555 - val_accuracy: 0.8251\n","Epoch 781/1000\n","53/67 [======================>.......] - ETA: 0s - loss: 0.2742 - accuracy: 0.8868\n","Epoch 781: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2637 - accuracy: 0.8877 - val_loss: 0.7265 - val_accuracy: 0.8161\n","Epoch 782/1000\n","44/67 [==================>...........] - ETA: 0s - loss: 0.2683 - accuracy: 0.8886\n","Epoch 782: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2667 - accuracy: 0.8907 - val_loss: 0.7875 - val_accuracy: 0.8206\n","Epoch 783/1000\n","57/67 [========================>.....] - ETA: 0s - loss: 0.2739 - accuracy: 0.8789\n","Epoch 783: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2720 - accuracy: 0.8802 - val_loss: 0.7229 - val_accuracy: 0.8117\n","Epoch 784/1000\n","52/67 [======================>.......] - ETA: 0s - loss: 0.2688 - accuracy: 0.8865\n","Epoch 784: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2728 - accuracy: 0.8847 - val_loss: 0.7698 - val_accuracy: 0.8161\n","Epoch 785/1000\n","44/67 [==================>...........] - ETA: 0s - loss: 0.2575 - accuracy: 0.8932\n","Epoch 785: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2566 - accuracy: 0.8937 - val_loss: 0.7363 - val_accuracy: 0.8161\n","Epoch 786/1000\n","51/67 [=====================>........] - ETA: 0s - loss: 0.2688 - accuracy: 0.8863\n","Epoch 786: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2712 - accuracy: 0.8847 - val_loss: 0.7622 - val_accuracy: 0.8027\n","Epoch 787/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.2666 - accuracy: 0.8892\n","Epoch 787: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2666 - accuracy: 0.8892 - val_loss: 0.7810 - val_accuracy: 0.8251\n","Epoch 788/1000\n","64/67 [===========================>..] - ETA: 0s - loss: 0.2610 - accuracy: 0.8875\n","Epoch 788: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2674 - accuracy: 0.8847 - val_loss: 0.7341 - val_accuracy: 0.8072\n","Epoch 789/1000\n","47/67 [====================>.........] - ETA: 0s - loss: 0.2672 - accuracy: 0.8894\n","Epoch 789: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2766 - accuracy: 0.8847 - val_loss: 0.7373 - val_accuracy: 0.8161\n","Epoch 790/1000\n","51/67 [=====================>........] - ETA: 0s - loss: 0.2776 - accuracy: 0.8784\n","Epoch 790: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2743 - accuracy: 0.8817 - val_loss: 0.7506 - val_accuracy: 0.8072\n","Epoch 791/1000\n","51/67 [=====================>........] - ETA: 0s - loss: 0.2493 - accuracy: 0.8941\n","Epoch 791: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2689 - accuracy: 0.8832 - val_loss: 0.7069 - val_accuracy: 0.8206\n","Epoch 792/1000\n","57/67 [========================>.....] - ETA: 0s - loss: 0.2688 - accuracy: 0.8982\n","Epoch 792: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2671 - accuracy: 0.8922 - val_loss: 0.8123 - val_accuracy: 0.8072\n","Epoch 793/1000\n","64/67 [===========================>..] - ETA: 0s - loss: 0.2723 - accuracy: 0.8844\n","Epoch 793: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2673 - accuracy: 0.8877 - val_loss: 0.7761 - val_accuracy: 0.8072\n","Epoch 794/1000\n","61/67 [==========================>...] - ETA: 0s - loss: 0.2853 - accuracy: 0.8869\n","Epoch 794: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2792 - accuracy: 0.8892 - val_loss: 0.7556 - val_accuracy: 0.8072\n","Epoch 795/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2829 - accuracy: 0.8870\n","Epoch 795: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2741 - accuracy: 0.8892 - val_loss: 0.7252 - val_accuracy: 0.8251\n","Epoch 796/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2654 - accuracy: 0.8913\n","Epoch 796: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2765 - accuracy: 0.8862 - val_loss: 0.6969 - val_accuracy: 0.8072\n","Epoch 797/1000\n","64/67 [===========================>..] - ETA: 0s - loss: 0.2639 - accuracy: 0.8953\n","Epoch 797: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2693 - accuracy: 0.8907 - val_loss: 0.7327 - val_accuracy: 0.8251\n","Epoch 798/1000\n","65/67 [============================>.] - ETA: 0s - loss: 0.2629 - accuracy: 0.8862\n","Epoch 798: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2628 - accuracy: 0.8847 - val_loss: 0.7740 - val_accuracy: 0.8027\n","Epoch 799/1000\n","65/67 [============================>.] - ETA: 0s - loss: 0.2625 - accuracy: 0.8938\n","Epoch 799: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2623 - accuracy: 0.8937 - val_loss: 0.8053 - val_accuracy: 0.8206\n","Epoch 800/1000\n","62/67 [==========================>...] - ETA: 0s - loss: 0.2831 - accuracy: 0.8839\n","Epoch 800: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2726 - accuracy: 0.8877 - val_loss: 0.7623 - val_accuracy: 0.8206\n","Epoch 801/1000\n","58/67 [========================>.....] - ETA: 0s - loss: 0.2833 - accuracy: 0.8845\n","Epoch 801: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2761 - accuracy: 0.8907 - val_loss: 0.7561 - val_accuracy: 0.8251\n","Epoch 802/1000\n","59/67 [=========================>....] - ETA: 0s - loss: 0.2486 - accuracy: 0.8949\n","Epoch 802: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2719 - accuracy: 0.8847 - val_loss: 0.7821 - val_accuracy: 0.8206\n","Epoch 803/1000\n","54/67 [=======================>......] - ETA: 0s - loss: 0.2732 - accuracy: 0.8870\n","Epoch 803: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2597 - accuracy: 0.8937 - val_loss: 0.8575 - val_accuracy: 0.8072\n","Epoch 804/1000\n","64/67 [===========================>..] - ETA: 0s - loss: 0.2706 - accuracy: 0.8828\n","Epoch 804: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2679 - accuracy: 0.8847 - val_loss: 0.8681 - val_accuracy: 0.7848\n","Epoch 805/1000\n","49/67 [====================>.........] - ETA: 0s - loss: 0.2752 - accuracy: 0.8857\n","Epoch 805: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2805 - accuracy: 0.8832 - val_loss: 0.7715 - val_accuracy: 0.7937\n","Epoch 806/1000\n","49/67 [====================>.........] - ETA: 0s - loss: 0.2746 - accuracy: 0.8837\n","Epoch 806: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2666 - accuracy: 0.8892 - val_loss: 0.8016 - val_accuracy: 0.8251\n","Epoch 807/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.2693 - accuracy: 0.8894\n","Epoch 807: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2696 - accuracy: 0.8892 - val_loss: 0.7310 - val_accuracy: 0.8161\n","Epoch 808/1000\n","62/67 [==========================>...] - ETA: 0s - loss: 0.2759 - accuracy: 0.8806\n","Epoch 808: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2734 - accuracy: 0.8802 - val_loss: 0.7571 - val_accuracy: 0.8296\n","Epoch 809/1000\n","61/67 [==========================>...] - ETA: 0s - loss: 0.2833 - accuracy: 0.8820\n","Epoch 809: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2739 - accuracy: 0.8877 - val_loss: 0.8226 - val_accuracy: 0.8161\n","Epoch 810/1000\n","62/67 [==========================>...] - ETA: 0s - loss: 0.2778 - accuracy: 0.8919\n","Epoch 810: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2875 - accuracy: 0.8877 - val_loss: 0.6380 - val_accuracy: 0.8161\n","Epoch 811/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.2912 - accuracy: 0.8894\n","Epoch 811: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2916 - accuracy: 0.8892 - val_loss: 0.6325 - val_accuracy: 0.8341\n","Epoch 812/1000\n","57/67 [========================>.....] - ETA: 0s - loss: 0.2721 - accuracy: 0.9000\n","Epoch 812: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2774 - accuracy: 0.8922 - val_loss: 0.6296 - val_accuracy: 0.8161\n","Epoch 813/1000\n","43/67 [==================>...........] - ETA: 0s - loss: 0.2839 - accuracy: 0.8814\n","Epoch 813: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2700 - accuracy: 0.8862 - val_loss: 0.6769 - val_accuracy: 0.8027\n","Epoch 814/1000\n","64/67 [===========================>..] - ETA: 0s - loss: 0.2716 - accuracy: 0.8828\n","Epoch 814: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2744 - accuracy: 0.8817 - val_loss: 0.7228 - val_accuracy: 0.8206\n","Epoch 815/1000\n","49/67 [====================>.........] - ETA: 0s - loss: 0.2792 - accuracy: 0.8857\n","Epoch 815: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2676 - accuracy: 0.8892 - val_loss: 0.7429 - val_accuracy: 0.8117\n","Epoch 816/1000\n","59/67 [=========================>....] - ETA: 0s - loss: 0.2506 - accuracy: 0.8949\n","Epoch 816: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2612 - accuracy: 0.8892 - val_loss: 0.7418 - val_accuracy: 0.8251\n","Epoch 817/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.2686 - accuracy: 0.8877\n","Epoch 817: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2686 - accuracy: 0.8877 - val_loss: 0.7009 - val_accuracy: 0.8206\n","Epoch 818/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.2601 - accuracy: 0.8937\n","Epoch 818: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2601 - accuracy: 0.8937 - val_loss: 0.7331 - val_accuracy: 0.8251\n","Epoch 819/1000\n","58/67 [========================>.....] - ETA: 0s - loss: 0.2528 - accuracy: 0.8966\n","Epoch 819: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2627 - accuracy: 0.8937 - val_loss: 0.7584 - val_accuracy: 0.8206\n","Epoch 820/1000\n","55/67 [=======================>......] - ETA: 0s - loss: 0.2585 - accuracy: 0.8891\n","Epoch 820: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2676 - accuracy: 0.8892 - val_loss: 0.7224 - val_accuracy: 0.8251\n","Epoch 821/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.2696 - accuracy: 0.8907\n","Epoch 821: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2696 - accuracy: 0.8907 - val_loss: 0.7234 - val_accuracy: 0.8072\n","Epoch 822/1000\n","48/67 [====================>.........] - ETA: 0s - loss: 0.2547 - accuracy: 0.8958\n","Epoch 822: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2602 - accuracy: 0.8952 - val_loss: 0.7396 - val_accuracy: 0.8027\n","Epoch 823/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.4447 - accuracy: 0.8879\n","Epoch 823: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.4465 - accuracy: 0.8862 - val_loss: 0.7010 - val_accuracy: 0.8117\n","Epoch 824/1000\n","45/67 [===================>..........] - ETA: 0s - loss: 0.2701 - accuracy: 0.8956\n","Epoch 824: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2775 - accuracy: 0.8847 - val_loss: 0.7834 - val_accuracy: 0.8206\n","Epoch 825/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.2589 - accuracy: 0.8909\n","Epoch 825: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2614 - accuracy: 0.8877 - val_loss: 0.8116 - val_accuracy: 0.7982\n","Epoch 826/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2509 - accuracy: 0.9000\n","Epoch 826: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2737 - accuracy: 0.8862 - val_loss: 0.7428 - val_accuracy: 0.8117\n","Epoch 827/1000\n","50/67 [=====================>........] - ETA: 0s - loss: 0.2684 - accuracy: 0.8780\n","Epoch 827: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2584 - accuracy: 0.8907 - val_loss: 0.7516 - val_accuracy: 0.8072\n","Epoch 828/1000\n","45/67 [===================>..........] - ETA: 0s - loss: 0.2433 - accuracy: 0.8867\n","Epoch 828: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2655 - accuracy: 0.8832 - val_loss: 0.7930 - val_accuracy: 0.8072\n","Epoch 829/1000\n","64/67 [===========================>..] - ETA: 0s - loss: 0.2543 - accuracy: 0.8922\n","Epoch 829: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2619 - accuracy: 0.8892 - val_loss: 0.8103 - val_accuracy: 0.8027\n","Epoch 830/1000\n","62/67 [==========================>...] - ETA: 0s - loss: 0.2845 - accuracy: 0.8855\n","Epoch 830: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2806 - accuracy: 0.8847 - val_loss: 0.8331 - val_accuracy: 0.8027\n","Epoch 831/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.2922 - accuracy: 0.8802\n","Epoch 831: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2922 - accuracy: 0.8802 - val_loss: 0.8136 - val_accuracy: 0.8072\n","Epoch 832/1000\n","50/67 [=====================>........] - ETA: 0s - loss: 0.2785 - accuracy: 0.8820\n","Epoch 832: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2834 - accuracy: 0.8847 - val_loss: 0.6968 - val_accuracy: 0.8072\n","Epoch 833/1000\n","47/67 [====================>.........] - ETA: 0s - loss: 0.2660 - accuracy: 0.8915\n","Epoch 833: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2586 - accuracy: 0.8922 - val_loss: 0.7766 - val_accuracy: 0.8117\n","Epoch 834/1000\n","65/67 [============================>.] - ETA: 0s - loss: 0.2660 - accuracy: 0.8908\n","Epoch 834: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2665 - accuracy: 0.8907 - val_loss: 0.7186 - val_accuracy: 0.8117\n","Epoch 835/1000\n","51/67 [=====================>........] - ETA: 0s - loss: 0.2640 - accuracy: 0.8882\n","Epoch 835: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2672 - accuracy: 0.8922 - val_loss: 0.7259 - val_accuracy: 0.8072\n","Epoch 836/1000\n","48/67 [====================>.........] - ETA: 0s - loss: 0.2769 - accuracy: 0.8771\n","Epoch 836: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2760 - accuracy: 0.8772 - val_loss: 0.7573 - val_accuracy: 0.8027\n","Epoch 837/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.2579 - accuracy: 0.8909\n","Epoch 837: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2572 - accuracy: 0.8907 - val_loss: 0.8025 - val_accuracy: 0.8117\n","Epoch 838/1000\n","61/67 [==========================>...] - ETA: 0s - loss: 0.2610 - accuracy: 0.8754\n","Epoch 838: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2640 - accuracy: 0.8728 - val_loss: 0.8973 - val_accuracy: 0.8072\n","Epoch 839/1000\n","49/67 [====================>.........] - ETA: 0s - loss: 0.2519 - accuracy: 0.8918\n","Epoch 839: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2823 - accuracy: 0.8757 - val_loss: 0.8209 - val_accuracy: 0.8117\n","Epoch 840/1000\n","44/67 [==================>...........] - ETA: 0s - loss: 0.2957 - accuracy: 0.8636\n","Epoch 840: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2763 - accuracy: 0.8817 - val_loss: 0.7804 - val_accuracy: 0.8206\n","Epoch 841/1000\n","51/67 [=====================>........] - ETA: 0s - loss: 0.2676 - accuracy: 0.8941\n","Epoch 841: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2801 - accuracy: 0.8802 - val_loss: 0.7719 - val_accuracy: 0.7982\n","Epoch 842/1000\n","48/67 [====================>.........] - ETA: 0s - loss: 0.2833 - accuracy: 0.8771\n","Epoch 842: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2713 - accuracy: 0.8847 - val_loss: 0.7672 - val_accuracy: 0.8161\n","Epoch 843/1000\n","48/67 [====================>.........] - ETA: 0s - loss: 0.2812 - accuracy: 0.8792\n","Epoch 843: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2595 - accuracy: 0.8892 - val_loss: 0.8124 - val_accuracy: 0.8072\n","Epoch 844/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2426 - accuracy: 0.9065\n","Epoch 844: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2624 - accuracy: 0.8967 - val_loss: 0.8009 - val_accuracy: 0.8117\n","Epoch 845/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.2729 - accuracy: 0.8907\n","Epoch 845: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2729 - accuracy: 0.8907 - val_loss: 0.7687 - val_accuracy: 0.8161\n","Epoch 846/1000\n","49/67 [====================>.........] - ETA: 0s - loss: 0.2402 - accuracy: 0.9020\n","Epoch 846: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2655 - accuracy: 0.8892 - val_loss: 0.7968 - val_accuracy: 0.8206\n","Epoch 847/1000\n","44/67 [==================>...........] - ETA: 0s - loss: 0.2389 - accuracy: 0.9023\n","Epoch 847: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2546 - accuracy: 0.8907 - val_loss: 0.7714 - val_accuracy: 0.8161\n","Epoch 848/1000\n","47/67 [====================>.........] - ETA: 0s - loss: 0.2776 - accuracy: 0.8830\n","Epoch 848: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2663 - accuracy: 0.8907 - val_loss: 0.8396 - val_accuracy: 0.8117\n","Epoch 849/1000\n","44/67 [==================>...........] - ETA: 0s - loss: 0.2555 - accuracy: 0.8909\n","Epoch 849: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2614 - accuracy: 0.8862 - val_loss: 0.8546 - val_accuracy: 0.8161\n","Epoch 850/1000\n","47/67 [====================>.........] - ETA: 0s - loss: 0.2781 - accuracy: 0.8723\n","Epoch 850: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2648 - accuracy: 0.8832 - val_loss: 0.7827 - val_accuracy: 0.8206\n","Epoch 851/1000\n","57/67 [========================>.....] - ETA: 0s - loss: 0.2766 - accuracy: 0.8789\n","Epoch 851: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2776 - accuracy: 0.8802 - val_loss: 0.7287 - val_accuracy: 0.8206\n","Epoch 852/1000\n","56/67 [========================>.....] - ETA: 0s - loss: 0.2754 - accuracy: 0.8821\n","Epoch 852: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2650 - accuracy: 0.8922 - val_loss: 0.7373 - val_accuracy: 0.8027\n","Epoch 853/1000\n","55/67 [=======================>......] - ETA: 0s - loss: 0.2658 - accuracy: 0.8945\n","Epoch 853: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2644 - accuracy: 0.8952 - val_loss: 0.7714 - val_accuracy: 0.8027\n","Epoch 854/1000\n","53/67 [======================>.......] - ETA: 0s - loss: 0.2728 - accuracy: 0.8943\n","Epoch 854: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2739 - accuracy: 0.8907 - val_loss: 0.7294 - val_accuracy: 0.8072\n","Epoch 855/1000\n","49/67 [====================>.........] - ETA: 0s - loss: 0.2587 - accuracy: 0.8980\n","Epoch 855: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2549 - accuracy: 0.8922 - val_loss: 0.7758 - val_accuracy: 0.8027\n","Epoch 856/1000\n","51/67 [=====================>........] - ETA: 0s - loss: 0.2741 - accuracy: 0.8824\n","Epoch 856: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2812 - accuracy: 0.8847 - val_loss: 0.7315 - val_accuracy: 0.8072\n","Epoch 857/1000\n","47/67 [====================>.........] - ETA: 0s - loss: 0.2659 - accuracy: 0.8809\n","Epoch 857: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2702 - accuracy: 0.8847 - val_loss: 0.7451 - val_accuracy: 0.8161\n","Epoch 858/1000\n","50/67 [=====================>........] - ETA: 0s - loss: 0.2611 - accuracy: 0.8940\n","Epoch 858: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2622 - accuracy: 0.8922 - val_loss: 0.7323 - val_accuracy: 0.8206\n","Epoch 859/1000\n","50/67 [=====================>........] - ETA: 0s - loss: 0.3082 - accuracy: 0.8760\n","Epoch 859: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2792 - accuracy: 0.8862 - val_loss: 0.6757 - val_accuracy: 0.8072\n","Epoch 860/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.2681 - accuracy: 0.8985\n","Epoch 860: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2683 - accuracy: 0.8982 - val_loss: 0.7441 - val_accuracy: 0.8072\n","Epoch 861/1000\n","52/67 [======================>.......] - ETA: 0s - loss: 0.2925 - accuracy: 0.8865\n","Epoch 861: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2783 - accuracy: 0.8922 - val_loss: 0.7625 - val_accuracy: 0.8072\n","Epoch 862/1000\n","63/67 [===========================>..] - ETA: 0s - loss: 0.2708 - accuracy: 0.8810\n","Epoch 862: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2704 - accuracy: 0.8832 - val_loss: 0.7103 - val_accuracy: 0.8206\n","Epoch 863/1000\n","60/67 [=========================>....] - ETA: 0s - loss: 0.2755 - accuracy: 0.8867\n","Epoch 863: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2696 - accuracy: 0.8907 - val_loss: 0.7454 - val_accuracy: 0.8117\n","Epoch 864/1000\n","63/67 [===========================>..] - ETA: 0s - loss: 0.2608 - accuracy: 0.8889\n","Epoch 864: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2592 - accuracy: 0.8892 - val_loss: 0.7535 - val_accuracy: 0.8117\n","Epoch 865/1000\n","45/67 [===================>..........] - ETA: 0s - loss: 0.2521 - accuracy: 0.8956\n","Epoch 865: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2691 - accuracy: 0.8847 - val_loss: 0.6866 - val_accuracy: 0.8027\n","Epoch 866/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.2819 - accuracy: 0.8832\n","Epoch 866: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2819 - accuracy: 0.8832 - val_loss: 0.7145 - val_accuracy: 0.8027\n","Epoch 867/1000\n","58/67 [========================>.....] - ETA: 0s - loss: 0.2672 - accuracy: 0.8879\n","Epoch 867: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2754 - accuracy: 0.8832 - val_loss: 0.7164 - val_accuracy: 0.8027\n","Epoch 868/1000\n","59/67 [=========================>....] - ETA: 0s - loss: 0.2800 - accuracy: 0.8814\n","Epoch 868: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2762 - accuracy: 0.8847 - val_loss: 0.6976 - val_accuracy: 0.8072\n","Epoch 869/1000\n","58/67 [========================>.....] - ETA: 0s - loss: 0.2621 - accuracy: 0.8931\n","Epoch 869: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2628 - accuracy: 0.8907 - val_loss: 0.7419 - val_accuracy: 0.8027\n","Epoch 870/1000\n","65/67 [============================>.] - ETA: 0s - loss: 0.2872 - accuracy: 0.8754\n","Epoch 870: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2840 - accuracy: 0.8757 - val_loss: 0.7211 - val_accuracy: 0.8072\n","Epoch 871/1000\n","45/67 [===================>..........] - ETA: 0s - loss: 0.2847 - accuracy: 0.8778\n","Epoch 871: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2661 - accuracy: 0.8892 - val_loss: 0.7401 - val_accuracy: 0.8117\n","Epoch 872/1000\n","49/67 [====================>.........] - ETA: 0s - loss: 0.2647 - accuracy: 0.8857\n","Epoch 872: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2612 - accuracy: 0.8847 - val_loss: 0.7306 - val_accuracy: 0.8206\n","Epoch 873/1000\n","65/67 [============================>.] - ETA: 0s - loss: 0.2770 - accuracy: 0.8815\n","Epoch 873: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2761 - accuracy: 0.8817 - val_loss: 0.6594 - val_accuracy: 0.7937\n","Epoch 874/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.3158 - accuracy: 0.8674\n","Epoch 874: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3021 - accuracy: 0.8728 - val_loss: 0.6861 - val_accuracy: 0.8206\n","Epoch 875/1000\n","53/67 [======================>.......] - ETA: 0s - loss: 0.2810 - accuracy: 0.8887\n","Epoch 875: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2696 - accuracy: 0.8937 - val_loss: 0.7306 - val_accuracy: 0.8027\n","Epoch 876/1000\n","60/67 [=========================>....] - ETA: 0s - loss: 0.2515 - accuracy: 0.8983\n","Epoch 876: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2635 - accuracy: 0.8922 - val_loss: 0.7726 - val_accuracy: 0.8072\n","Epoch 877/1000\n","61/67 [==========================>...] - ETA: 0s - loss: 0.2743 - accuracy: 0.8820\n","Epoch 877: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2772 - accuracy: 0.8817 - val_loss: 0.7057 - val_accuracy: 0.8072\n","Epoch 878/1000\n","57/67 [========================>.....] - ETA: 0s - loss: 0.2660 - accuracy: 0.8877\n","Epoch 878: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2701 - accuracy: 0.8847 - val_loss: 0.6871 - val_accuracy: 0.8117\n","Epoch 879/1000\n","48/67 [====================>.........] - ETA: 0s - loss: 0.2858 - accuracy: 0.8813\n","Epoch 879: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2777 - accuracy: 0.8847 - val_loss: 0.6352 - val_accuracy: 0.8027\n","Epoch 880/1000\n","61/67 [==========================>...] - ETA: 0s - loss: 0.2649 - accuracy: 0.8984\n","Epoch 880: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2706 - accuracy: 0.8922 - val_loss: 0.7273 - val_accuracy: 0.8161\n","Epoch 881/1000\n","62/67 [==========================>...] - ETA: 0s - loss: 0.2635 - accuracy: 0.8855\n","Epoch 881: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 5ms/step - loss: 0.2653 - accuracy: 0.8892 - val_loss: 0.7688 - val_accuracy: 0.8027\n","Epoch 882/1000\n","58/67 [========================>.....] - ETA: 0s - loss: 0.2702 - accuracy: 0.8759\n","Epoch 882: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2663 - accuracy: 0.8787 - val_loss: 0.7883 - val_accuracy: 0.8072\n","Epoch 883/1000\n","63/67 [===========================>..] - ETA: 0s - loss: 0.2591 - accuracy: 0.8873\n","Epoch 883: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2544 - accuracy: 0.8907 - val_loss: 0.7833 - val_accuracy: 0.8072\n","Epoch 884/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.2644 - accuracy: 0.8847\n","Epoch 884: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 5ms/step - loss: 0.2644 - accuracy: 0.8847 - val_loss: 0.7623 - val_accuracy: 0.8117\n","Epoch 885/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.2592 - accuracy: 0.8922\n","Epoch 885: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2592 - accuracy: 0.8922 - val_loss: 0.7969 - val_accuracy: 0.8161\n","Epoch 886/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.2584 - accuracy: 0.8879\n","Epoch 886: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2561 - accuracy: 0.8892 - val_loss: 0.7843 - val_accuracy: 0.8161\n","Epoch 887/1000\n","63/67 [===========================>..] - ETA: 0s - loss: 0.2684 - accuracy: 0.8825\n","Epoch 887: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2618 - accuracy: 0.8862 - val_loss: 0.7879 - val_accuracy: 0.8072\n","Epoch 888/1000\n","56/67 [========================>.....] - ETA: 0s - loss: 0.2625 - accuracy: 0.8893\n","Epoch 888: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2700 - accuracy: 0.8862 - val_loss: 0.7650 - val_accuracy: 0.8206\n","Epoch 889/1000\n","65/67 [============================>.] - ETA: 0s - loss: 0.2705 - accuracy: 0.8954\n","Epoch 889: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2701 - accuracy: 0.8952 - val_loss: 0.7547 - val_accuracy: 0.8117\n","Epoch 890/1000\n","63/67 [===========================>..] - ETA: 0s - loss: 0.2567 - accuracy: 0.8937\n","Epoch 890: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2587 - accuracy: 0.8922 - val_loss: 0.7928 - val_accuracy: 0.8161\n","Epoch 891/1000\n","60/67 [=========================>....] - ETA: 0s - loss: 0.2653 - accuracy: 0.8950\n","Epoch 891: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2642 - accuracy: 0.8922 - val_loss: 0.7904 - val_accuracy: 0.8072\n","Epoch 892/1000\n","48/67 [====================>.........] - ETA: 0s - loss: 0.2793 - accuracy: 0.8833\n","Epoch 892: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2728 - accuracy: 0.8832 - val_loss: 0.8172 - val_accuracy: 0.8117\n","Epoch 893/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.2747 - accuracy: 0.8788\n","Epoch 893: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2727 - accuracy: 0.8802 - val_loss: 0.7594 - val_accuracy: 0.8206\n","Epoch 894/1000\n","54/67 [=======================>......] - ETA: 0s - loss: 0.2826 - accuracy: 0.8796\n","Epoch 894: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2759 - accuracy: 0.8847 - val_loss: 0.7908 - val_accuracy: 0.8161\n","Epoch 895/1000\n","65/67 [============================>.] - ETA: 0s - loss: 0.2661 - accuracy: 0.8985\n","Epoch 895: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2641 - accuracy: 0.9012 - val_loss: 0.7880 - val_accuracy: 0.8161\n","Epoch 896/1000\n","62/67 [==========================>...] - ETA: 0s - loss: 0.2693 - accuracy: 0.8806\n","Epoch 896: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2705 - accuracy: 0.8802 - val_loss: 0.8176 - val_accuracy: 0.8161\n","Epoch 897/1000\n","55/67 [=======================>......] - ETA: 0s - loss: 0.2723 - accuracy: 0.8764\n","Epoch 897: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2706 - accuracy: 0.8832 - val_loss: 0.7551 - val_accuracy: 0.8206\n","Epoch 898/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.2668 - accuracy: 0.8967\n","Epoch 898: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2668 - accuracy: 0.8967 - val_loss: 0.7604 - val_accuracy: 0.8072\n","Epoch 899/1000\n","65/67 [============================>.] - ETA: 0s - loss: 0.2715 - accuracy: 0.8800\n","Epoch 899: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2712 - accuracy: 0.8817 - val_loss: 0.7696 - val_accuracy: 0.8206\n","Epoch 900/1000\n","49/67 [====================>.........] - ETA: 0s - loss: 0.2760 - accuracy: 0.8816\n","Epoch 900: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2729 - accuracy: 0.8907 - val_loss: 0.7555 - val_accuracy: 0.8027\n","Epoch 901/1000\n","57/67 [========================>.....] - ETA: 0s - loss: 0.2757 - accuracy: 0.8825\n","Epoch 901: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2663 - accuracy: 0.8892 - val_loss: 0.7458 - val_accuracy: 0.8117\n","Epoch 902/1000\n","47/67 [====================>.........] - ETA: 0s - loss: 0.2872 - accuracy: 0.8872\n","Epoch 902: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2973 - accuracy: 0.8772 - val_loss: 0.7449 - val_accuracy: 0.7982\n","Epoch 903/1000\n","49/67 [====================>.........] - ETA: 0s - loss: 0.2844 - accuracy: 0.8857\n","Epoch 903: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2783 - accuracy: 0.8922 - val_loss: 0.7124 - val_accuracy: 0.8072\n","Epoch 904/1000\n","47/67 [====================>.........] - ETA: 0s - loss: 0.2558 - accuracy: 0.9021\n","Epoch 904: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2688 - accuracy: 0.8907 - val_loss: 0.7895 - val_accuracy: 0.7937\n","Epoch 905/1000\n","43/67 [==================>...........] - ETA: 0s - loss: 0.2629 - accuracy: 0.8814\n","Epoch 905: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2722 - accuracy: 0.8802 - val_loss: 0.7427 - val_accuracy: 0.8027\n","Epoch 906/1000\n","62/67 [==========================>...] - ETA: 0s - loss: 0.2699 - accuracy: 0.8903\n","Epoch 906: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2618 - accuracy: 0.8952 - val_loss: 0.7504 - val_accuracy: 0.8027\n","Epoch 907/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.2620 - accuracy: 0.8909\n","Epoch 907: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2632 - accuracy: 0.8907 - val_loss: 0.7591 - val_accuracy: 0.8206\n","Epoch 908/1000\n","65/67 [============================>.] - ETA: 0s - loss: 0.2773 - accuracy: 0.8785\n","Epoch 908: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2754 - accuracy: 0.8817 - val_loss: 0.7868 - val_accuracy: 0.8027\n","Epoch 909/1000\n","56/67 [========================>.....] - ETA: 0s - loss: 0.2575 - accuracy: 0.8946\n","Epoch 909: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2583 - accuracy: 0.8922 - val_loss: 0.7928 - val_accuracy: 0.8072\n","Epoch 910/1000\n","65/67 [============================>.] - ETA: 0s - loss: 0.2677 - accuracy: 0.8862\n","Epoch 910: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2642 - accuracy: 0.8892 - val_loss: 0.7745 - val_accuracy: 0.7982\n","Epoch 911/1000\n","61/67 [==========================>...] - ETA: 0s - loss: 0.2742 - accuracy: 0.8836\n","Epoch 911: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2734 - accuracy: 0.8817 - val_loss: 0.7470 - val_accuracy: 0.8206\n","Epoch 912/1000\n","57/67 [========================>.....] - ETA: 0s - loss: 0.2625 - accuracy: 0.8895\n","Epoch 912: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2601 - accuracy: 0.8907 - val_loss: 0.7573 - val_accuracy: 0.8072\n","Epoch 913/1000\n","65/67 [============================>.] - ETA: 0s - loss: 0.2587 - accuracy: 0.8985\n","Epoch 913: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2597 - accuracy: 0.8982 - val_loss: 0.8232 - val_accuracy: 0.8072\n","Epoch 914/1000\n","58/67 [========================>.....] - ETA: 0s - loss: 0.2733 - accuracy: 0.8845\n","Epoch 914: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2652 - accuracy: 0.8877 - val_loss: 0.8278 - val_accuracy: 0.8072\n","Epoch 915/1000\n","54/67 [=======================>......] - ETA: 0s - loss: 0.2621 - accuracy: 0.8852\n","Epoch 915: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2623 - accuracy: 0.8892 - val_loss: 0.8579 - val_accuracy: 0.8027\n","Epoch 916/1000\n","52/67 [======================>.......] - ETA: 0s - loss: 0.3343 - accuracy: 0.9019\n","Epoch 916: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.3200 - accuracy: 0.8997 - val_loss: 0.7367 - val_accuracy: 0.8027\n","Epoch 917/1000\n","58/67 [========================>.....] - ETA: 0s - loss: 0.2633 - accuracy: 0.8914\n","Epoch 917: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2669 - accuracy: 0.8877 - val_loss: 0.7255 - val_accuracy: 0.8117\n","Epoch 918/1000\n","62/67 [==========================>...] - ETA: 0s - loss: 0.2672 - accuracy: 0.8839\n","Epoch 918: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2599 - accuracy: 0.8862 - val_loss: 0.7909 - val_accuracy: 0.8072\n","Epoch 919/1000\n","64/67 [===========================>..] - ETA: 0s - loss: 0.2681 - accuracy: 0.8813\n","Epoch 919: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2694 - accuracy: 0.8817 - val_loss: 0.7937 - val_accuracy: 0.8027\n","Epoch 920/1000\n","64/67 [===========================>..] - ETA: 0s - loss: 0.2616 - accuracy: 0.8891\n","Epoch 920: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2669 - accuracy: 0.8847 - val_loss: 0.7769 - val_accuracy: 0.8072\n","Epoch 921/1000\n","59/67 [=========================>....] - ETA: 0s - loss: 0.2706 - accuracy: 0.8881\n","Epoch 921: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2727 - accuracy: 0.8907 - val_loss: 0.7609 - val_accuracy: 0.8072\n","Epoch 922/1000\n","58/67 [========================>.....] - ETA: 0s - loss: 0.2727 - accuracy: 0.8862\n","Epoch 922: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2655 - accuracy: 0.8877 - val_loss: 0.8212 - val_accuracy: 0.8027\n","Epoch 923/1000\n","59/67 [=========================>....] - ETA: 0s - loss: 0.2869 - accuracy: 0.8864\n","Epoch 923: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2835 - accuracy: 0.8892 - val_loss: 0.6851 - val_accuracy: 0.8117\n","Epoch 924/1000\n","57/67 [========================>.....] - ETA: 0s - loss: 0.3054 - accuracy: 0.8789\n","Epoch 924: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2940 - accuracy: 0.8817 - val_loss: 0.6859 - val_accuracy: 0.8027\n","Epoch 925/1000\n","57/67 [========================>.....] - ETA: 0s - loss: 0.2764 - accuracy: 0.8842\n","Epoch 925: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2653 - accuracy: 0.8892 - val_loss: 0.7604 - val_accuracy: 0.8117\n","Epoch 926/1000\n","49/67 [====================>.........] - ETA: 0s - loss: 0.2629 - accuracy: 0.8837\n","Epoch 926: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2678 - accuracy: 0.8862 - val_loss: 0.7420 - val_accuracy: 0.8072\n","Epoch 927/1000\n","61/67 [==========================>...] - ETA: 0s - loss: 0.2623 - accuracy: 0.8869\n","Epoch 927: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2746 - accuracy: 0.8862 - val_loss: 0.7156 - val_accuracy: 0.8072\n","Epoch 928/1000\n","60/67 [=========================>....] - ETA: 0s - loss: 0.2608 - accuracy: 0.8850\n","Epoch 928: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2750 - accuracy: 0.8802 - val_loss: 0.7352 - val_accuracy: 0.8072\n","Epoch 929/1000\n","61/67 [==========================>...] - ETA: 0s - loss: 0.2602 - accuracy: 0.8951\n","Epoch 929: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2548 - accuracy: 0.8952 - val_loss: 0.7766 - val_accuracy: 0.8206\n","Epoch 930/1000\n","65/67 [============================>.] - ETA: 0s - loss: 0.2779 - accuracy: 0.8846\n","Epoch 930: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2751 - accuracy: 0.8847 - val_loss: 0.7308 - val_accuracy: 0.8206\n","Epoch 931/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2728 - accuracy: 0.8783\n","Epoch 931: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2608 - accuracy: 0.8862 - val_loss: 0.8131 - val_accuracy: 0.8117\n","Epoch 932/1000\n","60/67 [=========================>....] - ETA: 0s - loss: 0.2635 - accuracy: 0.8883\n","Epoch 932: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2556 - accuracy: 0.8922 - val_loss: 0.8232 - val_accuracy: 0.8251\n","Epoch 933/1000\n","61/67 [==========================>...] - ETA: 0s - loss: 0.2585 - accuracy: 0.8967\n","Epoch 933: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2615 - accuracy: 0.9012 - val_loss: 0.8650 - val_accuracy: 0.8296\n","Epoch 934/1000\n","65/67 [============================>.] - ETA: 0s - loss: 0.2618 - accuracy: 0.8954\n","Epoch 934: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2664 - accuracy: 0.8922 - val_loss: 0.8151 - val_accuracy: 0.8251\n","Epoch 935/1000\n","63/67 [===========================>..] - ETA: 0s - loss: 0.2545 - accuracy: 0.8889\n","Epoch 935: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2567 - accuracy: 0.8877 - val_loss: 0.7836 - val_accuracy: 0.8117\n","Epoch 936/1000\n","51/67 [=====================>........] - ETA: 0s - loss: 0.2850 - accuracy: 0.8824\n","Epoch 936: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2773 - accuracy: 0.8847 - val_loss: 0.7966 - val_accuracy: 0.8161\n","Epoch 937/1000\n","61/67 [==========================>...] - ETA: 0s - loss: 0.2571 - accuracy: 0.8934\n","Epoch 937: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2598 - accuracy: 0.8907 - val_loss: 0.8693 - val_accuracy: 0.8072\n","Epoch 938/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.2696 - accuracy: 0.8832\n","Epoch 938: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2696 - accuracy: 0.8832 - val_loss: 0.7576 - val_accuracy: 0.8117\n","Epoch 939/1000\n","53/67 [======================>.......] - ETA: 0s - loss: 0.2484 - accuracy: 0.8925\n","Epoch 939: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2765 - accuracy: 0.8817 - val_loss: 0.8707 - val_accuracy: 0.8072\n","Epoch 940/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2630 - accuracy: 0.8935\n","Epoch 940: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2621 - accuracy: 0.8892 - val_loss: 0.7991 - val_accuracy: 0.8072\n","Epoch 941/1000\n","64/67 [===========================>..] - ETA: 0s - loss: 0.2651 - accuracy: 0.8891\n","Epoch 941: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2629 - accuracy: 0.8922 - val_loss: 0.7821 - val_accuracy: 0.8161\n","Epoch 942/1000\n","62/67 [==========================>...] - ETA: 0s - loss: 0.2626 - accuracy: 0.8903\n","Epoch 942: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2609 - accuracy: 0.8937 - val_loss: 0.8410 - val_accuracy: 0.8027\n","Epoch 943/1000\n","62/67 [==========================>...] - ETA: 0s - loss: 0.2838 - accuracy: 0.8806\n","Epoch 943: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2744 - accuracy: 0.8847 - val_loss: 0.8233 - val_accuracy: 0.8072\n","Epoch 944/1000\n","62/67 [==========================>...] - ETA: 0s - loss: 0.2605 - accuracy: 0.8919\n","Epoch 944: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2614 - accuracy: 0.8907 - val_loss: 0.7944 - val_accuracy: 0.8072\n","Epoch 945/1000\n","64/67 [===========================>..] - ETA: 0s - loss: 0.2667 - accuracy: 0.8875\n","Epoch 945: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2696 - accuracy: 0.8862 - val_loss: 0.8939 - val_accuracy: 0.8027\n","Epoch 946/1000\n","59/67 [=========================>....] - ETA: 0s - loss: 0.2548 - accuracy: 0.8915\n","Epoch 946: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2566 - accuracy: 0.8937 - val_loss: 0.9118 - val_accuracy: 0.8027\n","Epoch 947/1000\n","57/67 [========================>.....] - ETA: 0s - loss: 0.2824 - accuracy: 0.8789\n","Epoch 947: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2591 - accuracy: 0.8922 - val_loss: 0.8870 - val_accuracy: 0.8072\n","Epoch 948/1000\n","63/67 [===========================>..] - ETA: 0s - loss: 0.2556 - accuracy: 0.8968\n","Epoch 948: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2536 - accuracy: 0.8967 - val_loss: 0.9285 - val_accuracy: 0.8027\n","Epoch 949/1000\n","52/67 [======================>.......] - ETA: 0s - loss: 0.2687 - accuracy: 0.8885\n","Epoch 949: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2606 - accuracy: 0.8937 - val_loss: 0.9086 - val_accuracy: 0.8296\n","Epoch 950/1000\n","65/67 [============================>.] - ETA: 0s - loss: 0.2620 - accuracy: 0.8862\n","Epoch 950: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2616 - accuracy: 0.8862 - val_loss: 0.9096 - val_accuracy: 0.8161\n","Epoch 951/1000\n","61/67 [==========================>...] - ETA: 0s - loss: 0.2577 - accuracy: 0.8885\n","Epoch 951: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2658 - accuracy: 0.8847 - val_loss: 0.7902 - val_accuracy: 0.8206\n","Epoch 952/1000\n","41/67 [=================>............] - ETA: 0s - loss: 0.2721 - accuracy: 0.8902\n","Epoch 952: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2651 - accuracy: 0.8922 - val_loss: 0.8269 - val_accuracy: 0.8206\n","Epoch 953/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.2628 - accuracy: 0.8877\n","Epoch 953: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2628 - accuracy: 0.8877 - val_loss: 0.8415 - val_accuracy: 0.8251\n","Epoch 954/1000\n","61/67 [==========================>...] - ETA: 0s - loss: 0.2738 - accuracy: 0.8869\n","Epoch 954: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2704 - accuracy: 0.8892 - val_loss: 0.8740 - val_accuracy: 0.8161\n","Epoch 955/1000\n","46/67 [===================>..........] - ETA: 0s - loss: 0.2653 - accuracy: 0.8891\n","Epoch 955: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2696 - accuracy: 0.8862 - val_loss: 0.8437 - val_accuracy: 0.8161\n","Epoch 956/1000\n","62/67 [==========================>...] - ETA: 0s - loss: 0.2609 - accuracy: 0.8839\n","Epoch 956: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2689 - accuracy: 0.8817 - val_loss: 0.8769 - val_accuracy: 0.8296\n","Epoch 957/1000\n","65/67 [============================>.] - ETA: 0s - loss: 0.2650 - accuracy: 0.8954\n","Epoch 957: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2688 - accuracy: 0.8922 - val_loss: 0.8792 - val_accuracy: 0.8072\n","Epoch 958/1000\n","63/67 [===========================>..] - ETA: 0s - loss: 0.2668 - accuracy: 0.8921\n","Epoch 958: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2624 - accuracy: 0.8922 - val_loss: 0.8491 - val_accuracy: 0.8072\n","Epoch 959/1000\n","50/67 [=====================>........] - ETA: 0s - loss: 0.2817 - accuracy: 0.8780\n","Epoch 959: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2720 - accuracy: 0.8877 - val_loss: 0.9262 - val_accuracy: 0.8027\n","Epoch 960/1000\n","59/67 [=========================>....] - ETA: 0s - loss: 0.2737 - accuracy: 0.8864\n","Epoch 960: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2748 - accuracy: 0.8892 - val_loss: 0.9058 - val_accuracy: 0.8161\n","Epoch 961/1000\n","49/67 [====================>.........] - ETA: 0s - loss: 0.2749 - accuracy: 0.8796\n","Epoch 961: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2689 - accuracy: 0.8802 - val_loss: 0.8089 - val_accuracy: 0.8251\n","Epoch 962/1000\n","45/67 [===================>..........] - ETA: 0s - loss: 0.2531 - accuracy: 0.9000\n","Epoch 962: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2556 - accuracy: 0.8922 - val_loss: 0.8257 - val_accuracy: 0.8027\n","Epoch 963/1000\n","54/67 [=======================>......] - ETA: 0s - loss: 0.2656 - accuracy: 0.8870\n","Epoch 963: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2680 - accuracy: 0.8862 - val_loss: 0.7992 - val_accuracy: 0.8072\n","Epoch 964/1000\n","49/67 [====================>.........] - ETA: 0s - loss: 0.2827 - accuracy: 0.8776\n","Epoch 964: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2807 - accuracy: 0.8817 - val_loss: 0.7773 - val_accuracy: 0.8072\n","Epoch 965/1000\n","50/67 [=====================>........] - ETA: 0s - loss: 0.2788 - accuracy: 0.8840\n","Epoch 965: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2961 - accuracy: 0.8728 - val_loss: 0.6954 - val_accuracy: 0.8161\n","Epoch 966/1000\n","57/67 [========================>.....] - ETA: 0s - loss: 0.2526 - accuracy: 0.9035\n","Epoch 966: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2684 - accuracy: 0.8937 - val_loss: 0.7604 - val_accuracy: 0.8072\n","Epoch 967/1000\n","47/67 [====================>.........] - ETA: 0s - loss: 0.2703 - accuracy: 0.8957\n","Epoch 967: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2680 - accuracy: 0.8937 - val_loss: 0.7525 - val_accuracy: 0.8251\n","Epoch 968/1000\n","49/67 [====================>.........] - ETA: 0s - loss: 0.2623 - accuracy: 0.8878\n","Epoch 968: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2609 - accuracy: 0.8892 - val_loss: 0.7424 - val_accuracy: 0.8117\n","Epoch 969/1000\n","51/67 [=====================>........] - ETA: 0s - loss: 0.2715 - accuracy: 0.8941\n","Epoch 969: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2710 - accuracy: 0.8892 - val_loss: 0.7306 - val_accuracy: 0.8206\n","Epoch 970/1000\n","45/67 [===================>..........] - ETA: 0s - loss: 0.2670 - accuracy: 0.8844\n","Epoch 970: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2613 - accuracy: 0.8922 - val_loss: 0.7269 - val_accuracy: 0.8251\n","Epoch 971/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.2723 - accuracy: 0.8894\n","Epoch 971: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2722 - accuracy: 0.8892 - val_loss: 0.7205 - val_accuracy: 0.8117\n","Epoch 972/1000\n","64/67 [===========================>..] - ETA: 0s - loss: 0.2714 - accuracy: 0.8813\n","Epoch 972: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2655 - accuracy: 0.8832 - val_loss: 0.7636 - val_accuracy: 0.8027\n","Epoch 973/1000\n","63/67 [===========================>..] - ETA: 0s - loss: 0.2732 - accuracy: 0.8937\n","Epoch 973: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2785 - accuracy: 0.8907 - val_loss: 0.7542 - val_accuracy: 0.8027\n","Epoch 974/1000\n","57/67 [========================>.....] - ETA: 0s - loss: 0.2673 - accuracy: 0.8895\n","Epoch 974: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2623 - accuracy: 0.8877 - val_loss: 0.7674 - val_accuracy: 0.8072\n","Epoch 975/1000\n","59/67 [=========================>....] - ETA: 0s - loss: 0.2597 - accuracy: 0.8847\n","Epoch 975: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2714 - accuracy: 0.8832 - val_loss: 0.8060 - val_accuracy: 0.8027\n","Epoch 976/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.2645 - accuracy: 0.8892\n","Epoch 976: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2645 - accuracy: 0.8892 - val_loss: 0.8025 - val_accuracy: 0.8161\n","Epoch 977/1000\n","65/67 [============================>.] - ETA: 0s - loss: 0.2568 - accuracy: 0.8954\n","Epoch 977: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2562 - accuracy: 0.8952 - val_loss: 0.7971 - val_accuracy: 0.8161\n","Epoch 978/1000\n","51/67 [=====================>........] - ETA: 0s - loss: 0.2665 - accuracy: 0.8843\n","Epoch 978: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2580 - accuracy: 0.8877 - val_loss: 0.8272 - val_accuracy: 0.8161\n","Epoch 979/1000\n","64/67 [===========================>..] - ETA: 0s - loss: 0.2641 - accuracy: 0.8906\n","Epoch 979: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2642 - accuracy: 0.8892 - val_loss: 0.8238 - val_accuracy: 0.8251\n","Epoch 980/1000\n","52/67 [======================>.......] - ETA: 0s - loss: 0.2618 - accuracy: 0.8865\n","Epoch 980: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2668 - accuracy: 0.8892 - val_loss: 0.7637 - val_accuracy: 0.8117\n","Epoch 981/1000\n","61/67 [==========================>...] - ETA: 0s - loss: 0.2781 - accuracy: 0.8770\n","Epoch 981: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2708 - accuracy: 0.8817 - val_loss: 0.8823 - val_accuracy: 0.8027\n","Epoch 982/1000\n","59/67 [=========================>....] - ETA: 0s - loss: 0.2718 - accuracy: 0.8915\n","Epoch 982: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2714 - accuracy: 0.8937 - val_loss: 0.8159 - val_accuracy: 0.7982\n","Epoch 983/1000\n","64/67 [===========================>..] - ETA: 0s - loss: 0.2645 - accuracy: 0.8891\n","Epoch 983: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2641 - accuracy: 0.8892 - val_loss: 0.8742 - val_accuracy: 0.8027\n","Epoch 984/1000\n","60/67 [=========================>....] - ETA: 0s - loss: 0.2660 - accuracy: 0.8883\n","Epoch 984: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2645 - accuracy: 0.8877 - val_loss: 0.9547 - val_accuracy: 0.8027\n","Epoch 985/1000\n","54/67 [=======================>......] - ETA: 0s - loss: 0.2818 - accuracy: 0.8852\n","Epoch 985: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2719 - accuracy: 0.8892 - val_loss: 0.8336 - val_accuracy: 0.7982\n","Epoch 986/1000\n","66/67 [============================>.] - ETA: 0s - loss: 0.2662 - accuracy: 0.8833\n","Epoch 986: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2639 - accuracy: 0.8847 - val_loss: 0.9029 - val_accuracy: 0.8027\n","Epoch 987/1000\n","42/67 [=================>............] - ETA: 0s - loss: 0.2479 - accuracy: 0.8976\n","Epoch 987: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2575 - accuracy: 0.8922 - val_loss: 0.8661 - val_accuracy: 0.8072\n","Epoch 988/1000\n","57/67 [========================>.....] - ETA: 0s - loss: 0.2578 - accuracy: 0.8982\n","Epoch 988: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2585 - accuracy: 0.8967 - val_loss: 0.9015 - val_accuracy: 0.8072\n","Epoch 989/1000\n","64/67 [===========================>..] - ETA: 0s - loss: 0.2972 - accuracy: 0.8813\n","Epoch 989: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2974 - accuracy: 0.8802 - val_loss: 0.7607 - val_accuracy: 0.8027\n","Epoch 990/1000\n","63/67 [===========================>..] - ETA: 0s - loss: 0.2703 - accuracy: 0.8873\n","Epoch 990: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2619 - accuracy: 0.8922 - val_loss: 0.8407 - val_accuracy: 0.8072\n","Epoch 991/1000\n","47/67 [====================>.........] - ETA: 0s - loss: 0.2497 - accuracy: 0.8979\n","Epoch 991: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2571 - accuracy: 0.8877 - val_loss: 0.8300 - val_accuracy: 0.8027\n","Epoch 992/1000\n","43/67 [==================>...........] - ETA: 0s - loss: 0.2513 - accuracy: 0.8930\n","Epoch 992: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2546 - accuracy: 0.8967 - val_loss: 0.8277 - val_accuracy: 0.8027\n","Epoch 993/1000\n","61/67 [==========================>...] - ETA: 0s - loss: 0.2649 - accuracy: 0.8836\n","Epoch 993: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2597 - accuracy: 0.8877 - val_loss: 0.8817 - val_accuracy: 0.8027\n","Epoch 994/1000\n","59/67 [=========================>....] - ETA: 0s - loss: 0.2793 - accuracy: 0.8881\n","Epoch 994: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2684 - accuracy: 0.8937 - val_loss: 0.8571 - val_accuracy: 0.8027\n","Epoch 995/1000\n","45/67 [===================>..........] - ETA: 0s - loss: 0.2784 - accuracy: 0.8756\n","Epoch 995: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2742 - accuracy: 0.8832 - val_loss: 0.8265 - val_accuracy: 0.8027\n","Epoch 996/1000\n","53/67 [======================>.......] - ETA: 0s - loss: 0.2568 - accuracy: 0.9000\n","Epoch 996: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 3ms/step - loss: 0.2588 - accuracy: 0.8907 - val_loss: 0.8709 - val_accuracy: 0.8027\n","Epoch 997/1000\n","62/67 [==========================>...] - ETA: 0s - loss: 0.2607 - accuracy: 0.8952\n","Epoch 997: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2676 - accuracy: 0.8892 - val_loss: 0.8542 - val_accuracy: 0.8027\n","Epoch 998/1000\n","65/67 [============================>.] - ETA: 0s - loss: 0.2668 - accuracy: 0.8846\n","Epoch 998: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2652 - accuracy: 0.8862 - val_loss: 0.8145 - val_accuracy: 0.8072\n","Epoch 999/1000\n","67/67 [==============================] - ETA: 0s - loss: 0.2627 - accuracy: 0.8892\n","Epoch 999: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2627 - accuracy: 0.8892 - val_loss: 0.8934 - val_accuracy: 0.8161\n","Epoch 1000/1000\n","61/67 [==========================>...] - ETA: 0s - loss: 0.2741 - accuracy: 0.8770\n","Epoch 1000: val_accuracy did not improve from 0.86996\n","67/67 [==============================] - 0s 4ms/step - loss: 0.2648 - accuracy: 0.8832 - val_loss: 0.8612 - val_accuracy: 0.8027\n"]},{"output_type":"execute_result","data":{"text/plain":["<keras.callbacks.History at 0x7f8cdbb4ebd0>"]},"metadata":{},"execution_count":264}],"source":["model.fit(X_train, y_train, epochs=1000, callbacks=[model_check], validation_data=(X_test, y_test), batch_size=10)"]},{"cell_type":"code","source":["best_model = tf.keras.models.load_model('/content/Logs')"],"metadata":{"id":"HYHhoz8gYqqA","executionInfo":{"status":"ok","timestamp":1661717771249,"user_tz":-270,"elapsed":1084,"user":{"displayName":"amirhossein rasouli","userId":"03756625815821128820"}}},"execution_count":265,"outputs":[]},{"cell_type":"code","source":["best_model.compile(optimizer='adam', loss=tf.keras.losses.BinaryCrossentropy(), metrics=['accuracy'])"],"metadata":{"id":"DDVfzRexVaM-","executionInfo":{"status":"ok","timestamp":1661717772634,"user_tz":-270,"elapsed":3,"user":{"displayName":"amirhossein rasouli","userId":"03756625815821128820"}}},"execution_count":266,"outputs":[]},{"cell_type":"code","source":["pred = best_model.predict(X_sub)\n","final = []\n","for p in pred: \n","  if p>0.5:\n","    final.append(1)\n","  else:\n","    final.append(0)"],"metadata":{"id":"BknUKawOao1l","executionInfo":{"status":"ok","timestamp":1661717774180,"user_tz":-270,"elapsed":2,"user":{"displayName":"amirhossein rasouli","userId":"03756625815821128820"}}},"execution_count":267,"outputs":[]},{"cell_type":"code","source":["sub = pd.read_csv('gender_submission.csv',index_col='PassengerId')\n","sub['Survived'] = final"],"metadata":{"id":"NTxiJ6jolowg","executionInfo":{"status":"ok","timestamp":1661717776206,"user_tz":-270,"elapsed":4,"user":{"displayName":"amirhossein rasouli","userId":"03756625815821128820"}}},"execution_count":268,"outputs":[]},{"cell_type":"code","source":["sub.to_csv('Pred.csv')"],"metadata":{"id":"QpGy8Y4mmh5J","executionInfo":{"status":"ok","timestamp":1661717776207,"user_tz":-270,"elapsed":5,"user":{"displayName":"amirhossein rasouli","userId":"03756625815821128820"}}},"execution_count":269,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3.10.2 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.2"},"orig_nbformat":4,"vscode":{"interpreter":{"hash":"0354d326129403289107761bee1c2024935d02ad6cbe1c7dd64c392723c72e60"}},"colab":{"name":"Titanic.ipynb","provenance":[],"collapsed_sections":[]}},"nbformat":4,"nbformat_minor":0}